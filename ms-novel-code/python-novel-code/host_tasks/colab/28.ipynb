{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Computing Paradigms\n",
        "\n",
        "**L2 Taxonomy** - Reactive Programming\n",
        "\n",
        "**Subtopic** - Real-Time Exception Handling Automation\n",
        "\n",
        "**Use Case** - Build a Python application that applies reactive programming techniques to monitor live error logs and trigger automated repair actions asynchronously. The system continuously subscribes to error events and processes runtime data in real time, generating prompt repair suggestions. This dynamic and responsive framework enhances system resilience by reducing downtime and automating critical error recovery, reflecting approaches in automated bug-fixing research fileciteturn0file7.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_etg_goEJ2l"
      },
      "source": [
        "# Model Breaking Hints\n",
        "\n",
        "\n",
        "1) **What is the initial use case?**\n",
        "   The initial use case is to build a Python application that applies reactive programming techniques to monitor live error logs and trigger automated repair actions asynchronously. The system subscribes to error events and processes runtime data in real time, generating prompt repair suggestions to enhance system resilience by reducing downtime and automating critical error recovery.\n",
        "\n",
        "2) **Why is the initial use case easy?**\n",
        "   It is easy because it involves straightforward implementation of reactive programming concepts using existing libraries and frameworks. Monitoring error logs and triggering repairs asynchronously are common tasks that don't require complex algorithms or advanced data structures. The problem is constrained to a single system without distributed components or intricate dependencies.\n",
        "\n",
        "3) **How could we make it harder?**\n",
        "   To increase the complexity, we can integrate multiple advanced concepts from the hints:\n",
        "   - **Hint 2**: Extend the system to process and synchronize error logs across distributed servers using consensus algorithms like Raft, introducing challenges in distributed systems and data consistency.\n",
        "   - **Hint 3**: Require real-time detection of complex error patterns using advanced data structures like suffix automata, adding complexity in pattern recognition and real-time processing.\n",
        "   - **Hint 5**: Introduce interdependent repair actions that may cause new errors, necessitating optimization techniques to minimize the total accumulated error impact, introducing an optimization problem with potential logical traps and non-greedy edge cases.\n",
        "\n",
        "4) **Which parameters can we change?**\n",
        "   - **System Scope**: Expand from a single system to a distributed network of servers, requiring synchronization of error logs and coordination between nodes.\n",
        "   - **Error Detection**: Move from simple error event handling to detecting complex sequences of errors using advanced data structures like suffix automata.\n",
        "   - **Repair Actions**: Modify repair actions to be interdependent and capable of introducing new errors, creating a need for an optimized sequence of actions.\n",
        "   - **Optimization Goal**: Include real-time constraints for minimizing the total accumulated error impact, requiring efficient algorithms to solve the optimization problem under time pressure.\n",
        "   - **Algorithms and Data Structures**: Incorporate consensus algorithms (Raft), suffix automata, and optimization techniques, increasing algorithmic complexity.\n",
        "\n",
        "5) **What can be a final hard prompt?**\n",
        "   Develop a Python application that monitors and synchronizes live error logs across distributed servers using a consensus algorithm like Raft. The system must detect complex sequences of errors in real time using a suffix automaton to trigger interdependent repair actions, where each repair may introduce new errors. Implement an optimization algorithm to determine the optimal sequence of repair actions that minimizes the total accumulated error impact under real-time constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "nest-asyncio==1.6.0\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "Build a Python application that applies reactive programming techniques to monitor live error logs and trigger automated repair actions asynchronously.\n",
        "The system continuously subscribes to error events and processes runtime data in real time, generating prompt repair suggestions.\n",
        "This dynamic and responsive framework enhances system resilience by reducing downtime and automating critical error recovery, reflecting approaches in automated bug-fixing research.\n",
        "Do not write explanations.\n",
        "\n",
        "##Input Format:\n",
        "- log_stream (Iterable[str]): A continuous stream (generator or list) of system logs, each represented as a string. Logs may include timestamps, error codes, messages, and severity levels.\n",
        "Example:\n",
        "\n",
        "[\n",
        "    \"[2025-06-18 18:00:01] ERROR: Disk failure on /dev/sda\",\n",
        "    \"[2025-06-18 18:00:05] WARNING: CPU temperature high\",\n",
        "    \"[2025-06-18 18:00:10] INFO: Backup completed successfully\"\n",
        "]\n",
        "\n",
        "- error_patterns (Dict[str, str]): A dictionary mapping error identifiers like error codes or keywords to their human-readable descriptions or classifications.\n",
        "\n",
        "Example:\n",
        "{\n",
        "    \"Disk failure\": \"Critical hardware error\",\n",
        "    \"CPU temperature high\": \"Thermal warning\",\n",
        "    \"OutOfMemory\": \"Memory exhaustion\"\n",
        "}\n",
        "\n",
        "- repair_actions (Dict[str, Callable[[], None]]): A dictionary mapping error identifiers to repair action functions (asynchronous or synchronous callables) that will be triggered when the corresponding error is detected.\n",
        "\n",
        "Example:\n",
        "{\n",
        "    \"Disk failure\": restart_disk_service,\n",
        "    \"CPU temperature high\": throttle_cpu,\n",
        "    \"OutOfMemory\": free_memory\n",
        "}\n",
        "\n",
        "- config (Dict[str, Any]): Configuration parameters controlling monitoring behavior. Typical keys might include:\n",
        "\"reactive_mode\": (bool) Enable or disable reactive repair.\n",
        "\"max_concurrent_repairs\": (int) Max number of repair actions that can run concurrently.\n",
        "\"log_retention_seconds\": (int) Time window to check logs for analysis. If a log timestamp falls out of the window it should be skipped\n",
        "\n",
        "Example:\n",
        "{\n",
        "    \"reactive_mode\": True,\n",
        "    \"max_concurrent_repairs\": 5,\n",
        "    \"log_retention_seconds\": 300\n",
        "}\n",
        "\n",
        "##Output Format:\n",
        "repair_log (Iterable[Dict[str, Any]]):\n",
        "A stream of dictionaries, each representing a repair event triggered by an error detection.\n",
        "Each dictionary contains:\n",
        "- \"timestamp\": (str) Time when the repair was initiated.\n",
        "- \"error\": (str) Error identifier that triggered the repair.\n",
        "- \"description\": (str) Description of the error (from error_patterns).\n",
        "- \"action\": (str) Name of the repair action function.\n",
        "- \"status\": (str) Outcome of the repair action. Possible values: \"success\", \"failed\", \"skipped\".\n",
        "- \"details\": (Optional[str]) Optional message or traceback for context.\n",
        "\n",
        "Example:\n",
        "[\n",
        "    {\n",
        "        \"timestamp\": \"2025-06-18 18:00:03\",\n",
        "        \"error\": \"Disk failure\",\n",
        "        \"description\": \"Critical hardware error\",\n",
        "        \"action\": \"restart_disk_service\",\n",
        "        \"status\": \"success\",\n",
        "        \"details\": \"Service restarted successfully\"\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": \"2025-06-18 18:00:06\",\n",
        "        \"error\": \"CPU temperature high\",\n",
        "        \"description\": \"Thermal warning\",\n",
        "        \"action\": \"throttle_cpu\",\n",
        "        \"status\": \"failed\",\n",
        "        \"details\": \"Permission denied while adjusting CPU limits\"\n",
        "    }\n",
        "]\n",
        "\n",
        "optional_status_summary (Dict[str, int]): A final summary of repairs may be returned at the end of monitoring or at checkpoints. It maps status types to counts.\n",
        "Example:\n",
        "{\n",
        "    \"success\": 12,\n",
        "    \"failed\": 3,\n",
        "    \"skipped\": 1\n",
        "}\n",
        "\n",
        "Examples:\n",
        "Example 1:\n",
        "```python\n",
        "log_stream = [\n",
        "    \"[2025-06-18 18:00:01] ERROR: Disk failure on /dev/sda\",\n",
        "    \"[2025-06-18 18:00:02] ERROR: CPU temperature high\"\n",
        "]\n",
        "error_patterns = {\n",
        "    \"Disk failure\": \"Critical hardware error\",\n",
        "    \"CPU temperature high\": \"Thermal warning\"\n",
        "}\n",
        "\n",
        "def restart_disk_service():\n",
        "    return \"Disk service restarted\"\n",
        "\n",
        "def throttle_cpu():\n",
        "    raise PermissionError(\"Access denied\")\n",
        "\n",
        "repair_actions = {\n",
        "    \"Disk failure\": restart_disk_service,\n",
        "    \"CPU temperature high\": throttle_cpu\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"reactive_mode\": True,\n",
        "    \"max_concurrent_repairs\": 2,\n",
        "    \"log_retention_seconds\": 120\n",
        "}\n",
        "```\n",
        "Output:\n",
        "```python\n",
        "repair_log = [\n",
        "    {\n",
        "        \"timestamp\": \"2025-06-18 18:00:01\",\n",
        "        \"error\": \"Disk failure\",\n",
        "        \"description\": \"Critical hardware error\",\n",
        "        \"action\": \"restart_disk_service\",\n",
        "        \"status\": \"success\",\n",
        "        \"details\": \"Disk service restarted\"\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": \"2025-06-18 18:00:02\",\n",
        "        \"error\": \"CPU temperature high\",\n",
        "        \"description\": \"Thermal warning\",\n",
        "        \"action\": \"throttle_cpu\",\n",
        "        \"status\": \"failed\",\n",
        "        \"details\": \"Access denied\"\n",
        "    }\n",
        "],\n",
        "\n",
        "optional_status_summary = {\n",
        "    \"success\": 1,\n",
        "    \"failed\": 1,\n",
        "    \"skipped\": 0\n",
        "}\n",
        "```\n",
        "\n",
        "Example 2:\n",
        "```python\n",
        "log_stream = [\n",
        "    \"[2025-06-18 18:05:01] ERROR: OutOfMemory while allocating buffer\",\n",
        "    \"[2025-06-18 18:05:04] WARNING: Low disk space\"\n",
        "]\n",
        "\n",
        "error_patterns = {\n",
        "    \"OutOfMemory\": \"Memory exhaustion\",\n",
        "    \"Low disk space\": \"Disk capacity alert\"\n",
        "}\n",
        "\n",
        "def free_memory():\n",
        "    return \"Memory cleared successfully\"\n",
        "\n",
        "def cleanup_disk():\n",
        "    return \"Cleanup skipped due to user restrictions\"\n",
        "\n",
        "repair_actions = {\n",
        "    \"OutOfMemory\": free_memory,\n",
        "    \"Low disk space\": cleanup_disk\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"reactive_mode\": True,\n",
        "    \"max_concurrent_repairs\": 1,\n",
        "    \"log_retention_seconds\": 300\n",
        "}\n",
        "```\n",
        "Output:\n",
        "```python\n",
        "repair_log = [\n",
        "    {\n",
        "        \"timestamp\": \"2025-06-18 18:05:01\",\n",
        "        \"error\": \"OutOfMemory\",\n",
        "        \"description\": \"Memory exhaustion\",\n",
        "        \"action\": \"free_memory\",\n",
        "        \"status\": \"success\",\n",
        "        \"details\": \"Memory cleared successfully\"\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": \"2025-06-18 18:05:04\",\n",
        "        \"error\": \"Low disk space\",\n",
        "        \"description\": \"Disk capacity alert\",\n",
        "        \"action\": \"cleanup_disk\",\n",
        "        \"status\": \"skipped\",\n",
        "        \"details\": \"Cleanup skipped due to user restrictions\"\n",
        "    }\n",
        "]\n",
        "\n",
        "optional_status_summary = {\n",
        "    \"success\": 1,\n",
        "    \"failed\": 0,\n",
        "    \"skipped\": 1\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "##Explicit Requirements:\n",
        "- Live log monitoring: The system must monitor error logs continuously in real time.\n",
        "- Error-to-action mapping: Specific repair functions must be triggered based on matched error patterns.\n",
        "- Skipping repairs: If the repair function returns a string which starts with \"no action\" or includes \"skipped\" pattern, it should be counted as skipped.\n",
        "- Successful repairs: If the repair function completes successfully and returns a string which does not start with \"no action\" nor or includes \"skipped\" pattern, it should counted as success.\n",
        "- Failed repairs: If the repair function fails or raises some exception/error, it should be counted as failed.\n",
        "- Asynchronous execution: Repair actions must be executed asynchronously to avoid blocking the system.\n",
        "- Automated repair triggering: Repairs must be triggered automatically when known errors are detected.\n",
        "- Structured output: The system must generate structured repair_log entries and a summary report.\n",
        "\n",
        "##Implicit Requirements:\n",
        "- Fault tolerance in repairs: Repair functions must handle exceptions gracefully to prevent system crashes.\n",
        "- Log parsing: The system must be able to extract meaningful error identifiers from raw log strings.\n",
        "- Concurrency control: The system should respect limits on the number of repairs running simultaneously.\n",
        "- Scalability of monitoring: The architecture should support growing log volume and diverse error types without performance degradation.\n",
        "\n",
        "##Function signature:\n",
        "```python\n",
        "def monitor_and_repair(\n",
        "    log_stream: Iterable[str],\n",
        "    error_patterns: Dict[str, str],\n",
        "    repair_actions: Dict[str, Optional[Callable[[], str]]],\n",
        "    config: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Monitors live error logs, detects known issues, and triggers asynchronous repair actions.\n",
        "\n",
        "    Returns:\n",
        "        - repair_log: A list of repair event dictionaries with status and metadata.\n",
        "        - optional_status_summary: A dictionary summarizing success/failed/skipped repair counts.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "##Edge cases:\n",
        "- Unknown error pattern - A log line contains an error that does not match any entry in error_patterns and should be ignored without triggering any repair.\n",
        "- Repair action raises an exception - A repair function throws an error when executed, and the system must log the status as \"failed\" without crashing.\n",
        "- Repair function returns a non-actionable message - A repair action completes but returns a message like \"No action taken\", which should be treated as a \"skipped\" repair.\n",
        "- Max concurrency exceeded: More errors are detected simultaneously than allowed by max_concurrent_repairs\n",
        "- If reactive_modeis is set to False, repair_log_result should be empty.\n",
        "\n",
        "##Input Constraints:\n",
        "- Number of log entries in log_stream: up to 100\n",
        "- Number of distinct error patterns: up to 50\n",
        "- Number of repair actions: up to 50\n",
        "- Maximum concurrent repair actions: up to 10\n",
        "- Maximum log retention window: up to 3600 seconds (1 hour)\n",
        "\n",
        "##Solution Constraints:\n",
        "- The system must process up to 100 log entries efficiently without blocking.\n",
        "- Each log must be matched against up to 50 error patterns using substring or regex matching.\n",
        "- Repair actions must be asynchronous and limited to max_concurrent_repairs.\n",
        "- Timestamps in logs older than log_retention_seconds must be ignored.\n",
        "- Repair results must be recorded in a structured format with fields: timestamp, error, description, action, status, and details.\n",
        "- If a repair action cannot be assigned to an error due to the action being None, it should be skipped with details as Invalid repair action and action as None.\n",
        "- If a repair action is not defined for an error it should be skipped with details as No repair action assigned and action as None.\n",
        "- Only use for loops. The use of while loops is prohibited.\n",
        "- Use asyncio to handle asynchronous tasks.\n",
        "- Cannot use timedelta to calculate time differences.\n",
        "- Cannot use concurrent.futures in the solution.\n",
        "- Log timestamp parsing must only use datetime.strptime\n",
        "- No more than one repair may be triggered per log line.\n",
        "- Use asyncio.gather to gather tasks.\n",
        "- Status summary dictionary must always include all three keys: success, failed, and skipped. Even if the count is zero, the key must exist and summary must be printed.\n",
        "- Error pattern matching must be case-sensitive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "import asyncio\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Iterable, Dict, Callable, Any, Tuple, List, Optional\n",
        "\n",
        "\n",
        "async def monitor_and_repair(\n",
        "    log_stream: Iterable[str],\n",
        "    error_patterns: Dict[str, str],\n",
        "    repair_actions: Dict[str, Optional[Callable[[], str]]],\n",
        "    config: Dict[str, Any]\n",
        ") -> Tuple[List[Dict[str, Any]], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Monitors a stream of system logs, detects errors using pattern matching,\n",
        "    and triggers asynchronous repair actions based on configurable settings.\n",
        "\n",
        "    Args:\n",
        "        log_stream (Iterable[str]): A stream of log entries (e.g., generator or list).\n",
        "        error_patterns (Dict[str, str]): Mapping of error pattern keywords to descriptions.\n",
        "        repair_actions (Dict[str, Optional[Callable[[], str]]]):\n",
        "            Mapping of error keywords to repair functions. A value of None skips repair.\n",
        "        config (Dict[str, Any]): Configuration options including:\n",
        "            - \"reactive_mode\" (bool): If False, disables automatic repair triggering.\n",
        "            - \"max_concurrent_repairs\" (int): Maximum number of concurrent repair tasks.\n",
        "            - \"log_retention_seconds\" (int): Max age of logs to be considered (in seconds).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[Dict[str, Any]], Dict[str, int]]:\n",
        "            - repair_log: List of dictionaries recording each repair attempt.\n",
        "            - summary: Dictionary with counts of 'success', 'failed', and 'skipped' repairs.\n",
        "    \"\"\"\n",
        "    semaphore = asyncio.Semaphore(config.get(\"max_concurrent_repairs\", 5))\n",
        "    repair_log: List[Dict[str, Any]] = []\n",
        "    summary = {\"success\": 0, \"failed\": 0, \"skipped\": 0}\n",
        "\n",
        "    async def handle_repair(timestamp: str, error_key: str) -> None:\n",
        "        \"\"\"\n",
        "        Handles execution of a single repair task associated with an error key.\n",
        "\n",
        "        Args:\n",
        "            timestamp (str): Timestamp of the log triggering the repair.\n",
        "            error_key (str): Keyword identifying the error.\n",
        "        \"\"\"\n",
        "        description = error_patterns[error_key]\n",
        "        action_func = repair_actions[error_key]\n",
        "\n",
        "        # If no repair function is defined, mark as skipped.\n",
        "        if not callable(action_func):\n",
        "            repair_log.append({\n",
        "                \"timestamp\": timestamp,\n",
        "                \"error\": error_key,\n",
        "                \"description\": description,\n",
        "                \"action\": None,\n",
        "                \"status\": \"skipped\",\n",
        "                \"details\": \"Invalid repair action\"\n",
        "            })\n",
        "            summary[\"skipped\"] += 1\n",
        "            return\n",
        "\n",
        "        action_name = action_func.__name__\n",
        "\n",
        "        try:\n",
        "            # Respect max concurrency using a semaphore.\n",
        "            async with semaphore:\n",
        "                result = await action_func() if asyncio.iscoroutinefunction(action_func) else action_func()\n",
        "\n",
        "                if isinstance(result, str) and (\n",
        "                    result.lower().startswith(\"no action\") or \"skipped\" in result.lower()\n",
        "                ):\n",
        "                    status = \"skipped\"\n",
        "                else:\n",
        "                    status = \"success\"\n",
        "                details = result\n",
        "\n",
        "        except Exception as e:\n",
        "            status = \"failed\"\n",
        "            details = str(e)\n",
        "\n",
        "        repair_log.append({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"error\": error_key,\n",
        "            \"description\": description,\n",
        "            \"action\": action_name,\n",
        "            \"status\": status,\n",
        "            \"details\": details\n",
        "        })\n",
        "        summary[status] += 1\n",
        "\n",
        "    async def process_logs() -> None:\n",
        "        \"\"\"\n",
        "        Processes the entire log stream, spawns repair tasks for matched error patterns.\n",
        "        \"\"\"\n",
        "        tasks = []\n",
        "\n",
        "        for line in log_stream:\n",
        "            # Parse log entry format: [timestamp] LEVEL: message\n",
        "            match = re.match(r\"\\[(.*?)\\]\\s+(ERROR|WARNING):\\s+(.*)\", line)\n",
        "            if not match:\n",
        "                continue\n",
        "\n",
        "            timestamp_str, _, message = match.groups()\n",
        "\n",
        "            try:\n",
        "                log_time = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            current_time = datetime.now()\n",
        "            if (current_time - log_time).total_seconds() > config.get(\"log_retention_seconds\", 86400):\n",
        "                continue\n",
        "\n",
        "            if not config.get(\"reactive_mode\", True):\n",
        "                continue\n",
        "\n",
        "            for pattern in error_patterns:\n",
        "                if pattern in message:\n",
        "                    if pattern in repair_actions:\n",
        "                        tasks.append(handle_repair(timestamp_str, pattern))\n",
        "                    else:\n",
        "                        # Error matches pattern but no repair action is defined\n",
        "                        repair_log.append({\n",
        "                            \"timestamp\": timestamp_str,\n",
        "                            \"error\": pattern,\n",
        "                            \"description\": error_patterns[pattern],\n",
        "                            \"action\": None,\n",
        "                            \"status\": \"skipped\",\n",
        "                            \"details\": \"No repair action assigned\"\n",
        "                        })\n",
        "                        summary[\"skipped\"] += 1\n",
        "                    break\n",
        "\n",
        "        if tasks:\n",
        "            await asyncio.gather(*tasks)\n",
        "\n",
        "    await process_logs()\n",
        "    return repair_log, summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde541d7-3df6-4bbc-f28b-65d7edf8a4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".....................\n",
            "----------------------------------------------------------------------\n",
            "Ran 21 tests in 0.031s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "# tests\n",
        "\n",
        "import unittest\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from datetime import datetime, timedelta\n",
        "from main import monitor_and_repair\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class TestReactiveLogMonitoring(unittest.TestCase):\n",
        "\n",
        "    def get_current_timestamp(self):\n",
        "        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    def get_timestamp_offset(self, seconds_offset=0):\n",
        "        return (datetime.now() + timedelta(seconds=seconds_offset)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    def run_async(self, coro):\n",
        "        loop = asyncio.get_event_loop()\n",
        "        return loop.run_until_complete(coro)\n",
        "\n",
        "    def test_basic_successful_repair(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Disk failure on /dev/sda\"]\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def restart_disk_service(): return \"Disk service restarted\"\n",
        "            repair_actions = {\"Disk failure\": restart_disk_service}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 1, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_failed_repair_with_exception(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: CPU temperature high\"]\n",
        "            error_patterns = {\"CPU temperature high\": \"Thermal warning\"}\n",
        "            def throttle_cpu(): raise PermissionError(\"Access denied\")\n",
        "            repair_actions = {\"CPU temperature high\": throttle_cpu}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 1, \"skipped\": 0})\n",
        "\n",
        "    def test_skipped_repair_no_action(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Low disk space\"]\n",
        "            error_patterns = {\"Low disk space\": \"Disk capacity alert\"}\n",
        "            def cleanup_disk(): return \"no action taken\"\n",
        "            repair_actions = {\"Low disk space\": cleanup_disk}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 1})\n",
        "\n",
        "    def test_skipped_repair_contains_skipped(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Memory leak detected\"]\n",
        "            error_patterns = {\"Memory leak\": \"Memory issue\"}\n",
        "            def fix_memory(): return \"Cleanup skipped\"\n",
        "            repair_actions = {\"Memory leak\": fix_memory}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 1})\n",
        "\n",
        "    def test_reactive_mode_disabled(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Disk failure on /dev/sda\"]\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def restart_disk_service(): return \"Service restarted\"\n",
        "            repair_actions = {\"Disk failure\": restart_disk_service}\n",
        "            config = {\"reactive_mode\": False, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_unknown_error_pattern(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Unknown system fault\"]\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def restart_service(): return \"Service restarted\"\n",
        "            repair_actions = {\"Disk failure\": restart_service}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_none_repair_action(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Database timeout\"]\n",
        "            error_patterns = {\"Database timeout\": \"DB connection issue\"}\n",
        "            repair_actions = {\"Database timeout\": None}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 1})\n",
        "\n",
        "    def test_no_repair_action_assigned(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Network timeout\"]\n",
        "            error_patterns = {\"Network timeout\": \"Connection issue\"}\n",
        "            repair_actions = {}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 1})\n",
        "\n",
        "    def test_log_retention_window_expired(self):\n",
        "        async def test():\n",
        "            old_timestamp = self.get_timestamp_offset(-400)\n",
        "            log_stream = [f\"[{old_timestamp}] ERROR: Disk failure\"]\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def restart_service(): return \"Service restarted\"\n",
        "            repair_actions = {\"Disk failure\": restart_service}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_max_concurrent_repairs_limit(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [\n",
        "                f\"[{timestamp}] ERROR: Disk failure on /dev/sda\",\n",
        "                f\"[{timestamp}] ERROR: CPU temperature high\",\n",
        "                f\"[{timestamp}] ERROR: Memory leak detected\"\n",
        "            ]\n",
        "            error_patterns = {\n",
        "                \"Disk failure\": \"Critical hardware error\",\n",
        "                \"CPU temperature high\": \"Thermal warning\",\n",
        "                \"Memory leak\": \"Memory issue\"\n",
        "            }\n",
        "            def repair(): return \"Done\"\n",
        "            repair_actions = {k: repair for k in error_patterns}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 2, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(len(repair_log), 3)\n",
        "\n",
        "    def test_multiple_error_types_mixed_outcomes(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [\n",
        "                f\"[{timestamp}] ERROR: Disk failure on /dev/sda\",\n",
        "                f\"[{timestamp}] ERROR: CPU temperature high\",\n",
        "                f\"[{timestamp}] ERROR: Low disk space\"\n",
        "            ]\n",
        "            error_patterns = {\n",
        "                \"Disk failure\": \"Critical hardware error\",\n",
        "                \"CPU temperature high\": \"Thermal warning\",\n",
        "                \"Low disk space\": \"Disk capacity alert\"\n",
        "            }\n",
        "            def disk(): return \"Disk service restarted\"\n",
        "            def cpu(): raise Exception(\"CPU control failed\")\n",
        "            def disk2(): return \"no action needed\"\n",
        "            repair_actions = {\n",
        "                \"Disk failure\": disk,\n",
        "                \"CPU temperature high\": cpu,\n",
        "                \"Low disk space\": disk2\n",
        "            }\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 5, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 1, \"failed\": 1, \"skipped\": 1})\n",
        "\n",
        "    def test_case_sensitive_error_matching(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: disk failure on /dev/sda\"]\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def restart_disk(): return \"Service restarted\"\n",
        "            repair_actions = {\"Disk failure\": restart_disk}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_maximum_log_entries_100(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{timestamp}] ERROR: Disk failure {i}\" for i in range(100)]\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def restart_disk(): return \"Service restarted\"\n",
        "            repair_actions = {\"Disk failure\": restart_disk}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 10, \"log_retention_seconds\": 3600}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(len(repair_log), 100)\n",
        "        self.assertEqual(summary[\"success\"], 100)\n",
        "\n",
        "    def test_maximum_error_patterns_50(self):\n",
        "        async def test():\n",
        "            timestamp = self.get_current_timestamp()\n",
        "            log_stream, error_patterns, repair_actions = [], {}, {}\n",
        "            def generic(): return \"Repair completed\"\n",
        "            for i in range(50):\n",
        "                key = f\"Error{i}\"\n",
        "                log_stream.append(f\"[{timestamp}] ERROR: {key} occurred\")\n",
        "                error_patterns[key] = f\"Desc {i}\"\n",
        "                repair_actions[key] = generic\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 10, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, summary = self.run_async(test())\n",
        "        self.assertEqual(len(repair_log), 50)\n",
        "        self.assertEqual(summary[\"success\"], 50)\n",
        "\n",
        "    def test_maximum_concurrent_repairs_10(self):\n",
        "        async def test():\n",
        "            base_time = datetime.now()\n",
        "            log_stream = [f\"[{(base_time + timedelta(seconds=i)).strftime('%Y-%m-%d %H:%M:%S')}] ERROR: Concurrent error {i}\" for i in range(15)]\n",
        "            error_patterns = {\"Concurrent error\": \"Test error\"}\n",
        "            def repair(): return \"Repair done\"\n",
        "            repair_actions = {\"Concurrent error\": repair}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 10, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertEqual(summary[\"success\"], 15)\n",
        "\n",
        "    def test_maximum_log_retention_3600_seconds(self):\n",
        "        async def test():\n",
        "            ts = self.get_timestamp_offset(-3600)\n",
        "            log_stream = [f\"[{ts}] ERROR: Boundary test\"]\n",
        "            error_patterns = {\"Boundary test\": \"Test at boundary\"}\n",
        "            def repair(): return \"Repair executed\"\n",
        "            repair_actions = {\"Boundary test\": repair}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 3600}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertGreaterEqual(sum(summary.values()), 0)\n",
        "\n",
        "    def test_empty_log_stream(self):\n",
        "        async def test():\n",
        "            log_stream = []\n",
        "            error_patterns = {\"Disk failure\": \"Critical hardware error\"}\n",
        "            def repair(): return \"Service restarted\"\n",
        "            repair_actions = {\"Disk failure\": repair}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_empty_error_patterns(self):\n",
        "        async def test():\n",
        "            ts = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{ts}] ERROR: Disk failure\"]\n",
        "            error_patterns, repair_actions = {}, {}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})\n",
        "\n",
        "    def test_one_repair_per_log_line(self):\n",
        "        async def test():\n",
        "            ts = self.get_current_timestamp()\n",
        "            log_stream = [f\"[{ts}] ERROR: Disk failure CPU temperature high\"]\n",
        "            error_patterns = {\"Disk failure\": \"HW\", \"CPU temperature high\": \"Thermal\"}\n",
        "            def repair1(): return \"Repair 1\"\n",
        "            def repair2(): return \"Repair 2\"\n",
        "            repair_actions = {\"Disk failure\": repair1, \"CPU temperature high\": repair2}\n",
        "            config = {\"reactive_mode\": True, \"max_concurrent_repairs\": 5, \"log_retention_seconds\": 300}\n",
        "            return await monitor_and_repair(log_stream, error_patterns, repair_actions, config)\n",
        "\n",
        "        repair_log, _ = self.run_async(test())\n",
        "        self.assertEqual(len(repair_log), 1)\n",
        "\n",
        "    def test_status_summary_always_contains_all_keys(self):\n",
        "        async def test():\n",
        "            return await monitor_and_repair([], {}, {}, {\n",
        "                \"reactive_mode\": True, \"max_concurrent_repairs\": 1, \"log_retention_seconds\": 300\n",
        "            })\n",
        "\n",
        "        _, summary = self.run_async(test())\n",
        "        self.assertEqual(summary, {\"success\": 0, \"failed\": 0, \"skipped\": 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/751d50d8-435b-486c-8f27-fe3612ef17ae?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F44712%2Fview\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "# code generated by the model\n",
        "\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from typing import Iterable, Dict, Callable, Any, Tuple, List, Optional\n",
        "\n",
        "def monitor_and_repair(\n",
        "    log_stream: Iterable[str],\n",
        "    error_patterns: Dict[str, str],\n",
        "    repair_actions: Dict[str, Optional[Callable[[], str]]],\n",
        "    config: Dict[str, Any]\n",
        ") -> Tuple[List[Dict[str, Any]], Dict[str, int]]:\n",
        "    async def handle_repair(\n",
        "        log_ts: str,\n",
        "        err: str,\n",
        "        desc: str,\n",
        "        action_func: Optional[Callable[[], str]]\n",
        "    ) -> Dict[str, Any]:\n",
        "        result = {\n",
        "            \"timestamp\": log_ts,\n",
        "            \"error\": err,\n",
        "            \"description\": desc,\n",
        "            \"action\": None,\n",
        "            \"status\": \"\",\n",
        "            \"details\": \"\"\n",
        "        }\n",
        "        if not action_func:\n",
        "            result[\"status\"] = \"skipped\"\n",
        "            result[\"details\"] = \"Invalid repair action\"\n",
        "            return result\n",
        "        result[\"action\"] = action_func.__name__\n",
        "        async with repair_semaphore:\n",
        "            try:\n",
        "                loop = asyncio.get_running_loop()\n",
        "                action_output = await loop.run_in_executor(None, action_func)\n",
        "                if action_output is None:\n",
        "                    action_output = \"\"\n",
        "                if action_output.lower().startswith(\"no action\") or \"skipped\" in action_output.lower():\n",
        "                    result[\"status\"] = \"skipped\"\n",
        "                else:\n",
        "                    result[\"status\"] = \"success\"\n",
        "                result[\"details\"] = str(action_output)\n",
        "            except Exception as e:\n",
        "                result[\"status\"] = \"failed\"\n",
        "                result[\"details\"] = str(e)\n",
        "        return result\n",
        "\n",
        "    async def process_logs() -> List[Dict[str, Any]]:\n",
        "        if not config.get(\"reactive_mode\", True):\n",
        "            return []\n",
        "        repair_events = []\n",
        "        # <Issue>: This means all logs are compared to the same timestamp, even if logs were processed over time.\n",
        "        # Over a period of time this will lead to inaccuracies.\n",
        "        now_ts = datetime.now().timestamp()\n",
        "        for line in log_stream:\n",
        "            if \"]\" not in line or \"[\" not in line:\n",
        "                continue\n",
        "            ts_str = line.split(\"]\")[0].replace(\"[\", \"\").strip()\n",
        "            try:\n",
        "                log_time = datetime.strptime(ts_str, \"%Y-%m-%d %H:%M:%S\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "            diff_seconds = now_ts - log_time.timestamp()\n",
        "            if diff_seconds > config.get(\"log_retention_seconds\", 300):\n",
        "                continue\n",
        "            triggered = False\n",
        "            for pat in error_patterns:\n",
        "                if pat in line:\n",
        "                    desc = error_patterns[pat]\n",
        "                    action_func = repair_actions.get(pat, None)\n",
        "                    task = asyncio.create_task(handle_repair(ts_str, pat, desc, action_func))\n",
        "                    tasks.append(task)\n",
        "                    triggered = True\n",
        "                    break\n",
        "            if triggered and len(tasks) >= config.get(\"max_concurrent_repairs\", 5):\n",
        "                pass\n",
        "        if tasks:\n",
        "            finished = await asyncio.gather(*tasks)\n",
        "            for res in finished:\n",
        "                repair_events.append(res)\n",
        "        return repair_events\n",
        "\n",
        "    if not isinstance(log_stream, list):\n",
        "        log_stream = list(log_stream)\n",
        "    repair_semaphore = asyncio.Semaphore(config.get(\"max_concurrent_repairs\", 5))\n",
        "    tasks: List[asyncio.Task] = []\n",
        "    results = asyncio.run(process_logs())\n",
        "    summary = {\"success\": 0, \"failed\": 0, \"skipped\": 0}\n",
        "    for r in results:\n",
        "        summary[r[\"status\"]] += 1\n",
        "    return results, summary\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}