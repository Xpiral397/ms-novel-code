{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Background Processes\n",
        "\n",
        "**L2 Taxonomy** - Job Scheduling\n",
        "\n",
        "**Subtopic** - Implementing a timeout for jobs that overrun and scheduling follow-up actions\n",
        "\n",
        "**Use Case** - Develop a Python script that schedules a list of jobs with a predetermined timeout. If a job exceeds the timeout, the script should stop the job and schedule a follow-up action. The follow-up action should involve logging the job details to a local file for further analysis. All jobs and follow-up actions should be defined as Python functions within the script.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "\n",
        "Build a Python script that schedules a list of jobs with a fixed per-job timeout. Each job is a Python function defined in the same script. When a job exceeds the timeout, stop it and immediately schedule a follow-up action that logs the job details to a local file for later analysis. For jobs that finish in time, record their result. Use only the standard library.\n",
        "\n",
        "Input comes from in-script calls to your API; there is no stdin. Jobs and the follow-up action are regular Python callables. The scheduler must run jobs one at a time with a hard timeout per job.\n",
        "\n",
        "Input format and constraints\n",
        "\n",
        "* Jobs are provided as a list of pairs (job_id: str, func: Callable[[], Any]).\n",
        "* Timeout is a positive float in seconds and applies to each job separately.\n",
        "* The follow-up action is a callable that accepts the timed-out jobâ€™s details and appends a log line to a text file.\n",
        "* All code runs on CPython, cross-platform (Windows, macOS, Linux).\n",
        "\n",
        "Expected output format\n",
        "\n",
        "* The scheduler returns a list of per-job records with fields:\n",
        "\n",
        "  * job_id (str)\n",
        "  * status in {\"ok\", \"timeout\", \"error\"}\n",
        "  * duration_sec (float, rounded or raw)\n",
        "  * result (if status == \"ok\") or error (repr of exception)\n",
        "\n",
        "Examples\n",
        "\n",
        "Jobs:\n",
        "\n",
        "```\n",
        "def slow_job():\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "    return \"done\"\n",
        "\n",
        "def fast_job():\n",
        "    return 42\n",
        "```\n",
        "\n",
        "Run:\n",
        "\n",
        "```\n",
        "records = schedule_jobs(\n",
        "    jobs=[(\"J1\", fast_job), (\"J2\", slow_job)],\n",
        "    timeout=1.0,\n",
        "    follow_up=default_follow_up_logger,\n",
        "    log_file=\"job_followups.log\",\n",
        ")\n",
        "```\n",
        "\n",
        "Sample outcomes:\n",
        "\n",
        "* For J1: status \"ok\", result 42\n",
        "* For J2: status \"timeout\", follow-up logger appends a line to job_followups.log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "### Explicit and implicit points\n",
        "\n",
        "* Enforce a hard timeout per job. Overrunning jobs must be stopped and marked \"timeout\".\n",
        "* Immediately invoke a follow-up action for timed-out jobs that appends a line to a local log file.\n",
        "* Run jobs in isolation so they can be stopped safely on timeout (use multiprocessing, not threading; do not use OS-specific signals).\n",
        "* Process jobs sequentially in input order for determinism.\n",
        "* Do not print or log from inside the scheduler except via the provided follow-up callable.\n",
        "* All jobs and the follow-up action are defined in the same script for testing.\n",
        "* Results and errors must be captured and returned in a structured list.\n",
        "\n",
        "### Solution expectations\n",
        "\n",
        "* Use multiprocessing.Process to execute each job in its own child process and multiprocessing.Queue or Pipe to collect a result or exception.\n",
        "* Use process.join(timeout) and process.terminate() to enforce the timeout. Ensure the child process is cleaned up (join after terminate).\n",
        "* Measure per-job duration with time.monotonic().\n",
        "* Implement a default follow-up that appends a single line per timeout with timestamp, job\\_id, elapsed time, and a reason string. Use append mode and ensure parent directories exist.\n",
        "* Open files with context managers. Use text mode UTF-8.\n",
        "* Make behavior deterministic and cross-platform. Guard top-level runnable code with `if __name__ == \"__main__\":` when needed.\n",
        "\n",
        "### Signatures of expected functions\n",
        "\n",
        "```python\n",
        "from collections.abc import Callable\n",
        "from typing import Any\n",
        "\n",
        "def run_job_with_timeout(func: Callable[[], Any], timeout: float) -> tuple[str, float, Any | BaseException]:\n",
        "    \"\"\"Run func in a child process with a hard timeout.\n",
        "    Returns (status, duration_sec, payload) where:\n",
        "      - status is \"ok\", \"timeout\", or \"error\"\n",
        "      - payload is result (for \"ok\") or the exception instance (for \"error\")\n",
        "    \"\"\"\n",
        "\n",
        "def default_follow_up_logger(job_id: str, reason: str, duration_sec: float, log_file: str) -> None:\n",
        "    \"\"\"Append a line describing the timed-out job to log_file.\"\"\"\n",
        "\n",
        "def schedule_jobs(\n",
        "    jobs: list[tuple[str, Callable[[], Any]]],\n",
        "    timeout: float,\n",
        "    follow_up: Callable[[str, str, float, str], None],\n",
        "    log_file: str,\n",
        ") -> list[dict]:\n",
        "    \"\"\"Run jobs sequentially with timeout and follow-up on timeout.\n",
        "    Returns a list of dicts with keys: job_id, status, duration_sec, result or error.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "### Edge case behavior\n",
        "\n",
        "* timeout <= 0 -> raise ValueError(\"invalid timeout\").\n",
        "* Empty job list -> return empty list and create no logs.\n",
        "* Job raises an exception -> status \"error\", include repr(exc) in error.\n",
        "* Job returns a non-picklable result -> treat as \"error\" (child fails to send result); include a descriptive error repr.\n",
        "* Follow-up logging path unwritable -> propagate the exception from the follow-up call.\n",
        "* Very long-running job -> must be terminated on timeout and not leak child processes.\n",
        "* Duplicate job_ids are allowed; records must preserve input order.\n",
        "\n",
        "### Constraints\n",
        "\n",
        "* Use only Python standard library: multiprocessing, time, os, io, pathlib, typing, collections.abc, traceback, json (optional for formatting), datetime.\n",
        "* No external services, daemons, or system-specific signals.\n",
        "* Time complexity is linear in number of jobs; memory use is bounded aside from job results.\n",
        "* Cross-platform: use the default start method or explicitly choose \"spawn\" where necessary.\n",
        "\n",
        "### Important notes\n",
        "\n",
        "* Validate inputs:\n",
        "\n",
        "  * jobs must be a list of (str, callable); raise ValueError(\"invalid jobs\") otherwise.\n",
        "  * timeout must be a float > 0.\n",
        "  * follow_up must be callable; log_file must be a non-empty string.\n",
        "* The scheduler must not mutate the provided job callables.\n",
        "* The follow-up action must run only for timeouts, not for ordinary errors.\n",
        "* Tests will assert deterministic ordering of records and that timed-out jobs are terminated and logged.\n",
        "* Do not rely on wall-clock time for correctness; use time.monotonic() for durations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "from collections.abc import Callable\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "from pathlib import Path\n",
        "from queue import Empty\n",
        "from typing import Any, Tuple\n",
        "import time\n",
        "\n",
        "\n",
        "def _child_worker(func: Callable[[], Any], q: Queue) -> None:\n",
        "    \"\"\"\n",
        "    Execute func and put a tuple ('ok', result) or ('error', exception_instance) into q.\n",
        "    Handles the case where the result itself is not picklable by sending a synthetic error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = func()\n",
        "        try:\n",
        "            q.put((\"ok\", result))\n",
        "        except Exception as put_error:\n",
        "            # Result not picklable or queue serialization failed.\n",
        "            q.put((\"error\", RuntimeError(\n",
        "                f\"result not picklable: {put_error!r}\")))\n",
        "    except Exception as e:\n",
        "        # Function raised; send the exception instance (usually picklable)\n",
        "        try:\n",
        "            q.put((\"error\", e))\n",
        "        except Exception as put_error:\n",
        "            # As a last resort, send a simple, picklable exception\n",
        "            q.put((\"error\", RuntimeError(\n",
        "                f\"child failed to send exception: {put_error!r}\")))\n",
        "\n",
        "\n",
        "# Public API\n",
        "def run_job_with_timeout(func: Callable[[], Any], timeout: float) -> Tuple[str, float, Any | BaseException]:\n",
        "    \"\"\"Run func in a child process with a hard timeout.\n",
        "\n",
        "    Returns (status, duration_sec, payload) where:\n",
        "      - status is \"ok\", \"timeout\", or \"error\"\n",
        "      - payload is result (for \"ok\") or the exception instance (for \"error\")\n",
        "\n",
        "    Notes:\n",
        "      - Uses multiprocessing with a top-level worker for cross-platform 'spawn'.\n",
        "      - Uses time.monotonic() for duration measurement.\n",
        "    \"\"\"\n",
        "    if not isinstance(timeout, float) or timeout <= 0.0:\n",
        "        raise ValueError(\"invalid timeout\")\n",
        "\n",
        "    q: Queue = Queue(maxsize=1)\n",
        "    p = Process(target=_child_worker, args=(func, q))\n",
        "    start = time.monotonic()\n",
        "    p.start()\n",
        "    p.join(timeout)\n",
        "    duration = time.monotonic() - start\n",
        "\n",
        "    if p.is_alive():\n",
        "        # Timeout: hard stop, ensure cleanup\n",
        "        p.terminate()\n",
        "        p.join()\n",
        "        # Parent should finalize the queue properly even on timeout.\n",
        "        q.close()\n",
        "        q.join_thread()\n",
        "        return \"timeout\", duration, None\n",
        "\n",
        "    # Child exited; retrieve outcome non-blockingly with a small timeout\n",
        "    try:\n",
        "        status, payload = q.get(timeout=1.0)\n",
        "    except Empty:\n",
        "        status, payload = \"error\", RuntimeError(\n",
        "            \"no result received from child\")\n",
        "    finally:\n",
        "        q.close()\n",
        "        q.join_thread()\n",
        "\n",
        "    return status, duration, payload\n",
        "\n",
        "\n",
        "def default_follow_up_logger(job_id: str, reason: str, duration_sec: float, log_file: str) -> None:\n",
        "    \"\"\"Append a single line describing the timed-out job to log_file.\n",
        "\n",
        "    The line includes a timestamp, job_id, elapsed time, and reason.\n",
        "    Ensures parent directories exist when the log_file includes a directory.\n",
        "    Uses UTF-8 text and context managers.\n",
        "    \"\"\"\n",
        "    if not isinstance(log_file, str) or not log_file:\n",
        "        raise ValueError(\"invalid log_file\")\n",
        "\n",
        "    p = Path(log_file)\n",
        "    # Create parent directory if present (no-op when file is in CWD)\n",
        "    if p.parent and str(p.parent) not in (\"\", \".\"):\n",
        "        p.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    line = f\"{ts} - Job ID: {job_id}, Reason: {reason}, Elapsed Time: {duration_sec:.6f} seconds\\n\"\n",
        "    with p.open(\"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(line)\n",
        "\n",
        "\n",
        "def schedule_jobs(\n",
        "    jobs: list[tuple[str, Callable[[], Any]]],\n",
        "    timeout: float,\n",
        "    follow_up: Callable[[str, str, float, str], None],\n",
        "    log_file: str,\n",
        ") -> list[dict]:\n",
        "    \"\"\"Run jobs sequentially with a per-job hard timeout and follow-up on timeouts.\n",
        "\n",
        "    Returns a list of dicts with keys: job_id, status, duration_sec, and one of:\n",
        "      - result (if status == \"ok\")\n",
        "      - error (repr of exception, if status == \"error\")\n",
        "\n",
        "    Behavior:\n",
        "      - Validates inputs as per spec.\n",
        "      - Enforces hard timeout with process.terminate() and cleanup join.\n",
        "      - Uses time.monotonic() for durations.\n",
        "      - Calls follow_up only for timeouts; exceptions propagate from follow_up.\n",
        "      - Maintains deterministic ordering of records.\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    if not isinstance(jobs, list) or not all(\n",
        "        isinstance(j, tuple) and len(j) == 2 and isinstance(\n",
        "            j[0], str) and callable(j[1])\n",
        "        for j in jobs\n",
        "    ):\n",
        "        raise ValueError(\"invalid jobs\")\n",
        "\n",
        "    if not isinstance(timeout, float) or timeout <= 0.0:\n",
        "        raise ValueError(\"invalid timeout\")\n",
        "\n",
        "    if not callable(follow_up) or not isinstance(log_file, str) or not log_file:\n",
        "        raise ValueError(\"invalid follow_up or log_file\")\n",
        "\n",
        "    records: list[dict] = []\n",
        "    if not jobs:\n",
        "        # Empty job list: return empty records and do not create logs\n",
        "        return records\n",
        "\n",
        "    for job_id, func in jobs:\n",
        "        status, duration, payload = run_job_with_timeout(func, timeout)\n",
        "        rec: dict = {\"job_id\": job_id,\n",
        "                     \"status\": status, \"duration_sec\": duration}\n",
        "\n",
        "        if status == \"ok\":\n",
        "            rec[\"result\"] = payload\n",
        "        elif status == \"error\":\n",
        "            rec[\"error\"] = repr(payload)\n",
        "        elif status == \"timeout\":\n",
        "            # Invoke follow-up immediately; exceptions propagate by design\n",
        "            follow_up(job_id, \"timeout\", duration, log_file)\n",
        "        else:\n",
        "            # Should never occur; defensive\n",
        "            rec[\"error\"] = repr(RuntimeError(f\"unknown status: {status}\"))\n",
        "\n",
        "        records.append(rec)\n",
        "\n",
        "    return records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\"\"\"\n",
        "Unit tests for job scheduling with timeout, logging, and error handling.\n",
        "\"\"\"\n",
        "\n",
        "import unittest\n",
        "import os\n",
        "import time\n",
        "import tempfile\n",
        "from typing import Callable\n",
        "from pathlib import Path\n",
        "from main import (\n",
        "    schedule_jobs,\n",
        "    default_follow_up_logger,\n",
        ")\n",
        "\n",
        "\n",
        "def fast_job() -> int:\n",
        "    \"\"\"Returns quickly with a valid result.\"\"\"\n",
        "    return 42\n",
        "\n",
        "\n",
        "def slow_job() -> str:\n",
        "    \"\"\"Sleeps for 2 seconds and returns a string.\"\"\"\n",
        "    time.sleep(2)\n",
        "    return \"done\"\n",
        "\n",
        "\n",
        "def error_job() -> None:\n",
        "    \"\"\"Raises a RuntimeError immediately.\"\"\"\n",
        "    raise RuntimeError(\"job failed\")\n",
        "\n",
        "\n",
        "def non_picklable_job() -> Callable:\n",
        "    \"\"\"Returns a lambda (non-picklable).\"\"\"\n",
        "    return lambda x: x\n",
        "\n",
        "\n",
        "class TestJobScheduler(unittest.TestCase):\n",
        "    \"\"\"Test cases for the job scheduler module.\"\"\"\n",
        "\n",
        "    def setUp(self) -> None:\n",
        "        \"\"\"Create a temporary file for logging follow-ups.\"\"\"\n",
        "        self.temp_dir = tempfile.TemporaryDirectory()\n",
        "        self.log_file = os.path.join(self.temp_dir.name, \"followup.log\")\n",
        "\n",
        "    def tearDown(self) -> None:\n",
        "        \"\"\"Cleanup the temporary directory after tests.\"\"\"\n",
        "        self.temp_dir.cleanup()\n",
        "\n",
        "    def test_fast_job_completes(self) -> None:\n",
        "        \"\"\"Fast job should complete successfully.\"\"\"\n",
        "        result = schedule_jobs(\n",
        "            jobs=[(\"job1\", fast_job)],\n",
        "            timeout=1.0,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertEqual(result[0][\"job_id\"], \"job1\")\n",
        "        self.assertEqual(result[0][\"status\"], \"ok\")\n",
        "        self.assertEqual(result[0][\"result\"], 42)\n",
        "\n",
        "    def test_slow_job_times_out(self) -> None:\n",
        "        \"\"\"Slow job should be terminated and logged on timeout.\"\"\"\n",
        "        result = schedule_jobs(\n",
        "            jobs=[(\"job2\", slow_job)],\n",
        "            timeout=0.5,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertEqual(result[0][\"status\"], \"timeout\")\n",
        "        self.assertTrue(Path(self.log_file).exists())\n",
        "\n",
        "        with open(self.log_file, encoding=\"utf-8\") as f:\n",
        "            log = f.read()\n",
        "            self.assertIn(\"job2\", log)\n",
        "            self.assertIn(\"timeout\", log)\n",
        "\n",
        "    def test_error_job_captures_exception(self) -> None:\n",
        "        \"\"\"Job that raises an exception should be recorded as error.\"\"\"\n",
        "        result = schedule_jobs(\n",
        "            jobs=[(\"job3\", error_job)],\n",
        "            timeout=1.0,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertEqual(result[0][\"status\"], \"error\")\n",
        "        self.assertIn(\"RuntimeError\", result[0][\"error\"])\n",
        "\n",
        "    def test_invalid_timeout_raises(self) -> None:\n",
        "        \"\"\"Invalid timeout should raise ValueError.\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            schedule_jobs(\n",
        "                jobs=[(\"job5\", fast_job)],\n",
        "                timeout=0,\n",
        "                follow_up=default_follow_up_logger,\n",
        "                log_file=self.log_file,\n",
        "            )\n",
        "\n",
        "    def test_empty_job_list_returns_empty(self) -> None:\n",
        "        \"\"\"An empty job list should return an empty result list.\"\"\"\n",
        "        result = schedule_jobs(\n",
        "            jobs=[],\n",
        "            timeout=1.0,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertEqual(result, [])\n",
        "\n",
        "    def test_invalid_job_format_raises(self) -> None:\n",
        "        \"\"\"Invalid job format should raise ValueError.\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            schedule_jobs(\n",
        "                jobs=[\"bad job\"],\n",
        "                timeout=1.0,\n",
        "                follow_up=default_follow_up_logger,\n",
        "                log_file=self.log_file,\n",
        "            )\n",
        "\n",
        "    def test_follow_up_logger_writes_correct_line(self) -> None:\n",
        "        \"\"\"Follow-up logger should write a valid log entry.\"\"\"\n",
        "        default_follow_up_logger(\n",
        "            job_id=\"job6\",\n",
        "            reason=\"timeout\",\n",
        "            duration_sec=2.3,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        with open(self.log_file, encoding=\"utf-8\") as f:\n",
        "            line = f.read()\n",
        "        self.assertIn(\"job6\", line)\n",
        "        self.assertIn(\"timeout\", line)\n",
        "\n",
        "    def test_multiple_jobs_mixed_status(self) -> None:\n",
        "        \"\"\"Multiple jobs should return mixed statuses correctly.\"\"\"\n",
        "        jobs = [\n",
        "            (\"job8\", fast_job),\n",
        "            (\"job9\", slow_job),\n",
        "            (\"job10\", error_job),\n",
        "        ]\n",
        "        result = schedule_jobs(\n",
        "            jobs=jobs,\n",
        "            timeout=1.0,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        statuses = [r[\"status\"] for r in result]\n",
        "        self.assertEqual(statuses, [\"ok\", \"timeout\", \"error\"])\n",
        "\n",
        "    def test_job_duration_accuracy(self) -> None:\n",
        "        \"\"\"Job duration should be a positive float.\"\"\"\n",
        "        result = schedule_jobs(\n",
        "            jobs=[(\"job11\", fast_job)],\n",
        "            timeout=1.0,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        duration = result[0][\"duration_sec\"]\n",
        "        self.assertIsInstance(duration, float)\n",
        "        self.assertGreater(duration, 0.0)\n",
        "\n",
        "    def test_duplicate_job_ids_allowed(self) -> None:\n",
        "        \"\"\"Duplicate job IDs are allowed and results preserved in order.\"\"\"\n",
        "        jobs = [(\"job12\", fast_job), (\"job12\", slow_job)]\n",
        "        result = schedule_jobs(\n",
        "            jobs=jobs,\n",
        "            timeout=0.5,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertEqual(len(result), 2)\n",
        "        self.assertEqual(result[0][\"status\"], \"ok\")\n",
        "        self.assertEqual(result[1][\"status\"], \"timeout\")\n",
        "\n",
        "    def test_log_file_created_only_on_timeout(self) -> None:\n",
        "        \"\"\"Log file should not exist if no timeouts occurred.\"\"\"\n",
        "        schedule_jobs(\n",
        "            jobs=[(\"job13\", fast_job)],\n",
        "            timeout=1.0,\n",
        "            follow_up=default_follow_up_logger,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertFalse(Path(self.log_file).exists())\n",
        "\n",
        "    def test_custom_follow_up_called_on_timeout(self) -> None:\n",
        "        \"\"\"Custom follow-up should be invoked only on timeout.\"\"\"\n",
        "\n",
        "        self.called = False\n",
        "\n",
        "        def mock_follow_up(job_id: str, reason: str,\n",
        "                           duration_sec: float, log_file: str) -> None:\n",
        "            self.called = True\n",
        "            self.assertEqual(job_id, \"job14\")\n",
        "            self.assertEqual(reason, \"timeout\")\n",
        "            self.assertTrue(duration_sec >= 0.5)\n",
        "\n",
        "        schedule_jobs(\n",
        "            jobs=[(\"job14\", slow_job)],\n",
        "            timeout=0.5,\n",
        "            follow_up=mock_follow_up,\n",
        "            log_file=self.log_file,\n",
        "        )\n",
        "        self.assertTrue(self.called)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/20e1ecc0-ac56-484e-9e75-f847f770f3b5\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "import os\n",
        "import time\n",
        "import traceback  # <Issue> Unused import. Harmless, but should be removed for cleanliness.</Issue>\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "from collections.abc import Callable\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "def run_job_with_timeout(func: Callable[[], Any], timeout: float) -> tuple[str, float, Any | BaseException]:\n",
        "    \"\"\"Run func in a child process with a hard timeout.\n",
        "    Returns (status, duration_sec, payload) where:\n",
        "      - status is \"ok\", \"timeout\", or \"error\"\n",
        "      - payload is result (for \"ok\") or the exception instance (for \"error\")\n",
        "    \"\"\"\n",
        "    def target_func(q):\n",
        "        try:\n",
        "            result = func()\n",
        "            q.put(('ok', result))\n",
        "        except Exception as e:\n",
        "            q.put(('error', e))  # <Issue> If the first put fails due to non-picklable result, this second put can also fail; parent later blocks on queue.get(). Add timeout and a fallback error in parent, and consider a nested try/except here.</Issue>\n",
        "    \n",
        "    queue = Queue()\n",
        "    process = Process(target=target_func, args=(queue,))\n",
        "    start_time = time.monotonic()\n",
        "    process.start()\n",
        "    process.join(timeout)\n",
        "    \n",
        "    duration_sec = time.monotonic() - start_time\n",
        "    \n",
        "    if process.is_alive():\n",
        "        process.terminate()\n",
        "        process.join()\n",
        "        return \"timeout\", duration_sec, None  # <Issue> Missing queue.close()/join_thread(). Also OK to return None payload for timeout.</Issue>\n",
        "    \n",
        "    status, payload = queue.get()  # <Issue> Blocking get() without timeout can deadlock if child failed to put anything.</Issue>\n",
        "    return status, duration_sec, payload\n",
        "\n",
        "\n",
        "def default_follow_up_logger(job_id: str, reason: str, duration_sec: float, log_file: str) -> None:\n",
        "    \"\"\"Append a line describing the timed-out job to log_file.\"\"\"\n",
        "    os.makedirs(os.path.dirname(log_file), exist_ok=True)  # <Issue> If log_file has no directory (e.g., \"log.txt\"), dirname is \"\", and makedirs(\"\") raises FileNotFoundError. Should be conditional or use pathlib.</Issue>\n",
        "    with open(log_file, 'a', encoding='utf-8') as file:\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        file.write(f\"{timestamp} - Job ID: {job_id}, Reason: {reason}, Elapsed Time: {duration_sec:.2f} seconds\\n\")\n",
        "\n",
        "\n",
        "def schedule_jobs(\n",
        "    jobs: list[tuple[str, Callable[[], Any]]],\n",
        "    timeout: float,\n",
        "    follow_up: Callable[[str, str, float, str], None],\n",
        "    log_file: str,\n",
        ") -> list[dict]:\n",
        "    \"\"\"Run jobs sequentially with timeout and follow-up on timeout.\n",
        "    Returns a list of dicts with keys: job_id, status, duration_sec, result or error.\n",
        "    \"\"\"\n",
        "    if not isinstance(jobs, list) or not all(isinstance(job, tuple) and len(job) == 2 and isinstance(job[0], str) and callable(job[1]) for job in jobs):\n",
        "        raise ValueError(\"invalid jobs\")\n",
        "    \n",
        "    if not isinstance(timeout, float) or timeout <= 0:\n",
        "        raise ValueError(\"invalid timeout\")  # <Issue> Strict float check matches spec; optionally accept ints and cast for usability, but not required.</Issue>\n",
        "    \n",
        "    if not (callable(follow_up) and isinstance(log_file, str) and log_file):\n",
        "        raise ValueError(\"invalid follow_up or log_file\")\n",
        "    \n",
        "    records = []\n",
        "    \n",
        "    for job_id, func in jobs:\n",
        "        status, duration, result = run_job_with_timeout(func, timeout)\n",
        "        \n",
        "        record = {'job_id': job_id, 'status': status, 'duration_sec': duration}\n",
        "        \n",
        "        if status == \"ok\":\n",
        "            record['result'] = result\n",
        "        elif status == \"error\":\n",
        "            record['error'] = repr(result)\n",
        "        elif status == \"timeout\":\n",
        "            follow_up(job_id, \"timeout\", duration, log_file)  # <Issue> OK; but if follow-up raises due to path bug above, exception should propagate (per spec). Fix the logger.</Issue>\n",
        "        \n",
        "        records.append(record)\n",
        "    \n",
        "    return records\n",
        "\n",
        "# Example job functions and usage\n",
        "\n",
        "def slow_job():\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "    return \"done\"\n",
        "\n",
        "def fast_job():\n",
        "    return 42\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    records = schedule_jobs(\n",
        "        jobs=[(\"J1\", fast_job), (\"J2\", slow_job)],\n",
        "        timeout=1.0,\n",
        "        follow_up=default_follow_up_logger,\n",
        "        log_file=\"job_followups.log\",\n",
        "    )\n",
        "    print(records)  # <Issue> Outside the scheduler, allowed by spec. Keep guarded by __main__.</Issue>\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}