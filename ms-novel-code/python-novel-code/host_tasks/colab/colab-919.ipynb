{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Backend Integration\n",
        "\n",
        "**L2 Taxonomy** - API Integration\n",
        "\n",
        "**Subtopic** - Using GraphQL introspection from Python to adapt to API schema changes\n",
        "\n",
        "**Use Case** - Develop a Python module that uses GraphQL introspection to fetch the schema of a GraphQL API and adapt to any changes in the schema. The module should be able to handle changes in the API schema such as addition or removal of fields, changes in data types, and deprecation of fields. The module should use only standard Python libraries and packages from PyPI, and should not require any external infrastructure.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "requests==2.32.4\n",
        "urllib3==2.5.0\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "## Problem Description\n",
        "You have been asked to build a *self-adapting* Python module that can talk to any GraphQL server whose schema may evolve at runtime.  \n",
        "The module must:\n",
        "\n",
        "1. Issue the standard GraphQL introspection query to fetch the complete schema as JSON.  \n",
        "2. Parse that schema and hold an in-memory representation of all object types, fields, arguments and their nullability.  \n",
        "3. Generate and execute dynamic read queries that always include every scalar field of a chosen object type, even when the server adds or removes fields later.  \n",
        "4. Detect server-side schema changes and refresh its internal model without restarting the process.  \n",
        "5. Offer a minimal public API so callers can request  \n",
        "   \"give me all scalar fields of type *X* where *id* = *Y*\" without writing GraphQL by hand.\n",
        "\n",
        "The deliverable is a single importable file named main.py. Importing the module must perform *zero* network or file I/O; all side effects happen only inside public functions.\n",
        "\n",
        "## Input Format\n",
        "Caller code passes:\n",
        "\n",
        "* endpoint_url – HTTPS GraphQL endpoint  \n",
        "* optional headers – dict of extra HTTP headers (auth tokens etc.)  \n",
        "* object_type – a type name found in the schema  \n",
        "* filter – dict such as {\"id\": 42}  \n",
        "\n",
        "Your module then:\n",
        "\n",
        "1. POSTS the introspection query (unless a fresh schema is already cached in memory).  \n",
        "2. Builds the read query string in deterministic field order.  \n",
        "3. Executes the query and returns the JSON *data* section.\n",
        "\n",
        "## Output Format\n",
        "* On success return a native Python dict equal to response[\"data\"].  \n",
        "* On any error raise GraphQLAdaptiveError.  \n",
        "* The module must never print to stdout or stderr except in the example below.\n",
        "\n",
        "## Example\n",
        "```python\n",
        "from main import AdaptiveClient, GraphQLAdaptiveError\n",
        "\n",
        "client = AdaptiveClient(\n",
        "    endpoint=\"https://api.example.com/graphql\",\n",
        "    headers={\"Authorization\": \"Bearer abc123\"},\n",
        "    refresh_interval_seconds=300      # auto refresh schema every 5 min\n",
        ")\n",
        "\n",
        "try:\n",
        "    product = client.fetch_by_id(object_type=\"Product\", object_id=17)\n",
        "    print(product)   # {'id': 17, 'name': 'Widget', 'price': 12.5, ...}\n",
        "except GraphQLAdaptiveError as err:\n",
        "    print(\"GraphQL call failed:\", err)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "## Explicit Requirements\n",
        "* Libraries – only Python 3.8 standard library plus the third-party package requests. No other dependencies.\n",
        "* Class design\n",
        "  * class AdaptiveClient with constructor  \n",
        "    __init__(endpoint: str, headers: dict | None = None, refresh_interval_seconds: int = 0)\n",
        "  * Public methods  \n",
        "    * refresh_schema(force: bool = False) -> None  \n",
        "      Perform introspection if the refresh interval has expired or force is True.  \n",
        "    * fetch_by_id(object_type: str, object_id: int | str) -> dict  \n",
        "      Build a query selecting every scalar field (and nested scalars of immediate non-nullable object fields) and return one record.  \n",
        "    * run_raw(query: str, variables: dict | None = None) -> dict – low-level escape hatch.\n",
        "* Schema cache\n",
        "  * Store the last introspection result plus a timestamp in memory only.  \n",
        "  * Respect refresh_interval_seconds; zero disables automatic refresh.  \n",
        "  * Compare SHA-256 of the raw introspection JSON; rebuild internal structures if the hash changes.\n",
        "* Dynamic query generation\n",
        "  * Scalars include built-ins Int, Float, String, Boolean, ID plus custom scalars that map to JSON primitives.  \n",
        "  * Ignore fields that require arguments other than id.  \n",
        "  * Keep field order alphabetical so that generated query strings are deterministic.\n",
        "* Networking\n",
        "  * Use a single requests.Session with keep-alive per AdaptiveClient instance.  \n",
        "  * Add Content-Type: application/json automatically.  \n",
        "  * Follow up to three HTTP redirects while preserving headers.  \n",
        "  * On status 429 or 503 back off and retry up to three times with delays 1 sec, 2 sec, 4 sec.\n",
        "* Error handling\n",
        "  * Define class GraphQLAdaptiveError(Exception).  \n",
        "  * Raise on network failure, top-level \"errors\" from GraphQL, unknown object_type, or schema hash mismatch after a refresh.\n",
        "* Performance\n",
        "  * A single schema refresh (up to 1 MB JSON) must complete within 5 seconds.  \n",
        "  * fetch_by_id must build its query in O(n) where n is the number of fields in the type.\n",
        "* Logging\n",
        "  * Use logging at INFO.  \n",
        "  * Log every schema refresh, generated query string, variables, and total latency in milliseconds.\n",
        "* File layout\n",
        "  * Single file main.py, no more than 400 logical lines (comments excluded).  \n",
        "  * Importing must not trigger network access, disk reads, or logging.\n",
        "\n",
        "## Implicit Requirements\n",
        "* HTTPS only; abort if the endpoint URL is not https://.\n",
        "* Deterministic behavior – identical inputs yield byte-for-byte identical GraphQL queries.\n",
        "* Respect caller-supplied headers on every request.\n",
        "* Use json.dumps(separators=(\",\", \":\")) for deterministic payloads.\n",
        "* All timestamps in logs are UTC ISO-8601 with trailing Z.\n",
        "* Unit-test friendly: if environment variable ADAPTIVE_GQL_OFFLINE=1 is set, skip network calls and raise GraphQLAdaptiveError.\n",
        "\n",
        "## Edge Cases\n",
        "* Server drops a custom scalar – treat as String without failing.\n",
        "* Field removed between refreshes – detect on next access, raise GraphQLAdaptiveError.\n",
        "* Introspection disabled on the server – raise with clear message.\n",
        "* Network throttled to 50 KiB per second – still meet time limits.\n",
        "* Enforce peak resident set size under 200 MB.\n",
        "\n",
        "## Constraints\n",
        "* No interactive prompts or input() calls.\n",
        "* Works unchanged on CPython 3.8 through 3.12.\n",
        "* Never write to disk or create temp files.\n",
        "\n",
        "## Function and Class Signatures\n",
        "```python\n",
        "class GraphQLAdaptiveError(Exception): ...\n",
        "\n",
        "class AdaptiveClient:\n",
        "    def __init__(self,\n",
        "                 endpoint: str,\n",
        "                 headers: dict | None = None,\n",
        "                 refresh_interval_seconds: int = 0): ...\n",
        "\n",
        "    def refresh_schema(self, force: bool = False) -> None: ...\n",
        "\n",
        "    def fetch_by_id(self,\n",
        "                    object_type: str,\n",
        "                    object_id: int | str) -> dict: ...\n",
        "\n",
        "    def run_raw(self,\n",
        "                query: str,\n",
        "                variables: dict | None = None) -> dict: ...\n",
        "```\n",
        "\n",
        "## Important Notes\n",
        "\n",
        "The grading harness may:\n",
        "\n",
        "* Mock the endpoint to return evolving schemas with fields reordered.\n",
        "* Inject random network delays and bandwidth limits.\n",
        "* Use the resource module to check peak RSS.\n",
        "\n",
        "Your implementation should handle all of these without timeouts, memory leaks, or nondeterministic output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import hashlib\n",
        "import logging\n",
        "from datetime import datetime, timezone\n",
        "from typing import Set, Union\n",
        "\n",
        "import requests\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "# Configure logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class GraphQLAdaptiveError(Exception):\n",
        "    \"\"\"Raised for any GraphQL adaptive client error.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class AdaptiveClient:\n",
        "    \"\"\"Self-adapting GraphQL client that handles evolving schemas.\"\"\"\n",
        "\n",
        "    INTROSPECTION_QUERY = \"\"\"\n",
        "    query IntrospectionQuery {\n",
        "      __schema {\n",
        "        queryType { name }\n",
        "        mutationType { name }\n",
        "        subscriptionType { name }\n",
        "        types {\n",
        "          kind\n",
        "          name\n",
        "          description\n",
        "          fields(includeDeprecated: true) {\n",
        "            name\n",
        "            description\n",
        "            args {\n",
        "              name\n",
        "              type { ...TypeRef }\n",
        "              defaultValue\n",
        "            }\n",
        "            type { ...TypeRef }\n",
        "            isDeprecated\n",
        "            deprecationReason\n",
        "          }\n",
        "          inputFields {\n",
        "            name\n",
        "            description\n",
        "            type { ...TypeRef }\n",
        "            defaultValue\n",
        "          }\n",
        "          interfaces { ...TypeRef }\n",
        "          enumValues(includeDeprecated: true) {\n",
        "            name\n",
        "            description\n",
        "            isDeprecated\n",
        "            deprecationReason\n",
        "          }\n",
        "          possibleTypes { ...TypeRef }\n",
        "        }\n",
        "        directives {\n",
        "          name\n",
        "          description\n",
        "          locations\n",
        "          args {\n",
        "            name\n",
        "            description\n",
        "            type { ...TypeRef }\n",
        "            defaultValue\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    fragment TypeRef on __Type {\n",
        "      kind\n",
        "      name\n",
        "      ofType {\n",
        "        kind\n",
        "        name\n",
        "        ofType {\n",
        "          kind\n",
        "          name\n",
        "          ofType {\n",
        "            kind\n",
        "            name\n",
        "            ofType {\n",
        "              kind\n",
        "              name\n",
        "              ofType {\n",
        "                kind\n",
        "                name\n",
        "                ofType {\n",
        "                  kind\n",
        "                  name\n",
        "                  ofType {\n",
        "                    kind\n",
        "                    name\n",
        "                  }\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    SCALAR_TYPES = {\n",
        "        'Int', 'Float', 'String', 'Boolean', 'ID'\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 endpoint: str,\n",
        "                 headers: dict | None = None,\n",
        "                 refresh_interval_seconds: int = 0):\n",
        "        \"\"\"Initialize the adaptive GraphQL client.\"\"\"\n",
        "        if not endpoint.startswith('https://'):\n",
        "            raise GraphQLAdaptiveError(\"Endpoint must use HTTPS\")\n",
        "\n",
        "        self._endpoint = endpoint\n",
        "        self._headers = headers or {}\n",
        "        self._refresh_interval = refresh_interval_seconds\n",
        "\n",
        "        # Schema cache\n",
        "        self._schema_raw = None\n",
        "        self._schema_hash = None\n",
        "        self._schema_timestamp = 0\n",
        "        self._schema_types = {}\n",
        "\n",
        "        # Setup session with retry strategy\n",
        "        self._session = self._create_session()\n",
        "\n",
        "    def _create_session(self) -> requests.Session:\n",
        "        \"\"\"Create requests session with retry logic and proper configuration.\"\"\"\n",
        "        session = requests.Session()\n",
        "\n",
        "        # Configure retry strategy for 429 and 503 only\n",
        "        retry_strategy = Retry(\n",
        "            total=3,\n",
        "            status_forcelist=[429, 503],\n",
        "            backoff_factor=1,  # 1s, 2s, 4s progression\n",
        "            raise_on_status=False\n",
        "        )\n",
        "\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount('https://', adapter)\n",
        "\n",
        "        # Set default headers\n",
        "        session.headers.update({\n",
        "            'Content-Type': 'application/json',\n",
        "            **self._headers\n",
        "        })\n",
        "\n",
        "        return session\n",
        "\n",
        "    def _check_offline_mode(self) -> None:\n",
        "        \"\"\"Check if offline mode is enabled via environment variable.\"\"\"\n",
        "        if os.environ.get('ADAPTIVE_GQL_OFFLINE') == '1':\n",
        "            raise GraphQLAdaptiveError(\n",
        "                \"Offline mode enabled - network calls disabled\")\n",
        "\n",
        "    def _should_refresh_schema(self, force: bool) -> bool:\n",
        "        \"\"\"Determine if schema should be refreshed.\"\"\"\n",
        "        if force:\n",
        "            return True\n",
        "\n",
        "        if self._schema_raw is None:\n",
        "            return True\n",
        "\n",
        "        if self._refresh_interval == 0:\n",
        "            return False\n",
        "\n",
        "        elapsed = time.time() - self._schema_timestamp\n",
        "        return elapsed >= self._refresh_interval\n",
        "\n",
        "    def _execute_request(self, payload: dict) -> dict:\n",
        "        \"\"\"Execute GraphQL request with proper error handling.\"\"\"\n",
        "        self._check_offline_mode()\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            response = self._session.post(\n",
        "                self._endpoint,\n",
        "                json=payload,\n",
        "                timeout=5.0\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "\n",
        "            result = response.json()\n",
        "\n",
        "            # Check for GraphQL errors\n",
        "            if 'errors' in result:\n",
        "                error_msg = '; '.join(err.get('message', 'Unknown error')\n",
        "                                      for err in result['errors'])\n",
        "                raise GraphQLAdaptiveError(f\"GraphQL errors: {error_msg}\")\n",
        "\n",
        "            if 'data' not in result:\n",
        "                raise GraphQLAdaptiveError(\"No data in GraphQL response\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise GraphQLAdaptiveError(f\"Network error: {e}\")\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise GraphQLAdaptiveError(f\"Invalid JSON response: {e}\")\n",
        "        finally:\n",
        "            duration_ms = (time.time() - start_time) * 1000\n",
        "            logger.info(f\"GraphQL request completed in {duration_ms:.2f}ms\")\n",
        "\n",
        "    def _compute_schema_hash(self, schema_data: dict) -> str:\n",
        "        \"\"\"Compute SHA-256 hash of schema data.\"\"\"\n",
        "        schema_json = json.dumps(\n",
        "            schema_data, separators=(',', ':'), sort_keys=True)\n",
        "        return hashlib.sha256(schema_json.encode('utf-8')).hexdigest()\n",
        "\n",
        "    def _parse_type_ref(self, type_ref: dict) -> tuple[str, bool]:\n",
        "        \"\"\"Parse GraphQL type reference to get type name and nullability.\"\"\"\n",
        "        if type_ref['kind'] == 'NON_NULL':\n",
        "            inner_type, _ = self._parse_type_ref(type_ref['ofType'])\n",
        "            return inner_type, False  # Non-nullable\n",
        "        elif type_ref['kind'] == 'LIST':\n",
        "            inner_type, nullable = self._parse_type_ref(type_ref['ofType'])\n",
        "            return f\"[{inner_type}]\", True  # Lists are nullable by default\n",
        "        else:\n",
        "            return type_ref['name'], True  # Nullable\n",
        "\n",
        "    def _is_scalar_type(self, type_name: str) -> bool:\n",
        "        \"\"\"Check if a type is a scalar type.\"\"\"\n",
        "        if type_name in self.SCALAR_TYPES:\n",
        "            return True\n",
        "\n",
        "        # Check if it's a custom scalar\n",
        "        type_info = self._schema_types.get(type_name, {})\n",
        "        return type_info.get('kind') == 'SCALAR'\n",
        "\n",
        "    def _parse_schema(self, schema_data: dict) -> None:\n",
        "        \"\"\"Parse introspection schema into internal representation.\"\"\"\n",
        "        self._schema_types = {}\n",
        "\n",
        "        for type_def in schema_data['__schema']['types']:\n",
        "            type_name = type_def['name']\n",
        "\n",
        "            # Skip GraphQL internal types\n",
        "            if type_name.startswith('__'):\n",
        "                continue\n",
        "\n",
        "            parsed_type = {\n",
        "                'kind': type_def['kind'],\n",
        "                'name': type_name,\n",
        "                'fields': {}\n",
        "            }\n",
        "\n",
        "            # Parse fields for OBJECT and INTERFACE types\n",
        "            if type_def['kind'] in ('OBJECT', 'INTERFACE') and type_def.get('fields'):\n",
        "                for field in type_def['fields']:\n",
        "                    field_name = field['name']\n",
        "                    field_type, nullable = self._parse_type_ref(field['type'])\n",
        "\n",
        "                    # Check if field requires arguments (other than id)\n",
        "                    args = field.get('args', [])\n",
        "                    requires_args = any(arg['name'] != 'id' for arg in args)\n",
        "\n",
        "                    parsed_type['fields'][field_name] = {\n",
        "                        'type': field_type,\n",
        "                        'nullable': nullable,\n",
        "                        'requires_args': requires_args\n",
        "                    }\n",
        "\n",
        "            self._schema_types[type_name] = parsed_type\n",
        "\n",
        "    def refresh_schema(self, force: bool = False) -> None:\n",
        "        \"\"\"Refresh schema from GraphQL endpoint.\"\"\"\n",
        "        if not self._should_refresh_schema(force):\n",
        "            return\n",
        "\n",
        "        start_time = time.time()\n",
        "        timestamp_str = datetime.now(\n",
        "            timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "\n",
        "        logger.info(f\"Starting schema refresh at {timestamp_str}\")\n",
        "\n",
        "        payload = {\n",
        "            'query': self.INTROSPECTION_QUERY,\n",
        "            'variables': {}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            result = self._execute_request(payload)\n",
        "            schema_data = result['data']\n",
        "\n",
        "            # Check if schema actually changed\n",
        "            new_hash = self._compute_schema_hash(schema_data)\n",
        "\n",
        "            if self._schema_hash and self._schema_hash != new_hash:\n",
        "                logger.info(\n",
        "                    \"Schema hash changed - rebuilding internal structures\")\n",
        "            elif self._schema_hash == new_hash:\n",
        "                logger.info(\"Schema unchanged - using cached structures\")\n",
        "                self._schema_timestamp = time.time()\n",
        "                return\n",
        "\n",
        "            # Parse and store new schema\n",
        "            self._parse_schema(schema_data)\n",
        "            self._schema_raw = schema_data\n",
        "            self._schema_hash = new_hash\n",
        "            self._schema_timestamp = time.time()\n",
        "\n",
        "            duration_ms = (time.time() - start_time) * 1000\n",
        "            logger.info(f\"Schema refresh completed in {duration_ms:.2f}ms\")\n",
        "\n",
        "        except Exception as e:\n",
        "            if isinstance(e, GraphQLAdaptiveError):\n",
        "                if \"Introspection\" in str(e):\n",
        "                    raise GraphQLAdaptiveError(\n",
        "                        \"GraphQL introspection is disabled on this server\")\n",
        "                raise\n",
        "            raise GraphQLAdaptiveError(f\"Schema refresh failed: {e}\")\n",
        "\n",
        "    def _build_scalar_query(self, object_type: str, visited: Set[str] = None) -> str:\n",
        "        \"\"\"Build query string for all scalar fields of an object type.\"\"\"\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "\n",
        "        if object_type in visited:\n",
        "            return \"\"  # Prevent infinite recursion\n",
        "\n",
        "        visited.add(object_type)\n",
        "\n",
        "        type_info = self._schema_types.get(object_type)\n",
        "        if not type_info:\n",
        "            raise GraphQLAdaptiveError(f\"Unknown object type: {object_type}\")\n",
        "\n",
        "        if type_info['kind'] not in ('OBJECT', 'INTERFACE'):\n",
        "            raise GraphQLAdaptiveError(f\"Type {object_type} is not queryable\")\n",
        "\n",
        "        fields = []\n",
        "\n",
        "        # Get all fields in alphabetical order for deterministic output\n",
        "        for field_name in sorted(type_info['fields'].keys()):\n",
        "            field_info = type_info['fields'][field_name]\n",
        "\n",
        "            # Skip fields that require arguments (except id)\n",
        "            if field_info['requires_args']:\n",
        "                continue\n",
        "\n",
        "            field_type = field_info['type']\n",
        "\n",
        "            # Handle list types\n",
        "            if field_type.startswith('[') and field_type.endswith(']'):\n",
        "                inner_type = field_type[1:-1]\n",
        "                if self._is_scalar_type(inner_type):\n",
        "                    fields.append(field_name)\n",
        "            elif self._is_scalar_type(field_type):\n",
        "                # Direct scalar field\n",
        "                fields.append(field_name)\n",
        "            elif not field_info['nullable']:\n",
        "                # Non-nullable object field - include nested scalars\n",
        "                try:\n",
        "                    nested_query = self._build_scalar_query(\n",
        "                        field_type, visited.copy())\n",
        "                    if nested_query:\n",
        "                        fields.append(f\"{field_name} {{ {nested_query} }}\")\n",
        "                except GraphQLAdaptiveError:\n",
        "                    # Skip if nested type not found or not queryable\n",
        "                    pass\n",
        "\n",
        "        return ' '.join(fields)\n",
        "\n",
        "    def fetch_by_id(self, object_type: str, object_id: Union[int, str]) -> dict:\n",
        "        \"\"\"Fetch object by ID with all scalar fields.\"\"\"\n",
        "        # Ensure schema is fresh\n",
        "        self.refresh_schema()\n",
        "\n",
        "        # Build the query\n",
        "        scalar_fields = self._build_scalar_query(object_type)\n",
        "        if not scalar_fields:\n",
        "            raise GraphQLAdaptiveError(\n",
        "                f\"No queryable scalar fields found for type {object_type}\")\n",
        "\n",
        "        query = f\"\"\"\n",
        "        query FetchById($id: ID!) {{\n",
        "          {object_type.lower()}(id: $id) {{\n",
        "            {scalar_fields}\n",
        "          }}\n",
        "        }}\n",
        "        \"\"\".strip()\n",
        "\n",
        "        variables = {'id': str(object_id)}\n",
        "\n",
        "        # Log the generated query\n",
        "        query_compact = ' '.join(query.split())\n",
        "        logger.info(f\"Generated query: {query_compact}\")\n",
        "        logger.info(\n",
        "            f\"Variables: {json.dumps(variables, separators=(',', ':'))}\")\n",
        "\n",
        "        result = self.run_raw(query, variables)\n",
        "\n",
        "        # Extract the specific object from response\n",
        "        data = result.get('data', {})\n",
        "        object_data = data.get(object_type.lower())\n",
        "\n",
        "        if object_data is None:\n",
        "            raise GraphQLAdaptiveError(\n",
        "                f\"No {object_type} found with id {object_id}\")\n",
        "\n",
        "        return object_data\n",
        "\n",
        "    def run_raw(self, query: str, variables: dict | None = None) -> dict:\n",
        "        \"\"\"Execute raw GraphQL query.\"\"\"\n",
        "        payload = {\n",
        "            'query': query,\n",
        "            'variables': variables or {}\n",
        "        }\n",
        "\n",
        "        # Use deterministic JSON serialization\n",
        "        payload_json = json.dumps(\n",
        "            payload, separators=(',', ':'), sort_keys=True)\n",
        "        logger.info(f\"Executing query with payload: {payload_json}\")\n",
        "\n",
        "        return self._execute_request(payload)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\"\"\"Unit tests for the AdaptiveClient class interact with a GraphQL endpoint.\"\"\"\n",
        "\n",
        "import unittest\n",
        "from unittest.mock import patch\n",
        "from main import AdaptiveClient, GraphQLAdaptiveError\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "class TestAdaptiveClient(unittest.TestCase):\n",
        "    \"\"\"Test cases for the AdaptiveClient class.\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up an AdaptiveClient instance for testing.\"\"\"\n",
        "        self.endpoint = \"https://example.com/graphql\"\n",
        "        self.client = AdaptiveClient(endpoint=self.endpoint)\n",
        "\n",
        "    def test_invalid_endpoint_scheme(self):\n",
        "        \"\"\"Test that an insecure HTTP endpoint raises an error.\"\"\"\n",
        "        with self.assertRaises(GraphQLAdaptiveError):\n",
        "            AdaptiveClient(\"http://insecure.com/graphql\")\n",
        "\n",
        "    def test_session_headers_applied(self):\n",
        "        \"\"\"Test that custom headers are applied to the session.\"\"\"\n",
        "        client = AdaptiveClient(self.endpoint, headers={\"X-Test\": \"1\"})\n",
        "        self.assertEqual(client._session.headers[\"X-Test\"], \"1\")\n",
        "        self.assertEqual(client._session.headers[\"Content-Type\"],\n",
        "                         \"application/json\")\n",
        "\n",
        "    def test_offline_mode_detection(self):\n",
        "        \"\"\"Test that offline mode is respected via environment variable.\"\"\"\n",
        "        os.environ[\"ADAPTIVE_GQL_OFFLINE\"] = \"1\"\n",
        "        with self.assertRaises(GraphQLAdaptiveError):\n",
        "            self.client._check_offline_mode()\n",
        "        os.environ[\"ADAPTIVE_GQL_OFFLINE\"] = \"0\"\n",
        "\n",
        "    def test_should_refresh_schema_first_time(self):\n",
        "        \"\"\"Test that schema refresh is needed when none is loaded yet.\"\"\"\n",
        "        self.assertTrue(self.client._should_refresh_schema(force=False))\n",
        "\n",
        "    def test_should_refresh_schema_force(self):\n",
        "        \"\"\"Test forced schema refresh.\"\"\"\n",
        "        self.client._schema_raw = {\"dummy\": True}\n",
        "        self.assertTrue(self.client._should_refresh_schema(force=True))\n",
        "\n",
        "    def test_should_refresh_schema_interval_elapsed(self):\n",
        "        \"\"\"Test schema refresh when interval has elapsed.\"\"\"\n",
        "        self.client._refresh_interval = 1\n",
        "        self.client._schema_raw = {\"x\": \"y\"}\n",
        "        self.client._schema_timestamp = time.time() - 2\n",
        "        self.assertTrue(self.client._should_refresh_schema(force=False))\n",
        "\n",
        "    def test_should_not_refresh_schema_when_cached(self):\n",
        "        \"\"\"Test no schema refresh when data is fresh and cached.\"\"\"\n",
        "        self.client._refresh_interval = 10\n",
        "        self.client._schema_raw = {\"x\": \"y\"}\n",
        "        self.client._schema_timestamp = time.time()\n",
        "        self.assertFalse(self.client._should_refresh_schema(force=False))\n",
        "\n",
        "    def test_compute_schema_hash_consistency(self):\n",
        "        \"\"\"Test that hashing the same schema twice gives the same hash.\"\"\"\n",
        "        schema = {\"types\": [{\"name\": \"A\"}]}\n",
        "        h1 = self.client._compute_schema_hash(schema)\n",
        "        h2 = self.client._compute_schema_hash(schema)\n",
        "        self.assertEqual(h1, h2)\n",
        "\n",
        "    def test_parse_type_ref_scalar(self):\n",
        "        \"\"\"Test parsing of scalar type reference.\"\"\"\n",
        "        ref = {\"kind\": \"SCALAR\", \"name\": \"String\"}\n",
        "        name, nullable = self.client._parse_type_ref(ref)\n",
        "        self.assertEqual(name, \"String\")\n",
        "        self.assertTrue(nullable)\n",
        "\n",
        "    def test_parse_type_ref_non_null(self):\n",
        "        \"\"\"Test parsing of non-null wrapped scalar reference.\"\"\"\n",
        "        ref = {\"kind\": \"NON_NULL\", \"ofType\": {\"kind\": \"SCALAR\", \"name\": \"Int\"}}\n",
        "        name, nullable = self.client._parse_type_ref(ref)\n",
        "        self.assertEqual(name, \"Int\")\n",
        "        self.assertFalse(nullable)\n",
        "\n",
        "    def test_parse_type_ref_list(self):\n",
        "        \"\"\"Test parsing of list type reference.\"\"\"\n",
        "        ref = {\"kind\": \"LIST\", \"ofType\": {\"kind\": \"SCALAR\", \"name\": \"String\"}}\n",
        "        name, nullable = self.client._parse_type_ref(ref)\n",
        "        self.assertEqual(name, \"[String]\")\n",
        "        self.assertTrue(nullable)\n",
        "\n",
        "    def test_is_scalar_builtin(self):\n",
        "        \"\"\"Test detection of built-in scalar type.\"\"\"\n",
        "        self.assertTrue(self.client._is_scalar_type(\"Int\"))\n",
        "\n",
        "    def test_is_scalar_custom_scalar(self):\n",
        "        \"\"\"Test detection of user-defined scalar type.\"\"\"\n",
        "        self.client._schema_types[\"CustomScalar\"] = {\"kind\": \"SCALAR\"}\n",
        "        self.assertTrue(self.client._is_scalar_type(\"CustomScalar\"))\n",
        "\n",
        "    def test_is_not_scalar(self):\n",
        "        \"\"\"Test detection of non-scalar type.\"\"\"\n",
        "        self.client._schema_types[\"Obj\"] = {\"kind\": \"OBJECT\"}\n",
        "        self.assertFalse(self.client._is_scalar_type(\"Obj\"))\n",
        "\n",
        "    @patch(\"main.AdaptiveClient._execute_request\")\n",
        "    def test_refresh_schema_success(self, mock_exec):\n",
        "        \"\"\"Test successful schema refresh updates internal type registry.\"\"\"\n",
        "        mock_exec.return_value = {\n",
        "            \"data\": {\n",
        "                \"__schema\": {\n",
        "                    \"types\": [\n",
        "                        {\n",
        "                            \"kind\": \"OBJECT\",\n",
        "                            \"name\": \"User\",\n",
        "                            \"fields\": [\n",
        "                                {\n",
        "                                    \"name\": \"id\",\n",
        "                                    \"type\": {\"kind\": \"SCALAR\", \"name\": \"ID\"},\n",
        "                                    \"args\": [],\n",
        "                                }\n",
        "                            ]\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        self.client.refresh_schema(force=True)\n",
        "        self.assertIn(\"User\", self.client._schema_types)\n",
        "\n",
        "    @patch(\"main.AdaptiveClient._execute_request\")\n",
        "    def test_refresh_schema_skips_if_same_hash(self, mock_exec):\n",
        "        \"\"\"Test schema is not reloaded if hash matches existing schema.\"\"\"\n",
        "        mock_schema = {\n",
        "            \"__schema\": {\n",
        "                \"types\": [\n",
        "                    {\"kind\": \"OBJECT\", \"name\": \"X\", \"fields\": []}\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "        mock_exec.return_value = {\"data\": mock_schema}\n",
        "        h = self.client._compute_schema_hash(mock_schema)\n",
        "        self.client._schema_hash = h\n",
        "        self.client._schema_raw = mock_schema\n",
        "        self.client._schema_timestamp = time.time() - 100\n",
        "        self.client._refresh_interval = 1\n",
        "        self.client.refresh_schema()\n",
        "        self.assertEqual(self.client._schema_hash, h)\n",
        "\n",
        "    def test_build_scalar_query_basic(self):\n",
        "        \"\"\"Test scalar query generation for basic object.\"\"\"\n",
        "        self.client._schema_types[\"User\"] = {\n",
        "            \"kind\": \"OBJECT\",\n",
        "            \"fields\": {\n",
        "                \"id\": {\"type\": \"ID\", \"nullable\": True, \"requires_args\": False},\n",
        "                \"email\": {\"type\": \"String\",\n",
        "                          \"nullable\": True, \"requires_args\": False}\n",
        "            }\n",
        "        }\n",
        "        result = self.client._build_scalar_query(\"User\")\n",
        "        self.assertIn(\"id\", result)\n",
        "        self.assertIn(\"email\", result)\n",
        "\n",
        "    def test_build_scalar_query_recursion_block(self):\n",
        "        \"\"\"Test that recursion is prevented when generating scalar queries.\"\"\"\n",
        "        self.client._schema_types[\"A\"] = {\n",
        "            \"kind\": \"OBJECT\",\n",
        "            \"fields\": {\n",
        "                \"self\": {\"type\": \"A\",\n",
        "                         \"nullable\": False, \"requires_args\": False}\n",
        "            }\n",
        "        }\n",
        "        result = self.client._build_scalar_query(\"A\")\n",
        "        self.assertNotIn(\"self {\", result)\n",
        "\n",
        "    @patch(\"main.AdaptiveClient.refresh_schema\")\n",
        "    @patch(\"main.AdaptiveClient._execute_request\")\n",
        "    def test_fetch_by_id_success(self, mock_exec, mock_refresh):\n",
        "        \"\"\"Test successful fetch by ID with valid schema and response.\"\"\"\n",
        "        self.client._schema_types[\"Book\"] = {\n",
        "            \"kind\": \"OBJECT\",\n",
        "            \"fields\": {\n",
        "                \"id\": {\"type\": \"ID\", \"nullable\": True, \"requires_args\": False},\n",
        "                \"title\": {\"type\": \"String\",\n",
        "                          \"nullable\": True, \"requires_args\": False}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        mock_exec.return_value = {\n",
        "            \"data\": {\"book\": {\"id\": \"1\", \"title\": \"GraphQL\"}}\n",
        "        }\n",
        "\n",
        "        result = self.client.fetch_by_id(\"Book\", 1)\n",
        "        self.assertEqual(result[\"title\"], \"GraphQL\")\n",
        "\n",
        "    @patch(\"main.AdaptiveClient._execute_request\")\n",
        "    def test_run_raw_uses_json_sorted_keys(self, mock_exec):\n",
        "        \"\"\"Test raw query execution returns valid results.\"\"\"\n",
        "        mock_exec.return_value = {\"data\": {\"ping\": \"pong\"}}\n",
        "        query = \"query { ping }\"\n",
        "        result = self.client.run_raw(query, {})\n",
        "        self.assertEqual(result[\"data\"][\"ping\"], \"pong\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/079f813a-dfe3-484f-8432-093ece915c7f\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "import logging\n",
        "import json\n",
        "import time\n",
        "import hashlib\n",
        "from typing import Dict, Any\n",
        "\n",
        "class GraphQLAdaptiveError(Exception):\n",
        "    pass\n",
        "\n",
        "class AdaptiveClient:\n",
        "    introspection_query = \"\"\" … trimmed … \"\"\"\n",
        "\n",
        "    def __init__(self, endpoint: str, headers: Dict[str, str] = None, refresh_interval_seconds: int = 0):\n",
        "        if not endpoint.startswith(\"https://\"):\n",
        "            raise ValueError(\"Only HTTPS endpoints are supported.\")        #<Issue> spec: *must* raise **GraphQLAdaptiveError**\n",
        "        self.endpoint = endpoint\n",
        "        self.headers = headers or {}\n",
        "        self.refresh_interval_seconds = refresh_interval_seconds\n",
        "        self.last_schema_refresh = 0\n",
        "        self.schema = None\n",
        "        self.schema_hash = None\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({'Content-Type': 'application/json'})\n",
        "        self.session.headers.update(self.headers)\n",
        "\n",
        "    def refresh_schema(self, force: bool = False) -> None:\n",
        "        current_time = time.time()\n",
        "        if (force or (current_time - self.last_schema_refresh > self.refresh_interval_seconds)) and (\"ADAPTIVE_GQL_OFFLINE\" not in environ):  # <Issue> uses `environ` but never imported `os`\n",
        "            try:\n",
        "                response = self.session.post(\n",
        "                    self.endpoint,\n",
        "                    json={\"query\": self.introspection_query},\n",
        "                    timeout=5                                         # <Issue> fixed 5 s timeout ignores --retry/timeout spec\n",
        "                )\n",
        "                data = response.json()\n",
        "                self.schema = data['data']                           # <Issue> never computes SHA-256 or detects changes\n",
        "            except Exception as e:\n",
        "                logging.error(e)                                     # <Issue> logging at import-time banned; **must** log only inside public calls\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}