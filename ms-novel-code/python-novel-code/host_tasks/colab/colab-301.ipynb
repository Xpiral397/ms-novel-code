{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Backend Integration\n",
        "\n",
        "**L2 Taxonomy** - API Integration\n",
        "\n",
        "**Subtopic** - Using GraphQL introspection from Python to adapt to API schema changes\n",
        "\n",
        "**Use Case** - Develop a Python module that uses GraphQL introspection to adapt to API schema changes. The module should be able to retrieve the current schema from a GraphQL API, parse it, and adjust its own internal data structures to match. It should also be able to handle changes in the schema over time, such as new fields being added or existing fields being removed.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "Problem Statement:\n",
        "- Develop a Python module that uses GraphQL introspection to adapt to API schema changes.\n",
        "- The module should be able to retrieve the current schema from a GraphQL API, parse it, and adjust its own internal data structures to match.\n",
        "- It should also be able to handle changes in the schema over time, such as new fields being added or existing fields being removed.\n",
        "- Please make sure not to include unnecessary explanations or extra details. Just provide the complete implementation from start to end as per the prompt.\n",
        "\n",
        "Input Format:\n",
        "- A string representing the GraphQL API endpoint (e.g., \"https://example.com/graphql\").\n",
        "- A dictionary of optional HTTP headers (e.g., {\"Authorization\": \"Bearer token\", \"Content-Type\": \"application/json\"}).\n",
        "- An optional previous schema snapshot as a dictionary to compare against the current schema.\n",
        "- An optional dictionary of configuration flags to control behavior (e.g., {\"validate_changes\": True, \"print_diff\": False}).\n",
        "\n",
        "Input Constraints:\n",
        "- The GraphQL API endpoint must be a valid HTTP or HTTPS URL.\n",
        "- Headers, if provided, must be in dictionary format with string keys and values.\n",
        "- The schema snapshot must be either:\n",
        "  - A valid JSON object conforming to GraphQL introspection format.\n",
        "- Configuration flags must be a dictionary containing only recognized keys:\n",
        "  - \"validate_changes\": boolean\n",
        "  - \"print_diff\": boolean\n",
        "  - \"update_internal_state\": boolean\n",
        "- The API must support the GraphQL introspection query (`__schema` field must be available).\n",
        "- Network requests must complete within a reasonable timeout (e.g., 10 seconds).\n",
        "\n",
        "Output Format:\n",
        "- A dictionary representing the current GraphQL schema as returned by the introspection query ({\"__schema\": ...}).\n",
        "- If a previous schema is provided, an additional dictionary indicating the differences:\n",
        "  - \"added_types\": list of newly added types or fields\n",
        "  - \"removed_types\": list of removed types or fields\n",
        "  - \"changed_fields\": list of fields whose types, arguments, or nullability have been modified.\n",
        "   - each item in the list is a dict.\n",
        "- If no previous schema is provided, only the current schema will be returned and comparison fields will be omitted.\n",
        "\n",
        "\n",
        "Class Definition:\n",
        "- class GraphQLSchemaAdapter:\n",
        "    - __init__(self, endpoint: str, headers: dict = None, config: dict = None)\n",
        "        - Initializes the adapter with the given GraphQL endpoint, optional headers, and configuration flags.\n",
        "\n",
        "    - fetch_current_schema(self) -> dict\n",
        "        - Sends an introspection query to the GraphQL endpoint and returns the current schema as a dictionary.\n",
        "\n",
        "    - load_previous_schema(self, source: dict) -> dict\n",
        "        - Loads a previous schema directly from a dictionary.\n",
        "\n",
        "    - compare_schemas(self, old_schema: dict, new_schema: dict) -> dict\n",
        "        - Compares two schemas and returns the differences as a dictionary with keys like 'added_types', 'removed_types', etc.\n",
        "\n",
        "    - update_internal_state(self, schema_diff: dict) -> None\n",
        "        - Updates internal representations based on schema changes, if enabled via config.\n",
        "\n",
        "    - run(self, old_schema: dict = None) -> dict\n",
        "        - Orchestrates the process: fetches current schema, compares with previous (if provided), updates state, and returns results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "Explicit Requirements:\n",
        "- The module must connect to a GraphQL endpoint and perform an introspection query.\n",
        "- It must parse and return the current schema in dictionary format.\n",
        "- The module must identify added, removed, or changed fields/types.\n",
        "- It must support headers (e.g., Authorization) for secured GraphQL endpoints.\n",
        "- Custom exceptions like SchemaFormatError, NetworkError, and ValidationError must be used for clear error reporting.\n",
        "\n",
        "Implicit Requirements:\n",
        "- The module should handle network errors gracefully (e.g., timeouts, connection errors).\n",
        "- It should validate the structure of the GraphQL introspection response.\n",
        "- It should support reusability and modular design (e.g., well-structured methods and classes).\n",
        "- It should avoid unnecessary reprocessing if the schema has not changed.\n",
        "- It should maintain backward compatibility with older schema versions when possible.\n",
        "- It should be extendable for future schema evolution strategies.\n",
        "- All data structures and comparisons must be deterministic and consistent.\n",
        "\n",
        "Solution Expectations:\n",
        "- A well-structured Python module with clear class and method definitions.\n",
        "- The class should encapsulate all functionality related to schema retrieval, comparison, and adaptation.\n",
        "- The module must correctly perform a GraphQL introspection query and parse the result.\n",
        "- It should detect and report schema changes such as added, removed, or modified types and fields.\n",
        "- The code should include input validation, error handling, and meaningful exceptions.\n",
        "- Internal data structures should be automatically updated if configured.\n",
        "- The design should be modular, reusable, and easily testable.\n",
        "- The solution should be able to handle evolving GraphQL APIs without manual intervention.\n",
        "\n",
        "Edge Cases and Behaviour:\n",
        "- Empty or Invalid Endpoint:\n",
        "  - The module should raise a clear error if the endpoint is missing or not a valid URL.\n",
        "\n",
        "- Unreachable GraphQL Server:\n",
        "  - Should handle connection errors, timeouts, or DNS failures gracefully with retry or failure messages.\n",
        "\n",
        "- Introspection Not Supported:\n",
        "  - If the GraphQL server disables introspection, the module should report this with a meaningful exception.\n",
        "\n",
        "- Missing or Malformed Previous Schema:\n",
        "  - If a provided schema is an invalid JSON, the module should fall back gracefully or raise a descriptive error.\n",
        "\n",
        "- No Schema Changes:\n",
        "  - If the new schema is identical to the previous one, the module should report \"no changes detected\" and skip updates.\n",
        "\n",
        "- Addition of New Fields or Types:\n",
        "  - Should list these in the `added_types` or equivalent output key.\n",
        "\n",
        "- Removal of Fields or Types:\n",
        "  - Should list these in the `removed_types` or equivalent key, and update or warn depending on configuration.\n",
        "\n",
        "- Type Modifications (e.g., field type changed):\n",
        "  - Should capture these in `changed_fields` and ensure consistency in internal updates.\n",
        "\n",
        "- Large or Deeply Nested Schemas:\n",
        "  - Should efficiently parse and compare without exceeding memory or recursion limits.\n",
        "\n",
        "- Authenticated Endpoints:\n",
        "  - Should correctly apply headers (e.g., tokens) and report unauthorized access errors.\n",
        "\n",
        "- Corrupted Introspection Response:\n",
        "  - Should validate the structure before processing and raise a schema format error if needed.\n",
        "\n",
        "- Valid HTTP response with invalid or incomplete introspection data:\n",
        "  - Should detect missing \"__schema\" or unexpected types and raise a SchemaFormatError.\n",
        "\n",
        "Solution Constraints:\n",
        "- Must use only standard Python libraries or widely accepted third-party packages (e.g., requests, json).\n",
        "- Must support GraphQL introspection query as per the GraphQL specification.\n",
        "- The solution should not depend on specific API implementations or hardcoded schema structures.\n",
        "- Must handle schema comparison deterministically and consistently.\n",
        "- Response parsing and diff computation must complete within reasonable time (e.g., <5 seconds for medium schemas).\n",
        "- Must support schemas of realistic size (e.g., thousands of types and fields) without excessive memory usage.\n",
        "- Internal state updates must not mutate input schema objects directly.\n",
        "- All external network calls must respect timeout settings (recommended default: 10 seconds).\n",
        "- Implement local in-memory caching of fetched schemas to minimize repeated network requests.\n",
        "- The module's peak memory usage must not exceed 100 MB during schema fetching and comparison, even for very large schemas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\"\"\"\n",
        "GraphQL Schema Adapter.\n",
        "\n",
        "This module defines a Python class to adapt to GraphQL schema changes.\n",
        "\n",
        "It uses introspection API and supports schema comparison,\n",
        "error handling, caching, and memory safety.\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "import re\n",
        "import threading\n",
        "import copy\n",
        "import resource\n",
        "\n",
        "\n",
        "class SchemaFormatError(Exception):\n",
        "    \"\"\"Raised when the schema is malformed or missing required keys.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "class NetworkError(Exception):\n",
        "    \"\"\"Raised when there is a network communication issue.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "class ValidationError(Exception):\n",
        "    \"\"\"Raised when validation of a user argument fails.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "_INTROSPECTION_QUERY = \"\"\"\n",
        "query IntrospectionQuery {\n",
        "  __schema {\n",
        "    queryType { name }\n",
        "    mutationType { name }\n",
        "    subscriptionType { name }\n",
        "    types {\n",
        "      ...FullType\n",
        "    }\n",
        "    directives {\n",
        "      name\n",
        "      description\n",
        "      locations\n",
        "      args {\n",
        "        ...InputValue\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "fragment FullType on __Type {\n",
        "  kind\n",
        "  name\n",
        "  description\n",
        "  fields(includeDeprecated: true) {\n",
        "    name\n",
        "    description\n",
        "    args {\n",
        "      ...InputValue\n",
        "    }\n",
        "    type {\n",
        "      ...TypeRef\n",
        "    }\n",
        "    isDeprecated\n",
        "    deprecationReason\n",
        "  }\n",
        "  inputFields {\n",
        "    ...InputValue\n",
        "  }\n",
        "  interfaces {\n",
        "    ...TypeRef\n",
        "  }\n",
        "  enumValues(includeDeprecated: true) {\n",
        "    name\n",
        "    description\n",
        "    isDeprecated\n",
        "    deprecationReason\n",
        "  }\n",
        "  possibleTypes {\n",
        "    ...TypeRef\n",
        "  }\n",
        "}\n",
        "\n",
        "fragment InputValue on __InputValue {\n",
        "  name\n",
        "  description\n",
        "  type { ...TypeRef }\n",
        "  defaultValue\n",
        "}\n",
        "\n",
        "fragment TypeRef on __Type {\n",
        "  kind\n",
        "  name\n",
        "  ofType {\n",
        "    kind\n",
        "    name\n",
        "    ofType {\n",
        "      kind\n",
        "      name\n",
        "      ofType {\n",
        "        kind\n",
        "        name\n",
        "        ofType {\n",
        "          kind\n",
        "          name\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _is_valid_url(url):\n",
        "    \"\"\"Check if the provided URL is valid for HTTP/HTTPS.\"\"\"\n",
        "    return bool(re.match(r'^https?://[^\\s/$.?#].[^\\s]*$', url))\n",
        "\n",
        "\n",
        "def _build_type_signature(type_obj):\n",
        "    \"\"\"Recursively construct a type string from introspection type.\"\"\"\n",
        "    if not type_obj:\n",
        "        return \"None\"\n",
        "    kind = type_obj.get(\"kind\")\n",
        "    name = type_obj.get(\"name\")\n",
        "    of_type = type_obj.get(\"ofType\")\n",
        "    if kind == \"NON_NULL\":\n",
        "        return f\"{_build_type_signature(of_type)}!\"\n",
        "    if kind == \"LIST\":\n",
        "        return f\"[{_build_type_signature(of_type)}]\"\n",
        "    return name or (_build_type_signature(of_type) if of_type else \"Unknown\")\n",
        "\n",
        "\n",
        "def _extract_types(schema):\n",
        "    \"\"\"Extract a name->type mapping of types from a schema object.\"\"\"\n",
        "    return {\n",
        "        t.get(\"name\"): t\n",
        "        for t in schema.get(\"__schema\", {}).get(\"types\", [])\n",
        "        if t.get(\"name\")\n",
        "    }\n",
        "\n",
        "\n",
        "def _extract_fields(type_obj):\n",
        "    \"\"\"Extract a mapping of field names to type/args for one GraphQL type.\"\"\"\n",
        "    result = {}\n",
        "    for field in (type_obj.get(\"fields\", []) or []):\n",
        "        args = {\n",
        "            a.get(\"name\"): {\n",
        "                \"type\": _build_type_signature(a.get(\"type\")),\n",
        "                \"default\": a.get(\"defaultValue\")\n",
        "            }\n",
        "            for a in (field.get(\"args\", []) or [])\n",
        "        }\n",
        "        result[field.get(\"name\")] = {\n",
        "            \"type\": _build_type_signature(field.get(\"type\")),\n",
        "            \"args\": args\n",
        "        }\n",
        "    return result\n",
        "\n",
        "\n",
        "def _get_memory_usage_mb():\n",
        "    \"\"\"Calculate memory usage in MB.\"\"\"\n",
        "    try:\n",
        "        usage = resource.getrusage(resource.RUSAGE_SELF)\n",
        "        return usage.ru_maxrss / 1024 if hasattr(usage, 'ru_maxrss') else 0\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "\n",
        "class GraphQLSchemaAdapter:\n",
        "    \"\"\"Adapter for dynamic GraphQL schema introspection, change detection.\"\"\"\n",
        "\n",
        "    _schema_cache = {}\n",
        "    _cache_lock = threading.Lock()\n",
        "\n",
        "    def __init__(self, endpoint, headers=None, config=None):\n",
        "        \"\"\"Initialize the adapter with an endpoint, headers, and configuration.\n",
        "\n",
        "        Args:\n",
        "            endpoint (str): GraphQL endpoint URL (must be valid HTTP/HTTPS).\n",
        "            headers (dict): Optional HTTP headers.\n",
        "            config (dict): Optional config flags.\n",
        "        Raises:\n",
        "            ValidationError: If the endpoint is not valid.\n",
        "        \"\"\"\n",
        "        if not (isinstance(endpoint, str) and _is_valid_url(endpoint)):\n",
        "            raise ValidationError(\"Invalid GraphQL endpoint URL.\")\n",
        "        self.endpoint = endpoint\n",
        "        self.headers = headers if headers and isinstance(headers, dict) else {}\n",
        "        self.config = {\n",
        "            \"validate_changes\": True,\n",
        "            \"print_diff\": False,\n",
        "            \"update_internal_state\": True,\n",
        "        }\n",
        "        if config:\n",
        "            for key in config:\n",
        "                if key in self.config:\n",
        "                    self.config[key] = config[key]\n",
        "                else:\n",
        "                    raise ValidationError(f\"Unsupported config key: {key}\")\n",
        "        self.internal_state = None\n",
        "\n",
        "    def fetch_current_schema(self):\n",
        "        \"\"\"Perform an introspection query and return the current schema.\n",
        "\n",
        "        Returns:\n",
        "            dict: Introspection schema object as returned from endpoint.\n",
        "\n",
        "        Raises:\n",
        "            NetworkError, SchemaFormatError, MemoryError\n",
        "        \"\"\"\n",
        "        cache_key = (self.endpoint, frozenset(self.headers.items()))\n",
        "        with GraphQLSchemaAdapter._cache_lock:\n",
        "            cached = GraphQLSchemaAdapter._schema_cache.get(cache_key)\n",
        "            if cached:\n",
        "                return copy.deepcopy(cached)\n",
        "        try:\n",
        "            resp = requests.post(\n",
        "                self.endpoint,\n",
        "                json={\"query\": _INTROSPECTION_QUERY},\n",
        "                headers=self.headers,\n",
        "                timeout=10,\n",
        "            )\n",
        "            if resp.status_code == 401:\n",
        "                raise NetworkError(\"Unauthorized access\"\n",
        "                                   \" to the endpoint (401).\")\n",
        "            resp.raise_for_status()\n",
        "        except requests.exceptions.RequestException as exc:\n",
        "            raise NetworkError(f\"Failed to fetch schema from endpoint: {exc}\")\n",
        "\n",
        "        try:\n",
        "            data = resp.json()\n",
        "        except Exception as exc:\n",
        "            raise SchemaFormatError(\n",
        "                f\"Failed to parse JSON from schema response: {exc}\"\n",
        "            )\n",
        "\n",
        "        if (\n",
        "            not isinstance(data, dict)\n",
        "            or \"data\" not in data\n",
        "            or \"__schema\" not in data[\"data\"]\n",
        "        ):\n",
        "            raise SchemaFormatError(\"Introspection result \"\n",
        "                                    \"missing '__schema' key.\")\n",
        "        schema = {\"__schema\": data[\"data\"][\"__schema\"]}\n",
        "\n",
        "        with GraphQLSchemaAdapter._cache_lock:\n",
        "            GraphQLSchemaAdapter._schema_cache[\n",
        "                cache_key] = copy.deepcopy(schema)\n",
        "\n",
        "        if _get_memory_usage_mb() > 100:\n",
        "            raise MemoryError(\n",
        "                \"Memory usage exceeded 100 MB limit during schema fetch.\"\n",
        "            )\n",
        "\n",
        "        return schema\n",
        "\n",
        "    def load_previous_schema(self, source):\n",
        "        \"\"\"Validate and return the provided previous schema dict.\"\"\"\n",
        "        if not source:\n",
        "            return None\n",
        "        if not (isinstance(source, dict) and \"__schema\" in source):\n",
        "            raise SchemaFormatError(\n",
        "                \"Provided previous schema must\"\n",
        "                \" be a dict with a '__schema' key.\"\n",
        "            )\n",
        "        return source\n",
        "\n",
        "    def compare_schemas(self, old_schema, new_schema):\n",
        "        \"\"\"Compare old and new schemas and return a diff.\n",
        "\n",
        "        Args:\n",
        "            old_schema (dict): Previous schema object.\n",
        "            new_schema (dict): Latest schema object.\n",
        "\n",
        "        Returns:\n",
        "            dict: Diff dict with 'added_types',\n",
        "            'removed_types', and 'changed_fields'.\n",
        "        \"\"\"\n",
        "        old_types = _extract_types(old_schema) if old_schema else {}\n",
        "        new_types = _extract_types(new_schema)\n",
        "\n",
        "        added_types = []\n",
        "        removed_types = []\n",
        "        changed_fields = []\n",
        "\n",
        "        for t_name, t in new_types.items():\n",
        "            if t_name not in old_types:\n",
        "                added_types.append({\"type\": t_name, \"kind\": t.get(\"kind\")})\n",
        "\n",
        "        for t_name, t in old_types.items():\n",
        "            if t_name not in new_types:\n",
        "                removed_types.append({\"type\": t_name, \"kind\": t.get(\"kind\")})\n",
        "\n",
        "        for t_name in new_types:\n",
        "            if t_name not in old_types:\n",
        "                continue\n",
        "            old_fields = _extract_fields(old_types[t_name])\n",
        "            new_fields = _extract_fields(new_types[t_name])\n",
        "\n",
        "            for f_name, f_data in new_fields.items():\n",
        "                if f_name not in old_fields:\n",
        "                    added_types.append(\n",
        "                        {\"type\": t_name, \"field\": f_name, \"action\": \"added\"}\n",
        "                    )\n",
        "            for f_name in old_fields:\n",
        "                if f_name not in new_fields:\n",
        "                    removed_types.append(\n",
        "                        {\"type\": t_name, \"field\": f_name, \"action\": \"removed\"}\n",
        "                    )\n",
        "            for f_name in old_fields:\n",
        "                if f_name in new_fields:\n",
        "                    old_f = old_fields[f_name]\n",
        "                    new_f = new_fields[f_name]\n",
        "                    if (old_f[\"type\"] != new_f[\"type\"]) or (\n",
        "                        old_f[\"args\"] != new_f[\"args\"]\n",
        "                    ):\n",
        "                        changed_fields.append(\n",
        "                            {\n",
        "                                \"type\": t_name,\n",
        "                                \"field\": f_name,\n",
        "                                \"old_type\": old_f[\"type\"],\n",
        "                                \"new_type\": new_f[\"type\"],\n",
        "                                \"old_args\": old_f[\"args\"],\n",
        "                                \"new_args\": new_f[\"args\"],\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "        diff = {\n",
        "            \"added_types\": added_types,\n",
        "            \"removed_types\": removed_types,\n",
        "            \"changed_fields\": changed_fields,\n",
        "        }\n",
        "\n",
        "        if _get_memory_usage_mb() > 100:\n",
        "            raise MemoryError(\n",
        "                \"Memory usage exceeded 100 MB during schema comparison.\"\n",
        "            )\n",
        "\n",
        "        return diff\n",
        "\n",
        "    def update_internal_state(self, schema_diff):\n",
        "        \"\"\"Update the object's state with schema_diff, if configured.\"\"\"\n",
        "        if self.config.get(\"update_internal_state\", True):\n",
        "            self.internal_state = copy.deepcopy(schema_diff)\n",
        "\n",
        "    def run(self, old_schema=None):\n",
        "        \"\"\"Orchestrate schema fetch, diff, state update, and return results.\n",
        "\n",
        "        Args:\n",
        "            old_schema (dict): Previous schema, or None.\n",
        "\n",
        "        Returns:\n",
        "            dict: Result, including 'current_schema' and, if present, the diff.\n",
        "        \"\"\"\n",
        "        current_schema = self.fetch_current_schema()\n",
        "        result = {\"current_schema\": copy.deepcopy(current_schema)}\n",
        "        if old_schema:\n",
        "            old_loaded = self.load_previous_schema(old_schema)\n",
        "            diff = self.compare_schemas(old_loaded, current_schema)\n",
        "            result.update(diff)\n",
        "            if self.config.get(\"update_internal_state\", True):\n",
        "                self.update_internal_state(diff)\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\"\"\"Unit tests for GraphQLSchemaAdapter class in main module.\"\"\"\n",
        "\n",
        "import unittest\n",
        "\n",
        "from main import (\n",
        "    GraphQLSchemaAdapter,\n",
        "    SchemaFormatError,\n",
        "    NetworkError,\n",
        "    ValidationError\n",
        ")\n",
        "\n",
        "\n",
        "class TestGraphQLSchemaAdapter(unittest.TestCase):\n",
        "    \"\"\"Test GraphQLSchemaAdapter behavior for all key functionalities.\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Initialize common schema, endpoint, headers, and config.\"\"\"\n",
        "        self.valid_endpoint = \"https://example.com/graphql\"\n",
        "        self.invalid_endpoint = \"ftp://invalid-url\"\n",
        "        self.headers = {\"Authorization\": \"Bearer token\"}\n",
        "        self.config = {\n",
        "            \"validate_changes\": True,\n",
        "            \"print_diff\": True,\n",
        "            \"update_internal_state\": True\n",
        "        }\n",
        "        self.minimal_schema = {\n",
        "            \"__schema\": {\n",
        "                \"types\": [\n",
        "                    {\n",
        "                        \"name\": \"Query\",\n",
        "                        \"kind\": \"OBJECT\",\n",
        "                        \"fields\": [\n",
        "                            {\n",
        "                                \"name\": \"hello\",\n",
        "                                \"type\": {\"kind\": \"SCALAR\", \"name\": \"String\"},\n",
        "                                \"args\": []\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "        self.modified_schema = {\n",
        "            \"__schema\": {\n",
        "                \"types\": [\n",
        "                    {\n",
        "                        \"name\": \"Query\",\n",
        "                        \"kind\": \"OBJECT\",\n",
        "                        \"fields\": [\n",
        "                            {\n",
        "                                \"name\": \"hello\",\n",
        "                                \"type\": {\"kind\": \"SCALAR\", \"name\": \"Int\"},\n",
        "                                \"args\": []\n",
        "                            },\n",
        "                            {\n",
        "                                \"name\": \"newField\",\n",
        "                                \"type\": {\"kind\": \"SCALAR\", \"name\": \"String\"},\n",
        "                                \"args\": []\n",
        "                            }\n",
        "                        ]\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"ExtraType\",\n",
        "                        \"kind\": \"OBJECT\",\n",
        "                        \"fields\": []\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def test_invalid_endpoint_raises_validation_error(self):\n",
        "        \"\"\"Raise ValidationError for invalid endpoint.\"\"\"\n",
        "        with self.assertRaises(ValidationError):\n",
        "            GraphQLSchemaAdapter(self.invalid_endpoint)\n",
        "\n",
        "    def test_unsupported_config_key_raises_validation_error(self):\n",
        "        \"\"\"Raise ValidationError for unknown config key.\"\"\"\n",
        "        with self.assertRaises(ValidationError):\n",
        "            GraphQLSchemaAdapter(\n",
        "                self.valid_endpoint,\n",
        "                config={\"bad_key\": True}\n",
        "            )\n",
        "\n",
        "    def test_load_previous_schema_with_invalid_dict_raises_error(self):\n",
        "        \"\"\"Raise SchemaFormatError for invalid previous schema.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        with self.assertRaises(SchemaFormatError):\n",
        "            adapter.load_previous_schema({\"not_schema\": {}})\n",
        "\n",
        "    def test_load_previous_schema_with_none_returns_none(self):\n",
        "        \"\"\"Return None when previous schema is None.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        self.assertIsNone(adapter.load_previous_schema(None))\n",
        "\n",
        "    def test_compare_schemas_detects_added_and_removed_types(self):\n",
        "        \"\"\"Detect added and removed types between schemas.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        diff = adapter.compare_schemas(\n",
        "            self.minimal_schema,\n",
        "            self.modified_schema\n",
        "        )\n",
        "        added = [t[\"type\"] for t in diff[\"added_types\"]]\n",
        "        removed = [t[\"type\"] for t in diff[\"removed_types\"]]\n",
        "        self.assertIn(\"ExtraType\", added)\n",
        "        self.assertEqual(len(removed), 0)\n",
        "\n",
        "    def test_compare_schemas_detects_added_and_removed_fields(self):\n",
        "        \"\"\"Detect field additions and removals in types.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        mod_schema = {\n",
        "            \"__schema\": {\n",
        "                \"types\": [\n",
        "                    {\n",
        "                        \"name\": \"Query\",\n",
        "                        \"kind\": \"OBJECT\",\n",
        "                        \"fields\": [\n",
        "                            {\n",
        "                                \"name\": \"hello\",\n",
        "                                \"type\": {\"kind\": \"SCALAR\", \"name\": \"String\"},\n",
        "                                \"args\": []\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "        diff = adapter.compare_schemas(self.modified_schema, mod_schema)\n",
        "        removed = [t for t in diff[\"removed_types\"] if \"field\" in t]\n",
        "        self.assertTrue(any(f[\"field\"] == \"newField\" for f in removed))\n",
        "\n",
        "    def test_compare_schemas_detects_changed_fields(self):\n",
        "        \"\"\"Detect changes in field types.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        diff = adapter.compare_schemas(\n",
        "            self.minimal_schema,\n",
        "            self.modified_schema\n",
        "        )\n",
        "        changed = [\n",
        "            f for f in diff[\"changed_fields\"] if f[\"field\"] == \"hello\"\n",
        "        ]\n",
        "        self.assertTrue(changed)\n",
        "        self.assertEqual(changed[0][\"old_type\"], \"String\")\n",
        "        self.assertEqual(changed[0][\"new_type\"], \"Int\")\n",
        "\n",
        "    def test_update_internal_state_applies_diff(self):\n",
        "        \"\"\"Update internal state using given diff.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        diff = adapter.compare_schemas(\n",
        "            self.minimal_schema,\n",
        "            self.modified_schema\n",
        "        )\n",
        "        adapter.update_internal_state(diff)\n",
        "        self.assertEqual(adapter.internal_state, diff)\n",
        "\n",
        "    def test_run_returns_current_schema_only_if_no_old_schema(self):\n",
        "        \"\"\"Return only current schema when old schema is None.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        adapter.fetch_current_schema = lambda: self.minimal_schema\n",
        "        result = adapter.run()\n",
        "        self.assertIn(\"current_schema\", result)\n",
        "        self.assertNotIn(\"added_types\", result)\n",
        "\n",
        "    def test_run_returns_diff_if_old_schema_provided(self):\n",
        "        \"\"\"Return schema diff when old schema is provided.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "        adapter.fetch_current_schema = lambda: self.modified_schema\n",
        "        result = adapter.run(self.minimal_schema)\n",
        "        self.assertIn(\"added_types\", result)\n",
        "        self.assertIn(\"removed_types\", result)\n",
        "        self.assertIn(\"changed_fields\", result)\n",
        "\n",
        "    def test_run_updates_internal_state_if_config_enabled(self):\n",
        "        \"\"\"Update internal state if config enables it.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(\n",
        "            self.valid_endpoint,\n",
        "            config={\"update_internal_state\": True}\n",
        "        )\n",
        "        adapter.fetch_current_schema = lambda: self.modified_schema\n",
        "        adapter.internal_state = None\n",
        "        adapter.run(self.minimal_schema)\n",
        "        self.assertIsNotNone(adapter.internal_state)\n",
        "\n",
        "    def test_run_does_not_update_internal_state_if_config_disabled(self):\n",
        "        \"\"\"Do not update internal state if config disables it.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(\n",
        "            self.valid_endpoint,\n",
        "            config={\"update_internal_state\": False}\n",
        "        )\n",
        "        adapter.fetch_current_schema = lambda: self.modified_schema\n",
        "        adapter.internal_state = None\n",
        "        adapter.run(self.minimal_schema)\n",
        "        self.assertIsNone(adapter.internal_state)\n",
        "\n",
        "    def test_schema_cache_returns_cached_schema(self):\n",
        "        \"\"\"Return cached schema for repeated same endpoint.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(\n",
        "            self.valid_endpoint,\n",
        "            headers=self.headers\n",
        "        )\n",
        "\n",
        "        def fake_post(*args, **kwargs):\n",
        "            class FakeResp:\n",
        "                status_code = 200\n",
        "\n",
        "                def json(self):\n",
        "                    return {\"data\": {\"__schema\": {\"types\": []}}}\n",
        "\n",
        "                def raise_for_status(self):\n",
        "                    pass\n",
        "\n",
        "            return FakeResp()\n",
        "\n",
        "        import main\n",
        "        main.requests.post = fake_post\n",
        "        schema1 = adapter.fetch_current_schema()\n",
        "        schema2 = adapter.fetch_current_schema()\n",
        "        self.assertEqual(schema1, schema2)\n",
        "\n",
        "    def test_fetch_current_schema_raises_network_error_on_401(self):\n",
        "        \"\"\"Raise NetworkError on unauthorized response.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "\n",
        "        def fake_post(*args, **kwargs):\n",
        "            class FakeResp:\n",
        "                status_code = 401\n",
        "\n",
        "                def raise_for_status(self):\n",
        "                    raise Exception(\"401 Unauthorized\")\n",
        "\n",
        "                def json(self):\n",
        "                    return {\"data\": {\"__schema\": {\"types\": []}}}\n",
        "\n",
        "            return FakeResp()\n",
        "\n",
        "        import main\n",
        "        main.requests.post = fake_post\n",
        "        with self.assertRaises(NetworkError):\n",
        "            adapter.fetch_current_schema()\n",
        "\n",
        "    def test_schema_format_error_on_missing_schema(self):\n",
        "        \"\"\"Raise SchemaFormatError when '__schema' is missing.\"\"\"\n",
        "        adapter = GraphQLSchemaAdapter(self.valid_endpoint)\n",
        "\n",
        "        def fake_post(*args, **kwargs):\n",
        "            class FakeResp:\n",
        "                status_code = 200\n",
        "\n",
        "                def raise_for_status(self):\n",
        "                    pass\n",
        "\n",
        "                def json(self):\n",
        "                    return {\"data\": {}}\n",
        "\n",
        "            return FakeResp()\n",
        "\n",
        "        import main\n",
        "        main.requests.post = fake_post\n",
        "        with self.assertRaises(SchemaFormatError):\n",
        "            adapter.fetch_current_schema()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/763cd8b4-69f3-4a96-9a6c-0de9eeeef66d?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F81794%2Fview\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "# code generated by the model\n",
        "\"\"\"GraphQL Schema Adapter Module\"\"\"\n",
        "\n",
        "import json\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "INTROSPECTION_QUERY = \"\"\"\n",
        "query IntrospectionQuery {\n",
        "  __schema {\n",
        "    queryType { name }\n",
        "    mutationType { name }\n",
        "    subscriptionType { name }\n",
        "    types {\n",
        "      ...FullType\n",
        "    }\n",
        "    directives {\n",
        "      name\n",
        "      locations\n",
        "      args {\n",
        "        ...InputValue\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "fragment FullType on __Type {\n",
        "  kind\n",
        "  name\n",
        "  description\n",
        "  fields(includeDeprecated: true) {\n",
        "    name\n",
        "    description\n",
        "    args {\n",
        "      ...InputValue\n",
        "    }\n",
        "    type {\n",
        "      ...TypeRef\n",
        "    }\n",
        "    isDeprecated\n",
        "    deprecationReason\n",
        "  }\n",
        "  inputFields {\n",
        "    ...InputValue\n",
        "  }\n",
        "  interfaces {\n",
        "    ...TypeRef\n",
        "  }\n",
        "  enumValues(includeDeprecated: true) {\n",
        "    name\n",
        "    description\n",
        "    isDeprecated\n",
        "    deprecationReason\n",
        "  }\n",
        "  possibleTypes {\n",
        "    ...TypeRef\n",
        "  }\n",
        "}\n",
        "\n",
        "fragment InputValue on __InputValue {\n",
        "  name\n",
        "  description\n",
        "  type { ...TypeRef }\n",
        "  defaultValue\n",
        "}\n",
        "\n",
        "fragment TypeRef on __Type {\n",
        "  kind\n",
        "  name\n",
        "  ofType {\n",
        "    kind\n",
        "    name\n",
        "    ofType {\n",
        "      kind\n",
        "      name\n",
        "      ofType {\n",
        "        kind\n",
        "        name\n",
        "        ofType {\n",
        "          kind\n",
        "          name\n",
        "          ofType {\n",
        "            kind\n",
        "            name\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "class SchemaFormatError(Exception):\n",
        "    pass\n",
        "\n",
        "class NetworkError(Exception):\n",
        "    pass\n",
        "\n",
        "class ValidationError(Exception):\n",
        "    pass\n",
        "\n",
        "class GraphQLSchemaAdapter:\n",
        "    def __init__(self, endpoint: str, headers: dict = None, config: dict = None):\n",
        "        self.validate_endpoint(endpoint)\n",
        "        self.endpoint = endpoint\n",
        "        self.headers = headers if headers else {}\n",
        "        self.config = config if config else {}\n",
        "        self._schema_cache = None\n",
        "        # <Issue: Missing validation to ensure config keys are only from the allowed set.\n",
        "\n",
        "    def validate_endpoint(self, endpoint: str) -> None:\n",
        "        parsed = urlparse(endpoint)\n",
        "        if not parsed.scheme in (\"http\", \"https\") or not parsed.netloc:\n",
        "            raise ValueError(\"Invalid GraphQL endpoint. Must be a valid URL.\")\n",
        "\n",
        "    def fetch_current_schema(self) -> dict:\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.endpoint,\n",
        "                json={\"query\": INTROSPECTION_QUERY},\n",
        "                headers=self.headers,\n",
        "                timeout=10\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise NetworkError(f\"Network error during schema fetch: {str(e)}\")\n",
        "\n",
        "        try:\n",
        "            data = response.json()\n",
        "        except json.JSONDecodeError:\n",
        "            raise SchemaFormatError(\"Invalid JSON response from server.\")\n",
        "\n",
        "        if \"errors\" in data:\n",
        "            raise ValidationError(\"GraphQL introspection failed or is disabled.\")\n",
        "\n",
        "        if \"__schema\" not in data.get(\"data\", {}):\n",
        "            raise SchemaFormatError(\"No '__schema' key found in introspection response.\")\n",
        "\n",
        "        return {\"__schema\": data[\"data\"][\"__schema\"]}\n",
        "\n",
        "    def load_previous_schema(self, source: dict) -> dict:\n",
        "        if not source or \"__schema\" not in source:\n",
        "            raise SchemaFormatError(\"Previous schema does not contain '__schema'.\")\n",
        "        return source\n",
        "\n",
        "    def compare_schemas(self, old_schema: dict, new_schema: dict) -> dict:\n",
        "        old_types = {t[\"name\"]: t for t in old_schema[\"__schema\"].get(\"types\", []) if t[\"name\"]}\n",
        "        new_types = {t[\"name\"]: t for t in new_schema[\"__schema\"].get(\"types\", []) if t[\"name\"]}\n",
        "\n",
        "        added_types = list(set(new_types.keys()) - set(old_types.keys()))\n",
        "        removed_types = list(set(old_types.keys()) - set(new_types.keys()))\n",
        "        changed_fields = []\n",
        "\n",
        "        common_types = set(old_types.keys()).intersection(new_types.keys())\n",
        "        for type_name in common_types:\n",
        "            old_type = old_types[type_name]\n",
        "            new_type = new_types[type_name]\n",
        "            if \"fields\" in old_type and \"fields\" in new_type:\n",
        "                old_fields = {f[\"name\"]: f for f in old_type[\"fields\"] if f[\"name\"]}\n",
        "                new_fields = {f[\"name\"]: f for f in new_type[\"fields\"] if f[\"name\"]}\n",
        "\n",
        "                # Identify changed fields\n",
        "                intersecting_fields = set(old_fields.keys()).intersection(new_fields.keys())\n",
        "                for field_name in intersecting_fields:\n",
        "                    old_repr = self.field_signature(old_fields[field_name])\n",
        "                    new_repr = self.field_signature(new_fields[field_name])\n",
        "                    if old_repr != new_repr:\n",
        "                        changed_fields.append({\n",
        "                            \"type_name\": type_name,\n",
        "                            \"field_name\": field_name,\n",
        "                            \"old_signature\": old_repr,\n",
        "                            \"new_signature\": new_repr\n",
        "                        })\n",
        "\n",
        "        return {\n",
        "            \"added_types\": sorted(added_types),\n",
        "            \"removed_types\": sorted(removed_types),\n",
        "            \"changed_fields\": changed_fields\n",
        "        }\n",
        "\n",
        "    def field_signature(self, field: dict) -> str:\n",
        "        type_str = self.type_to_str(field[\"type\"])\n",
        "        args_str = []\n",
        "        for arg in field.get(\"args\", []):\n",
        "            arg_type_str = self.type_to_str(arg[\"type\"])\n",
        "            args_str.append(f\"{arg['name']}:{arg_type_str}\")\n",
        "        args_str = \",\".join(sorted(args_str))\n",
        "        return f\"{field['name']}({args_str}):{type_str}\"\n",
        "\n",
        "    def type_to_str(self, type_obj: dict) -> str:\n",
        "        # Recursively resolve the type name with nullability\n",
        "        def helper(t):\n",
        "            kind = t.get(\"kind\")\n",
        "            name = t.get(\"name\")\n",
        "            of_type = t.get(\"ofType\")\n",
        "            if kind == \"NON_NULL\":\n",
        "                return f\"{helper(of_type)}!\"\n",
        "            elif kind == \"LIST\":\n",
        "                return f\"[{helper(of_type)}]\"\n",
        "            else:\n",
        "                return name if name else \"UNKNOWN\"\n",
        "\n",
        "        return helper(type_obj)\n",
        "\n",
        "    def update_internal_state(self, schema_diff: dict) -> None:\n",
        "        # If configured to update, we replace our cache with new schema\n",
        "        # or apply partial updates in a real scenario. Here, we do a simple replacement.\n",
        "        if self.config.get(\"update_internal_state\"):\n",
        "            self._schema_cache = schema_diff\n",
        "        # <Issue>: Cached value should be current schema, not the diff dictionary. This will lead to all cache misses and the caching mechanism will not work\n",
        "\n",
        "    def run(self, old_schema: dict = None) -> dict:\n",
        "        current_schema = self.fetch_current_schema()\n",
        "        # <Issue>: Missing memory check during operations should be less than 100MB.\n",
        "        if old_schema:\n",
        "            old_schema_valid = self.load_previous_schema(old_schema)\n",
        "            diff = self.compare_schemas(old_schema_valid, current_schema)\n",
        "            if self.config.get(\"validate_changes\"):\n",
        "                # Could add extra validations here\n",
        "                # <Issue>: 'validate_changes' is set but no validation report is returned or built.\n",
        "                pass\n",
        "            if self.config.get(\"print_diff\"):\n",
        "                pass\n",
        "                 # <Issue>: 'print_diff' is set but schema differences are not printed\n",
        "            self.update_internal_state(diff)\n",
        "            return {\n",
        "                \"__schema\": current_schema[\"__schema\"],\n",
        "                \"added_types\": diff[\"added_types\"],\n",
        "                \"removed_types\": diff[\"removed_types\"],\n",
        "                \"changed_fields\": diff[\"changed_fields\"]\n",
        "            }\n",
        "        else:\n",
        "            return current_schema\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}