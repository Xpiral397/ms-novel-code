{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Background Processes\n",
        "\n",
        "**L2 Taxonomy** - Asynchronous Processing\n",
        "\n",
        "**Subtopic** - Async/Await for Handling Asynchronous Operations in Python.\n",
        "\n",
        "**Use Case** - Develop a Python script that reads and processes multiple CSV files concurrently using async/await. The script should read each file line by line, perform a data transformation, and write the transformed data to a new CSV file.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "aiofiles\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "I want to develop a Python program that reads two CSV files concurrently and processes them line by line using asynchronous programming. The data in files may contain whitespace, negative float values, string text with mixed casing and inconsistent row lengths. Each line needs to be cleaned, normalized, and then written to an new output CSV.\n",
        "\n",
        "**Input Format**\n",
        "\n",
        "- Two CSV files.\n",
        "\n",
        "**Output Format**\n",
        "\n",
        "- Two new CSV files.\n",
        "\n",
        "\n",
        "**Examples**\n",
        "\n",
        "Input\n",
        "```\n",
        "file1.csv:\n",
        "apple,  34.12345 , -12.5\n",
        "banana,42, hello\n",
        "\n",
        "file2.csv:\n",
        "   x,  y , z\n",
        "1.2345 , -1.234 ,world\n",
        "\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "file1_output.csv\n",
        "APPLE,34.123,0\n",
        "BANANA,42,HELLO\n",
        "```\n",
        "\n",
        "```\n",
        "file2_output.csv\n",
        "X,Y,Z\n",
        "1.234,0,WORLD\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "**Explicit and Implicit Points**\n",
        "\n",
        "- Use asyncio to read both files concurrently.\n",
        "- Ignore rows with mismatched number of columns.\n",
        "- Processed output must follow the same column order and be written as the file is read.\n",
        "\n",
        "\n",
        "**Solution Expectations**\n",
        "\n",
        "- The output files must be named to inputfilename_output.csv\n",
        "- The processing of CSV files must be efficent.\n",
        "- Rows with differing number of columns must be discarded.\n",
        "- Normalize:\n",
        "\n",
        "  - Strings -> Uppercase + strip whitespace\n",
        "\n",
        "  - Floats -> Round to 3 decimal places, clamp negatives to 0\n",
        "\n",
        "  - Empty values -> Use \"\" for strings, 0 for floats.\n",
        "\n",
        "\n",
        "**Function Signatures**\n",
        "\n",
        "```python\n",
        "async def process_csv_folder(folder_path: str) -> None:\n",
        "    pass\n",
        "```\n",
        "\n",
        "**Edge Case Behavior**\n",
        "\n",
        "- Entire empty rows should be skipped.\n",
        "- Rows with inconsistent columns should be ignored.\n",
        "- Malformed floats should not crash the transform.\n",
        "- Negative floats like -0.0001 should become 0.\n",
        "- If folder has more than 2 CSV files return -1.\n",
        "\n",
        "\n",
        "**Constraints**\n",
        "\n",
        "- Only aiofiles as external dependency allowed.\n",
        "- The solution must not use threading and multiprocessing libraries, only standard and allowed libraries are allowed.\n",
        "- No more than 2 CSV allowed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "\"\"\"\n",
        "Asynchronous CSV processor.\n",
        "\n",
        "Infers column types and normalizes values.\n",
        "\"\"\"\n",
        "\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import os\n",
        "import csv\n",
        "from io import StringIO\n",
        "from typing import Optional, List\n",
        "\n",
        "\n",
        "async def infer_column_types(\n",
        "    file_path: str,\n",
        "    expected_columns: int\n",
        ") -> List[str]:\n",
        "    \"\"\"Infer data types for each column by examining non-empty values.\"\"\"\n",
        "    column_types = [\"string\"] * expected_columns\n",
        "\n",
        "    async with aiofiles.open(file_path, mode='r', encoding='utf-8') as infile:\n",
        "        await infile.readline()\n",
        "        sample_count = 0\n",
        "        async for line in infile:\n",
        "            line = line.strip()\n",
        "            if not line or sample_count >= 10:\n",
        "                continue\n",
        "            items = line.split(',')\n",
        "            if len(items) != expected_columns:\n",
        "                continue\n",
        "            for i, item in enumerate(items):\n",
        "                item = item.strip()\n",
        "                if item:\n",
        "                    try:\n",
        "                        float(item)\n",
        "                        column_types[i] = \"float\"\n",
        "                    except ValueError:\n",
        "                        column_types[i] = \"string\"\n",
        "            sample_count += 1\n",
        "\n",
        "    return column_types\n",
        "\n",
        "\n",
        "async def normalize_value_typed(\n",
        "    value: str,\n",
        "    expected_type: str\n",
        ") -> str:\n",
        "    \"\"\"Normalize a single value according to the rules with type awareness.\"\"\"\n",
        "    value = value.strip()\n",
        "    if not value:\n",
        "        return \"0\" if expected_type == \"float\" else \"\"\n",
        "    try:\n",
        "        num = float(value)\n",
        "        num = max(0, round(num, 3))\n",
        "        if num == int(num):\n",
        "            return str(int(num))\n",
        "        return f\"{num:.3f}\".rstrip('0').rstrip('.')\n",
        "    except ValueError:\n",
        "        return value.upper()\n",
        "\n",
        "\n",
        "async def process_line_typed(\n",
        "    line: str,\n",
        "    expected_columns: int,\n",
        "    column_types: List[str]\n",
        ") -> Optional[List[str]]:\n",
        "    \"\"\"Process a single line.\n",
        "\n",
        "    according to normalization rules with type awareness.\n",
        "    \"\"\"\n",
        "    items = line.split(',')\n",
        "    if len(items) != expected_columns:\n",
        "        return None\n",
        "\n",
        "    processed_items = []\n",
        "    for i, item in enumerate(items):\n",
        "        expected_type = column_types[i] if i < len(column_types) else \"string\"\n",
        "        normalized = await normalize_value_typed(item, expected_type)\n",
        "        processed_items.append(normalized)\n",
        "\n",
        "    return processed_items\n",
        "\n",
        "\n",
        "async def process_file(\n",
        "    input_path: str,\n",
        "    output_path: str\n",
        ") -> None:\n",
        "    \"\"\"Process a single CSV file asynchronously.\"\"\"\n",
        "    try:\n",
        "        async with aiofiles.open(\n",
        "            input_path,\n",
        "            mode='r',\n",
        "            encoding='utf-8'\n",
        "        ) as infile:\n",
        "            first_line = await infile.readline()\n",
        "            if not first_line.strip():\n",
        "                return\n",
        "\n",
        "            header_items = first_line.strip().split(',')\n",
        "            expected_columns = len(header_items)\n",
        "            column_types = await infer_column_types(\n",
        "                input_path,\n",
        "                expected_columns\n",
        "            )\n",
        "\n",
        "            processed_header = [\n",
        "                item.strip().upper() for item in header_items\n",
        "            ]\n",
        "\n",
        "            async with aiofiles.open(\n",
        "                output_path,\n",
        "                mode='w',\n",
        "                encoding='utf-8',\n",
        "                newline=''\n",
        "            ) as outfile:\n",
        "                output_buffer = StringIO()\n",
        "                writer = csv.writer(output_buffer)\n",
        "                writer.writerow(processed_header)\n",
        "                await outfile.write(output_buffer.getvalue())\n",
        "\n",
        "                async for line in infile:\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        continue\n",
        "\n",
        "                    processed_row = await process_line_typed(\n",
        "                        line,\n",
        "                        expected_columns,\n",
        "                        column_types\n",
        "                    )\n",
        "                    if processed_row:\n",
        "                        output_buffer = StringIO()\n",
        "                        writer = csv.writer(output_buffer)\n",
        "                        writer.writerow(processed_row)\n",
        "                        await outfile.write(output_buffer.getvalue())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {input_path}: {e}\")\n",
        "\n",
        "\n",
        "async def process_csv_folder(folder_path: str) -> Optional[int]:\n",
        "    \"\"\"Process all CSV files in a folder concurrently.\"\"\"\n",
        "    try:\n",
        "        files = [\n",
        "            f for f in os.listdir(folder_path)\n",
        "            if f.endswith('.csv')\n",
        "        ]\n",
        "\n",
        "        if len(files) != 2:\n",
        "            return -1\n",
        "\n",
        "        tasks = []\n",
        "        for file in files:\n",
        "            input_path = os.path.join(folder_path, file)\n",
        "            output_path = os.path.join(\n",
        "                folder_path,\n",
        "                f\"{os.path.splitext(file)[0]}_output.csv\"\n",
        "            )\n",
        "            tasks.append(process_file(input_path, output_path))\n",
        "\n",
        "        await asyncio.gather(*tasks)\n",
        "        return None\n",
        "\n",
        "    except OSError:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17f96bc0-3c9a-4899-d3e3-961b97a271c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "E/usr/lib/python3.11/unittest/case.py:622: RuntimeWarning: coroutine 'process_csv_folder' was never awaited\n",
            "  with outcome.testPartExecutor(self):\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "EEEE\n",
            "======================================================================\n",
            "ERROR: test_ignore_inconsistent_and_blank_rows (__main__.TestProcessCSVFolder.test_ignore_inconsistent_and_blank_rows)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1448136916.py\", line 66, in test_ignore_inconsistent_and_blank_rows\n",
            "    result = asyncio.run(process_csv_folder(self.tempdir.name))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 186, in run\n",
            "    raise RuntimeError(\n",
            "RuntimeError: asyncio.run() cannot be called from a running event loop\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_ignore_non_csv_files (__main__.TestProcessCSVFolder.test_ignore_non_csv_files)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1448136916.py\", line 97, in test_ignore_non_csv_files\n",
            "    result = asyncio.run(process_csv_folder(self.tempdir.name))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 186, in run\n",
            "    raise RuntimeError(\n",
            "RuntimeError: asyncio.run() cannot be called from a running event loop\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_malformed_and_negative_floats (__main__.TestProcessCSVFolder.test_malformed_and_negative_floats)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1448136916.py\", line 83, in test_malformed_and_negative_floats\n",
            "    result = asyncio.run(process_csv_folder(self.tempdir.name))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 186, in run\n",
            "    raise RuntimeError(\n",
            "RuntimeError: asyncio.run() cannot be called from a running event loop\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_more_than_two_csv_returns_minus1 (__main__.TestProcessCSVFolder.test_more_than_two_csv_returns_minus1)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1448136916.py\", line 32, in test_more_than_two_csv_returns_minus1\n",
            "    result = asyncio.run(process_csv_folder(self.tempdir.name))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 186, in run\n",
            "    raise RuntimeError(\n",
            "RuntimeError: asyncio.run() cannot be called from a running event loop\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_two_csv_processing (__main__.TestProcessCSVFolder.test_two_csv_processing)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-4-1448136916.py\", line 45, in test_two_csv_processing\n",
            "    result = asyncio.run(process_csv_folder(self.tempdir.name))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 186, in run\n",
            "    raise RuntimeError(\n",
            "RuntimeError: asyncio.run() cannot be called from a running event loop\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.019s\n",
            "\n",
            "FAILED (errors=5)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "True",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "# tests\n",
        "\n",
        "import unittest\n",
        "import tempfile\n",
        "import os\n",
        "import asyncio\n",
        "\n",
        "\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "from main import process_csv_folder\n",
        "\n",
        "class TestProcessCSVFolder(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tempdir = tempfile.TemporaryDirectory()\n",
        "        self.orig_cwd = os.getcwd()\n",
        "        os.chdir(self.tempdir.name)\n",
        "\n",
        "    def tearDown(self):\n",
        "        os.chdir(self.orig_cwd)\n",
        "        self.tempdir.cleanup()\n",
        "\n",
        "    def write_file(self, name: str, content: str):\n",
        "        with open(name, 'w') as f:\n",
        "            f.write(content)\n",
        "\n",
        "    def read_output(self, name: str):\n",
        "        with open(name, 'r') as f:\n",
        "            return [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    def test_more_than_two_csv_returns_minus1(self):\n",
        "        # Three CSVs should return -1 and produce no outputs\n",
        "        for name in ['a.csv', 'b.csv', 'c.csv']:\n",
        "            self.write_file(name, 'x,y\\n1,2\\n')\n",
        "        result = asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        self.assertEqual(result, -1)\n",
        "        self.assertFalse(os.path.exists('a_output.csv'))\n",
        "        self.assertFalse(os.path.exists('b_output.csv'))\n",
        "        self.assertFalse(os.path.exists('c_output.csv'))\n",
        "\n",
        "    def test_two_csv_file1_output(self):\n",
        "        # Verify first file processing from prompt example\n",
        "        file1 = 'apple,  34.12345 , -12.5\\nbanana,42, hello\\n'\n",
        "        file2 = '   x,  y , z\\n1.2345 , -1.234 ,world\\n'\n",
        "        self.write_file('file1.csv', file1)\n",
        "        self.write_file('file2.csv', file2)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        out1 = self.read_output('file1_output.csv')\n",
        "        self.assertEqual(out1, ['APPLE,34.123,0', 'BANANA,42,HELLO'])\n",
        "\n",
        "    def test_two_csv_file2_output(self):\n",
        "        # Verify second file processing from prompt example\n",
        "        file1 = 'apple,  34.12345 , -12.5\\nbanana,42, hello\\n'\n",
        "        file2 = '   x,  y , z\\n1.2345 , -1.234 ,world\\n'\n",
        "        self.write_file('file1.csv', file1)\n",
        "        self.write_file('file2.csv', file2)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        out2 = self.read_output('file2_output.csv')\n",
        "        self.assertEqual(out2, ['X,Y,Z', '1.234,0,WORLD'])\n",
        "\n",
        "    def test_ignore_inconsistent_rows(self):\n",
        "        # Rows with mismatched columns should be ignored, no blank rows\n",
        "        content = (\n",
        "            'c1,c2,c3\\n'\n",
        "            '1,2,3\\n'\n",
        "            '4,5\\n'      # too few\n",
        "            '6,7,8,9\\n'  # too many\n",
        "            '7,8,9\\n'    # valid\n",
        "        )\n",
        "        self.write_file('test.csv', content)\n",
        "        self.write_file('other.csv', content)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        lines = self.read_output('test_output.csv')\n",
        "        self.assertEqual(lines, ['C1,C2,C3', '1,2,3', '7,8,9'])\n",
        "\n",
        "    def test_ignore_blank_rows(self):\n",
        "        # Blank lines should be skipped, no inconsistent rows\n",
        "        content = (\n",
        "            'h1,h2\\n'\n",
        "            '\\n'         # blank\n",
        "            '1,2\\n'      # valid\n",
        "            '\\n'         # blank\n",
        "            '3,4\\n'      # valid\n",
        "        )\n",
        "        self.write_file('a.csv', content)\n",
        "        self.write_file('b.csv', content)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        lines = self.read_output('a_output.csv')\n",
        "        self.assertEqual(lines, ['H1,H2', '1,2', '3,4'])\n",
        "\n",
        "    def test_malformed_floats_become_zero(self):\n",
        "        # Malformed floats result in 0\n",
        "        content = 'v1,v2\\nX,notfloat\\n'\n",
        "        self.write_file('vals.csv', content)\n",
        "        self.write_file('other.csv', content)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        lines = self.read_output('vals_output.csv')\n",
        "        self.assertIn('X,0', lines)\n",
        "\n",
        "    def test_negative_floats_clamped_zero(self):\n",
        "        # Negative floats should be clamped to 0\n",
        "        content = 'v1,v2\\nY,-0.0001\\n'\n",
        "        self.write_file('n.csv', content)\n",
        "        self.write_file('m.csv', content)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        lines = self.read_output('n_output.csv')\n",
        "        self.assertIn('Y,0', lines)\n",
        "\n",
        "    def test_valid_floats_rounded_three_decimals(self):\n",
        "        # Valid floats rounded to 3 decimals\n",
        "        content = 'v1,v2\\nZ,2.71828\\n'\n",
        "        self.write_file('p.csv', content)\n",
        "        self.write_file('q.csv', content)\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        lines = self.read_output('p_output.csv')\n",
        "        self.assertIn('Z,2.718', lines)\n",
        "\n",
        "    def test_ignore_non_csv_with_two_csv(self):\n",
        "        # Two CSVs and one non-CSV file: only CSVs processed\n",
        "        self.write_file('file1.csv', 'a,b\\n1,2\\n')\n",
        "        self.write_file('file2.csv', 'x,y\\n3,4\\n')\n",
        "        self.write_file('readme.txt', 'ignore me')\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        self.assertTrue(os.path.exists('file1_output.csv'))\n",
        "        self.assertTrue(os.path.exists('file2_output.csv'))\n",
        "\n",
        "    def test_non_csv_not_generated(self):\n",
        "        # Ensure non-CSV file does not get an output\n",
        "        self.write_file('a.csv', 'x,y\\n1,2\\n')\n",
        "        self.write_file('b.csv', 'x,y\\n3,4\\n')\n",
        "        self.write_file('c.md', 'ignore')\n",
        "        asyncio.run(process_csv_folder(self.tempdir.name))\n",
        "        self.assertFalse(os.path.exists('c_output.md'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: <https://rlhf-v3.turing.com/prompt/664dc169-aa47-4773-8127-74c3d374a899?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F74376%2Fview>\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import os\n",
        "import csv\n",
        "\n",
        "async def process_line(line, num_columns):\n",
        "    # Split line by ','\n",
        "    items = [item.strip() for item in line.split(',')]\n",
        "    # If row length is inconsistent, return None\n",
        "    if len(items) != num_columns:\n",
        "        return None\n",
        "        \n",
        "    processed_items = []\n",
        "    for item in items:\n",
        "        # Normalize strings\n",
        "        if item.isalpha() or not item:\n",
        "\n",
        "          # <Issue>: <Empty values always become \"\", even for numeric columns, instead it should be 0 for numeric values>\n",
        "\n",
        "            processed_items.append(item.upper())\n",
        "        # Normalize numbers\n",
        "        else:\n",
        "            try:\n",
        "                num = float(item)\n",
        "                num = max(0, round(num, 3))  # Round and clamp numbers\n",
        "                processed_items.append(str(num))\n",
        "            except ValueError:  # Handle malformed floats\n",
        "                processed_items.append(\"\")\n",
        "    \n",
        "    return processed_items\n",
        "\n",
        "async def process_file(input_path, output_path):\n",
        "    async with aiofiles.open(input_path, mode='r') as infile, aiofiles.open(output_path, mode='w', newline='') as outfile:\n",
        "      # <Issue>: <Loads entire file at once, not truly async>\n",
        "        reader = csv.reader(await infile.readlines())\n",
        "      # <Issue>: <Outfile is an async file object (aiofiles), which can't be passed to csv.writer>\n",
        "        writer = csv.writer(outfile)\n",
        "        \n",
        "        headers = next(reader, None)\n",
        "        if headers is None:\n",
        "            return\n",
        "        \n",
        "        num_columns = len(headers)\n",
        "        \n",
        "        processed_header = await process_line(','.join(headers), num_columns)\n",
        "        # <Issue>: <Writer is sync, cannot be awaited>\n",
        "        if processed_header:\n",
        "            await writer.writerow(processed_header)\n",
        "        \n",
        "        # <Issue>: <reader is a list, so async for doesnâ€™t work here>\n",
        "        async for idx, row in enumerate(reader):\n",
        "            processed_row = await process_line(','.join(row), num_columns)\n",
        "            if processed_row:\n",
        "                await writer.writerow(processed_row)\n",
        "\n",
        "async def process_csv_folder(folder_path: str) -> int:\n",
        "    # List CSV files in folder\n",
        "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "    \n",
        "    # Ensure exactly two CSV files\n",
        "    if len(files) != 2:\n",
        "        return -1\n",
        "    \n",
        "    tasks = []\n",
        "    for file in files:\n",
        "        input_path = os.path.join(folder_path, file)\n",
        "        output_path = os.path.join(folder_path, f\"{os.path.splitext(file)[0]}_output.csv\")\n",
        "        tasks.append(process_file(input_path, output_path))\n",
        "    \n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "# Example usage:\n",
        "# asyncio.run(process_csv_folder('/path/to/csv/folder'))\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}