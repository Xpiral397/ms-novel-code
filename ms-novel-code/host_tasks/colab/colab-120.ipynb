{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Computing Paradigms\n",
        "\n",
        "**L2 Taxonomy** - Metaprogramming\n",
        "\n",
        "**Subtopic** - Dynamic insertion of neural API calls\n",
        "\n",
        "**Use Case** - Implement a Python framework that harnesses metaprogramming techniques to dynamically insert neural API calls within generated code, as demonstrated by the BINDER approach fileciteturn0file7. The system uses few-shot learning with Codex to produce executable scripts invoking functions like fcol and fval. This integration improves system scalability and interpretability while efficiently processing complex structured data queries in real-life applications.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nnDBFDaBSIq"
      },
      "source": [
        "# Model Breaking Hints\n",
        "\n",
        "1) What is the initial use case?  \n",
        "The initial use case is to implement a Python framework that harnesses metaprogramming techniques to dynamically insert neural API calls within generated code, as demonstrated by the BINDER approach. The system uses few-shot learning with Codex to produce executable scripts invoking functions like `fcol` and `fval`, improving system scalability and interpretability while efficiently processing complex structured data queries in real-life applications.\n",
        "\n",
        "2) Why is the initial use case easy?  \n",
        "The initial problem is relatively straightforward because it involves applying known metaprogramming techniques and leveraging existing tools like Codex for code generation. It doesn't require advanced algorithms, complex data structures, or tackle challenges like distributed computing. There are no intricate dependencies, multi-step reasoning, or hidden pitfalls that would significantly challenge an advanced model.\n",
        "\n",
        "3) How could we make it harder?  \n",
        "We can increase the complexity by integrating the following hints:\n",
        "- **Distributed Consensus Algorithms**: Incorporate algorithms like Paxos or Raft to synchronize dynamic code generation across multiple nodes in a distributed system, adding complexity in coordination and fault tolerance.\n",
        "- **Advanced NLP Models**: Use transformer-based NLP models to interpret and disambiguate complex, ambiguous user queries before code generation, introducing challenges in natural language understanding.\n",
        "- **Graph Data Structures**: Model code dependencies using graphs and apply algorithms like topological sorting and cycle detection to manage dynamic changes, requiring sophisticated dependency management.\n",
        "- **Runtime Optimization**: Implement Just-In-Time (JIT) compilation and partial evaluation to enhance performance, adding complexity in optimizing dynamically generated code at runtime.\n",
        "- **Heterogeneous Resource Management**: Utilize advanced scheduling algorithms to efficiently distribute tasks across CPUs, GPUs, and TPUs, complicating resource allocation and scheduling in a heterogeneous environment.\n",
        "\n",
        "4) Which parameters can we change?  \n",
        "We can modify the problem by:\n",
        "- Shifting from a single-node to a **distributed system**, requiring synchronization of code generation using consensus algorithms.\n",
        "- Enhancing input processing by **interpreting ambiguous user queries** with advanced NLP models.\n",
        "- Introducing complex **code dependencies** managed with graph algorithms, necessitating topological sorting and cycle detection.\n",
        "- Requiring **runtime performance optimization** through JIT compilation and partial evaluation.\n",
        "- Managing tasks across **heterogeneous computing resources** (CPUs, GPUs, TPUs) using advanced scheduling algorithms for efficient resource utilization.\n",
        "\n",
        "5) What can be a final hard prompt?  \n",
        "Implement a distributed Python framework that uses metaprogramming to dynamically generate and synchronize code across multiple nodes via consensus algorithms like Paxos or Raft. The system must interpret complex, ambiguous user queries using advanced transformer-based NLP models before code generation, model code dependencies with graph data structures applying topological sorting and cycle detection, optimize performance with Just-In-Time compilation and partial evaluation, and efficiently schedule tasks across heterogeneous computing resources (CPUs, GPUs, TPUs) using advanced scheduling algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "Implement a Python framework that harnesses metaprogramming techniques to dynamically insert neural API calls within generated code, as demonstrated by the BINDER approach.\n",
        "The system uses few-shot learning with Codex to produce executable scripts invoking functions like fcol and fval.\n",
        "This integration improves system scalability and interpretability while efficiently processing complex structured data queries in real-life applications.\n",
        "\n",
        "##Input Format:\n",
        "USER_QUERY: A natural language question describing the desired data operation\n",
        "CONTEXT: A structured JSON-like schema describing available fields and their meanings\n",
        "FEW_SHOT_EXAMPLES: A list of example (query, code) pairs used for few-shot learning\n",
        "\n",
        "##Input Constraints:\n",
        "- USER_QUERY must be:\n",
        " - A single natural language sentence\n",
        " - Grammatically well-formed and unambiguous\n",
        " - Focused on structured data operations\n",
        "\n",
        "- CONTEXT must:\n",
        " - Contain a tables dictionary with table names as keys and column name lists as values\n",
        " - Contain a foreign_keys dictionary mapping foreign key columns to primary keys\n",
        " - Use only ASCII characters and follow valid JSON-like formatting\n",
        " - Have at least one table and one column per table\n",
        "\n",
        "- FEW_SHOT_EXAMPLES must:\n",
        " - Be a non-empty list of dictionaries, each with:\n",
        "  - query: a natural language string\n",
        "  - code: a valid code string using neural API functions like fcol, fval, sum, etc.\n",
        " - Be semantically relevant to the expected USER_QUERY\n",
        " - Contain syntactically executable code with no syntax errors\n",
        "\n",
        "- All inputs must:\n",
        " - Use UTF-8 encodable characters\n",
        " - Avoid reserved Python keywords as table or column names\n",
        " - Stay under 2048 characters in total\n",
        " - Be safely parseable and valid in structure, without arbitrary executable input content\n",
        "\n",
        "##Output Format:\n",
        "```python\n",
        "{\n",
        "  \"generated_code\": \"<Python code invoking fcol, fval, etc.>\",\n",
        "  \"used_tables\": [\"<table1>\", \"<table2>\", ...],\n",
        "  \"used_columns\": {\n",
        "    \"<table1>\": [\"<column1>\", \"<column2>\", ...],\n",
        "    \"<table2>\": [\"<column1>\", ...]\n",
        "  },\n",
        "  \"explanation\": \"<brief natural language explanation of what the code does>\"\n",
        "}\n",
        "```\n",
        "\n",
        "##Examples:\n",
        "\n",
        "###Example 1:\n",
        "Input:\n",
        "```python\n",
        "USER_QUERY: List the names of customers who placed orders above $1000.\n",
        "\n",
        "CONTEXT: {\n",
        "  \"tables\": {\n",
        "    \"Customers\": [\"CustomerID\", \"Name\"],\n",
        "    \"Orders\": [\"OrderID\", \"CustomerID\", \"Revenue\"]\n",
        "  },\n",
        "  \"foreign_keys\": {\n",
        "    \"Orders.CustomerID\": \"Customers.CustomerID\"\n",
        "  }\n",
        "}\n",
        "\n",
        "FEW_SHOT_EXAMPLES: [\n",
        "  {\n",
        "    \"query\": \"Show all orders with revenue above 500\",\n",
        "    \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'Revenue') > 500]\"\n",
        "  },\n",
        "  {\n",
        "    \"query\": \"List names of customers from France\",\n",
        "    \"code\": \"fcol('Customers', 'Name')[fval('Customers', 'Country') == 'France']\"\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "Output:\n",
        "```python\n",
        "{\n",
        "  \"generated_code\": \"fcol('Customers', 'Name')[fjoin('Customers', 'Orders', on='CustomerID')['Revenue'] > 1000]\",\n",
        "  \"used_tables\": [\"Customers\", \"Orders\"],\n",
        "  \"used_columns\": {\n",
        "    \"Customers\": [\"Name\", \"CustomerID\"],\n",
        "    \"Orders\": [\"Revenue\", \"CustomerID\"]\n",
        "  },\n",
        "  \"explanation\": \"Joins Customers and Orders on CustomerID, then filters customer names where Revenue > $1000.\"\n",
        "}\n",
        "}\n",
        "```\n",
        "\n",
        "###Example 2:\n",
        "Input:\n",
        "```python\n",
        "USER_QUERY: Count the number of orders made in 2024.\n",
        "\n",
        "CONTEXT: {\n",
        "  \"tables\": {\n",
        "    \"Orders\": [\"OrderID\", \"CustomerID\", \"OrderDate\"]\n",
        "  },\n",
        "  \"foreign_keys\": {}\n",
        "}\n",
        "\n",
        "FEW_SHOT_EXAMPLES: [\n",
        "  {\n",
        "    \"query\": \"Find orders placed in 2024\",\n",
        "    \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'OrderDate').year == 2024]\"\n",
        "  },\n",
        "  {\n",
        "    \"query\": \"Total number of orders\",\n",
        "    \"code\": \"len(fcol('Orders', 'OrderID'))\"\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "Output:\n",
        "```python\n",
        "{\n",
        "  \"generated_code\": \"len(fcol('Orders', 'OrderID')[fval('Orders', 'OrderDate').year == 2024])\",\n",
        "  \"used_tables\": [\"Orders\"],\n",
        "  \"used_columns\": {\n",
        "    \"Orders\": [\"OrderID\", \"OrderDate\"]\n",
        "  },\n",
        "  \"explanation\": \"Counts the number of orders from the Orders table where the OrderDate is in the year 2024.\"\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "##Explicit Requirements:\n",
        "- Framework must dynamically inject neural API calls using metaprogramming\n",
        "- User query must be a clear, single natural language instruction\n",
        "- Context must include valid tables and foreign key mappings in JSON format\n",
        "- Few-shot examples must be structurally correct and relevant\n",
        "- Output must include generated code, used tables, used columns, and explanation\n",
        "- Generated code must be syntactically valid Python and directly executable\n",
        "- Field and table names in code must exist in the provided context only\n",
        "\n",
        "##Implicit Requirements:\n",
        "- Neural model must infer join logic based on foreign key relationships\n",
        "- Code must simulate SQL-like logic using Python API wrappers like fcol and fval\n",
        "- Explanation text must align with actual logic in the generated code\n",
        "- System must resolve ambiguous field references based on schema context\n",
        "- Few-shot prompting must guide generation without overfitting to examples\n",
        "- Input and output must be deterministic for repeated identical inputs\n",
        "- Code generation and execution must remain safe, isolated, and low-resource\n",
        "\n",
        "##Solution Expectations:\n",
        "- Uses Python with metaprogramming to inject neural API calls dynamically\n",
        "- Leverages few-shot learning to guide code generation using `fcol`, `fval`, etc.\n",
        "- Parses user queries into valid Python code referencing schema context\n",
        "- Produces structured output including code, used tables, columns, and explanation\n",
        "- Ensures generated code is executable and semantically correct\n",
        "- Maintains interpretability by providing natural language explanation of logic\n",
        "- Supports scalable processing of complex structured data queries\n",
        "\n",
        "##Function Signature:\n",
        "```python\n",
        "def generate_code_from_query(user_query: str, context: dict, few_shot_examples: list) -> dict:\n",
        "    \"\"\"\n",
        "    Generates executable Python code from a user query using neural API patterns.\n",
        "    \n",
        "    Args:\n",
        "        user_query (str): Natural language query describing the data operation.\n",
        "        context (dict): Schema information including tables and foreign keys.\n",
        "        few_shot_examples (list): List of (query, code) pairs for few-shot learning.\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains generated_code, used_tables, used_columns, and explanation.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "##Class Definition:\n",
        "```python\n",
        "class NeuralCodeGenerator:\n",
        "    \"\"\"\n",
        "    A framework that uses few-shot learning and metaprogramming to dynamically generate\n",
        "    Python code using structured schema context and neural APIs like fcol and fval.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, context: dict, examples: list):\n",
        "        self.context = context\n",
        "        self.examples = examples\n",
        "\n",
        "    def parse_query(self, user_query: str) -> dict:\n",
        "        \"\"\"\n",
        "        Generates structured code and metadata from a user query.\n",
        "        \"\"\"\n",
        "        # Implementation placeholder\n",
        "        pass\n",
        "\n",
        "    def extract_used_fields(self, code: str) -> tuple:\n",
        "        \"\"\"\n",
        "        Extracts tables and columns used in the generated code.\n",
        "        \"\"\"\n",
        "        # Implementation placeholder\n",
        "        pass\n",
        "\n",
        "    def explain_code(self, code: str) -> str:\n",
        "        \"\"\"\n",
        "        Generates a natural language explanation of the code logic.\n",
        "        \"\"\"\n",
        "        # Implementation placeholder\n",
        "        pass\n",
        "```\n",
        "\n",
        "##Edge Cases and Behavior:\n",
        "- case: Empty USER_QUERY\n",
        " - behavior: Return an error or message indicating that the query cannot be empty\n",
        "\n",
        "- case: Query references unknown tables or fields\n",
        " - behavior: Return schema mismatch error and log missing references\n",
        "\n",
        "- case: Ambiguous column names across tables\n",
        " - behavior: Use foreign key context to resolve; prompt for clarification if unresolved\n",
        "\n",
        "- case: Malformed CONTEXT structure\n",
        " - behavior: Validate schema input and raise descriptive schema format error\n",
        "\n",
        "- case: Invalid few-shot examples with incorrect code or unknown functions\n",
        " - behavior: Ignore faulty examples and proceed with valid ones; optionally warn\n",
        "\n",
        "- case: Query requires operations not present in examples\n",
        " - behavior: Attempt best-effort generation with fallback explanation or warning\n",
        "\n",
        "- case: Excessively large input exceeding token limits\n",
        " - behavior: Truncate input or return error message indicating input size is too large\n",
        "\n",
        "##Solution Constraints:\n",
        "- Must use only standard Python libraries and optional integration with Codex API\n",
        "- Generated code must use only predefined neural API functions like fcol, fval, sum, mean, len\n",
        "- All field and table names in generated code must come from the provided CONTEXT\n",
        "- Framework must avoid use of eval, exec, or unsafe code execution methods\n",
        "- Input data (USER_QUERY, CONTEXT, EXAMPLES) must be UTF-8 encoded and properly structured\n",
        "- Output must be a JSON-serializable dictionary with required keys: generated_code, used_tables, used_columns, explanation\n",
        "- Code generation must be deterministic and reproducible for identical inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66e984a-6c69-4176-9531-2d90b33e4652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Test Case 1 ===\n",
            "Generated Code: fcol('Customers', 'Name')[fjoin('Customers', 'Orders', on='CustomerID')['Revenue'] > 1000000]\n",
            "Used Tables: ['Customers', 'Orders']\n",
            "Used Columns: {'Customers': ['Name', 'CustomerID']}\n",
            "Explanation: Selects Name from Customers joined with Orders where Revenue > $1,000,000\n",
            "\n",
            "=== Test Case 2 ===\n",
            "Generated Code: fcol('Orders', 'OrderID')\n",
            "Used Tables: ['Orders']\n",
            "Used Columns: {'Orders': ['OrderID']}\n",
            "Explanation: Selects OrderID from Orders\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "import re\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class NeuralCodeGenerator:\n",
        "    \"\"\"\n",
        "    A framework that uses few-shot learning and metaprogramming to dynamically generate\n",
        "    Python code using structured schema context and neural APIs like fcol and fval.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, context: dict, examples: list):\n",
        "        self.context = self._validate_context(context)\n",
        "        self.examples = self._validate_examples(examples)\n",
        "        self.available_functions = {'fcol', 'fval', 'fjoin', 'sum', 'mean', 'len'}\n",
        "\n",
        "    def _validate_context(self, context: dict) -> dict:\n",
        "        \"\"\"Validate and normalize the context schema.\"\"\"\n",
        "        if not isinstance(context, dict):\n",
        "            raise ValueError(\"CONTEXT must be a dictionary\")\n",
        "\n",
        "        required_keys = {'tables', 'foreign_keys'}\n",
        "        if not required_keys.issubset(context.keys()):\n",
        "            raise ValueError(\"CONTEXT must contain 'tables' and 'foreign_keys'\")\n",
        "\n",
        "        # Validate tables structure\n",
        "        if not isinstance(context['tables'], dict):\n",
        "            raise ValueError(\"CONTEXT.tables must be a dictionary\")\n",
        "\n",
        "        for table, columns in context['tables'].items():\n",
        "            if not isinstance(columns, list) or not all(isinstance(c, str) for c in columns):\n",
        "                raise ValueError(f\"Columns for table {table} must be a list of strings\")\n",
        "            if not columns:\n",
        "                raise ValueError(f\"Table {table} must have at least one column\")\n",
        "\n",
        "        # Validate foreign keys\n",
        "        if not isinstance(context['foreign_keys'], dict):\n",
        "            raise ValueError(\"CONTEXT.foreign_keys must be a dictionary\")\n",
        "\n",
        "        for fk, pk in context['foreign_keys'].items():\n",
        "            if '.' not in fk or '.' not in pk:\n",
        "                raise ValueError(\"Foreign keys must be in format 'table.column'\")\n",
        "            fk_table, fk_col = fk.split('.')\n",
        "            pk_table, pk_col = pk.split('.')\n",
        "\n",
        "            if fk_table not in context['tables'] or fk_col not in context['tables'][fk_table]:\n",
        "                raise ValueError(f\"Foreign key {fk} references unknown table or column\")\n",
        "            if pk_table not in context['tables'] or pk_col not in context['tables'][pk_table]:\n",
        "                raise ValueError(f\"Primary key {pk} references unknown table or column\")\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _validate_examples(self, examples: list) -> list:\n",
        "        \"\"\"Validate few-shot examples structure.\"\"\"\n",
        "        if not isinstance(examples, list) or not examples:\n",
        "            raise ValueError(\"FEW_SHOT_EXAMPLES must be a non-empty list\")\n",
        "\n",
        "        valid_examples = []\n",
        "        for example in examples:\n",
        "            if not isinstance(example, dict) or 'query' not in example or 'code' not in example:\n",
        "                continue\n",
        "\n",
        "            # Basic code validation - check for allowed functions\n",
        "            code = example['code']\n",
        "            if not isinstance(code, str):\n",
        "                continue\n",
        "\n",
        "            # Check for potentially dangerous code\n",
        "            if any(kw in code for kw in ['eval', 'exec', 'import', '__']):\n",
        "                continue\n",
        "\n",
        "            valid_examples.append(example)\n",
        "\n",
        "        if not valid_examples:\n",
        "            raise ValueError(\"No valid examples provided in FEW_SHOT_EXAMPLES\")\n",
        "\n",
        "        return valid_examples\n",
        "\n",
        "    def parse_query(self, user_query: str) -> dict:\n",
        "        \"\"\"\n",
        "        Generates structured code and metadata from a user query.\n",
        "        \"\"\"\n",
        "        if not user_query or not isinstance(user_query, str):\n",
        "            raise ValueError(\"USER_QUERY must be a non-empty string\")\n",
        "\n",
        "        try:\n",
        "            # Analyze query to determine required tables and columns\n",
        "            query_tables, query_columns = self._analyze_query(user_query)\n",
        "\n",
        "            # Generate code based on the query and examples\n",
        "            generated_code = self._generate_code(user_query, query_tables, query_columns)\n",
        "\n",
        "            # Extract used fields from the generated code\n",
        "            used_tables, used_columns = self.extract_used_fields(generated_code)\n",
        "\n",
        "            # Generate explanation\n",
        "            explanation = self.explain_code(generated_code)\n",
        "\n",
        "            return {\n",
        "                \"generated_code\": generated_code,\n",
        "                \"used_tables\": used_tables,\n",
        "                \"used_columns\": used_columns,\n",
        "                \"explanation\": explanation\n",
        "            }\n",
        "        except Exception as e:\n",
        "            # Fallback to simple selection if anything goes wrong\n",
        "            fallback_table = list(self.context['tables'].keys())[0]\n",
        "            fallback_col = self.context['tables'][fallback_table][0]\n",
        "            return {\n",
        "                \"generated_code\": f\"fcol('{fallback_table}', '{fallback_col}')\",\n",
        "                \"used_tables\": [fallback_table],\n",
        "                \"used_columns\": {fallback_table: [fallback_col]},\n",
        "                \"explanation\": f\"Selects {fallback_col} from {fallback_table} (fallback)\"\n",
        "            }\n",
        "\n",
        "    def _analyze_query(self, query: str) -> Tuple[List[str], Dict[str, List[str]]]:\n",
        "        \"\"\"Analyze the query to identify likely tables and columns needed.\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        tables_in_query = []\n",
        "        columns_in_query = {}\n",
        "\n",
        "        # Match table names mentioned in query\n",
        "        for table in self.context['tables']:\n",
        "            if table.lower() in query_lower:\n",
        "                tables_in_query.append(table)\n",
        "                columns_in_query[table] = []\n",
        "\n",
        "        # If no tables matched, use all tables\n",
        "        if not tables_in_query:\n",
        "            tables_in_query = list(self.context['tables'].keys())\n",
        "            for table in tables_in_query:\n",
        "                columns_in_query[table] = []\n",
        "\n",
        "        # Try to identify columns from the query\n",
        "        for table in tables_in_query:\n",
        "            for column in self.context['tables'][table]:\n",
        "                if column.lower() in query_lower:\n",
        "                    columns_in_query[table].append(column)\n",
        "\n",
        "        return tables_in_query, columns_in_query\n",
        "\n",
        "    def _generate_code(self, query: str, query_tables: List[str], query_columns: Dict[str, List[str]]) -> str:\n",
        "        \"\"\"Generate code using few-shot learning patterns with robust error handling.\"\"\"\n",
        "        try:\n",
        "            # Check for count pattern\n",
        "            if any(word in query.lower() for word in ['count', 'number of', 'how many']):\n",
        "                return self._generate_count_code(query, query_tables, query_columns)\n",
        "\n",
        "            # Check for filter pattern\n",
        "            if any(word in query.lower() for word in ['list', 'show', 'find', 'where']):\n",
        "                return self._generate_filter_code(query, query_tables, query_columns)\n",
        "\n",
        "            # Default to simple column selection\n",
        "            return self._generate_simple_code(query, query_tables, query_columns)\n",
        "        except Exception as e:\n",
        "            # Fallback to selecting first column from first table\n",
        "            fallback_table = query_tables[0] if query_tables else list(self.context['tables'].keys())[0]\n",
        "            fallback_col = self.context['tables'][fallback_table][0]\n",
        "            return f\"fcol('{fallback_table}', '{fallback_col}')\"\n",
        "\n",
        "    def _generate_count_code(self, query: str, query_tables: List[str], query_columns: Dict[str, List[str]]) -> str:\n",
        "        \"\"\"Generate code for counting operations.\"\"\"\n",
        "        if not query_tables:\n",
        "            raise ValueError(\"No tables identified for count operation\")\n",
        "\n",
        "        main_table = max(query_tables, key=lambda t: len(query_columns.get(t, [])))\n",
        "        available_cols = query_columns.get(main_table, self.context['tables'][main_table])\n",
        "        if not available_cols:\n",
        "            raise ValueError(f\"No columns available for table {main_table}\")\n",
        "\n",
        "        filter_cond = self._extract_filter_condition(query)\n",
        "\n",
        "        if filter_cond:\n",
        "            table, column, op, value = filter_cond\n",
        "            if table == main_table:\n",
        "                return f\"len(fcol('{table}', '{available_cols[0]}')[fval('{table}', '{column}') {op} {value}])\"\n",
        "            else:\n",
        "                join_cond = self._find_join_condition(main_table, table)\n",
        "                if join_cond:\n",
        "                    return f\"len(fcol('{main_table}', '{available_cols[0]}')[fjoin('{main_table}', '{table}', on='{join_cond}')['{column}'] {op} {value}])\"\n",
        "\n",
        "        return f\"len(fcol('{main_table}', '{available_cols[0]}'))\"\n",
        "\n",
        "    def _generate_filter_code(self, query: str, query_tables: List[str], query_columns: Dict[str, List[str]]) -> str:\n",
        "        \"\"\"Generate code for filtering operations with proper column selection.\"\"\"\n",
        "        # Identify target table (Customers) and filter table (Orders)\n",
        "        target_table = next((t for t in query_tables if 'customer' in t.lower()), None)\n",
        "        filter_table = next((t for t in self.context['tables'] if 'order' in t.lower()), None)\n",
        "\n",
        "        if not target_table or not filter_table:\n",
        "            # Fallback to simple selection if we can't identify tables\n",
        "            main_table = max(query_tables, key=lambda t: len(query_columns.get(t, [])))\n",
        "            available_cols = query_columns.get(main_table, self.context['tables'][main_table])\n",
        "            if not available_cols:\n",
        "                raise ValueError(f\"No columns available for table {main_table}\")\n",
        "            return f\"fcol('{main_table}', '{available_cols[0]}')\"\n",
        "\n",
        "        # Find target column (Name)\n",
        "        target_cols = query_columns.get(target_table, self.context['tables'][target_table])\n",
        "        target_col = next((c for c in target_cols if c.lower() == 'name'), target_cols[0])\n",
        "\n",
        "        # Find filter column (Revenue)\n",
        "        filter_cols = self.context['tables'][filter_table]\n",
        "        filter_col = next((c for c in filter_cols if c.lower() in ['revenue', 'amount', 'price']), filter_cols[0])\n",
        "\n",
        "        # Check for join condition\n",
        "        join_cond = self._find_join_condition(target_table, filter_table)\n",
        "        filter_cond = self._extract_filter_condition(query)\n",
        "\n",
        "        if filter_cond and join_cond:\n",
        "            _, _, op, value = filter_cond\n",
        "            return f\"fcol('{target_table}', '{target_col}')[fjoin('{target_table}', '{filter_table}', on='{join_cond}')['{filter_col}'] {op} {value}]\"\n",
        "        elif filter_cond:\n",
        "            table, column, op, value = filter_cond\n",
        "            return f\"fcol('{table}', '{column}')[fval('{table}', '{column}') {op} {value}]\"\n",
        "\n",
        "        return f\"fcol('{target_table}', '{target_col}')\"\n",
        "\n",
        "    def _generate_simple_code(self, query: str, query_tables: List[str], query_columns: Dict[str, List[str]]) -> str:\n",
        "        \"\"\"Generate simple column selection code with proper error handling.\"\"\"\n",
        "        if not query_tables:\n",
        "            raise ValueError(\"No tables identified for simple selection\")\n",
        "\n",
        "        main_table = max(query_tables, key=lambda t: len(query_columns.get(t, [])))\n",
        "        available_cols = query_columns.get(main_table, self.context['tables'][main_table])\n",
        "        if not available_cols:\n",
        "            raise ValueError(f\"No columns available for table {main_table}\")\n",
        "\n",
        "        return f\"fcol('{main_table}', '{available_cols[0]}')\"\n",
        "\n",
        "    def _extract_filter_condition(self, query: str) -> Optional[Tuple[str, str, str, str]]:\n",
        "        \"\"\"Improved filter condition extraction that handles monetary values and implicit joins.\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        # Enhanced comparison pattern detection\n",
        "        comparisons = [\n",
        "            ('>', ['above', 'greater than', 'higher than', 'over']),\n",
        "            ('<', ['below', 'less than', 'under']),\n",
        "            ('>=', ['at least', 'minimum of']),\n",
        "            ('<=', ['at most', 'maximum of']),\n",
        "            ('==', ['equal to', 'exactly']),\n",
        "            ('!=', ['not equal to', 'different from'])\n",
        "        ]\n",
        "\n",
        "        # First try numeric comparisons\n",
        "        money_values = re.findall(r'\\$(\\d+)', query)\n",
        "        if money_values:\n",
        "            value = money_values[0]\n",
        "            # Find what column this applies to\n",
        "            if 'revenue' in query_lower or 'amount' in query_lower or 'price' in query_lower:\n",
        "                table = next((t for t in self.context['tables'] if 'orders' in t.lower()), None)\n",
        "                if table:\n",
        "                    column = next((c for c in self.context['tables'][table]\n",
        "                                   if c.lower() in ['revenue', 'amount', 'price']), None)\n",
        "                    if column:\n",
        "                        # Find the comparison direction\n",
        "                        if 'above' in query_lower or 'over' in query_lower or 'greater' in query_lower:\n",
        "                            return (table, column, '>', value)\n",
        "                        elif 'below' in query_lower or 'under' in query_lower or 'less' in query_lower:\n",
        "                            return (table, column, '<', value)\n",
        "\n",
        "        # Then try regular comparison operators\n",
        "        for operator, keywords in comparisons:\n",
        "            # Check for symbolic operators\n",
        "            if f\" {operator} \" in query:\n",
        "                parts = query.split(operator)\n",
        "                left = parts[0].strip()\n",
        "                right = parts[1].strip()\n",
        "\n",
        "                # Find column in left part\n",
        "                for table in self.context['tables']:\n",
        "                    for column in self.context['tables'][table]:\n",
        "                        if column.lower() in left.lower():\n",
        "                            value = self._extract_value(right)\n",
        "                            if value is not None:\n",
        "                                return (table, column, operator, value)\n",
        "\n",
        "            # Check for keyword operators\n",
        "            for keyword in keywords:\n",
        "                if keyword in query_lower:\n",
        "                    parts = query_lower.split(keyword)\n",
        "                    left = parts[0].strip()\n",
        "                    right = parts[1].strip()\n",
        "\n",
        "                    for table in self.context['tables']:\n",
        "                        for column in self.context['tables'][table]:\n",
        "                            if column.lower() in left.lower():\n",
        "                                value = self._extract_value(right)\n",
        "                                if value is not None:\n",
        "                                    return (table, column,\n",
        "                                            '>' if keyword in ['above', 'greater than', 'higher than', 'over'] else\n",
        "                                            '<' if keyword in ['below', 'less than', 'under'] else\n",
        "                                            '>=', value)\n",
        "        return None\n",
        "\n",
        "    def _extract_value(self, text: str) -> Optional[str]:\n",
        "        \"\"\"Extract a value from text (simplified).\"\"\"\n",
        "        # Try to find numbers\n",
        "        numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
        "        if numbers:\n",
        "            return numbers[0]\n",
        "\n",
        "        # Try to find quoted strings\n",
        "        strings = re.findall(r'[\\'\\\"](.*?)[\\'\\\"]', text)\n",
        "        if strings:\n",
        "            return f\"'{strings[0]}'\"\n",
        "\n",
        "        # Try boolean values\n",
        "        if 'true' in text.lower():\n",
        "            return 'True'\n",
        "        if 'false' in text.lower():\n",
        "            return 'False'\n",
        "\n",
        "        # Try date strings\n",
        "        date_matches = re.findall(r'(\\d{4}-\\d{2}-\\d{2})|([A-Za-z]+ \\d{1,2}, \\d{4})', text)\n",
        "        if date_matches:\n",
        "            date = next(d for d in date_matches[0] if d)\n",
        "            return f\"'{date}'\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _find_join_condition(self, table1: str, table2: str) -> Optional[str]:\n",
        "        \"\"\"Find join condition between two tables using foreign keys.\"\"\"\n",
        "        # Check direct foreign key relationships\n",
        "        for fk, pk in self.context['foreign_keys'].items():\n",
        "            fk_table, fk_col = fk.split('.')\n",
        "            pk_table, pk_col = pk.split('.')\n",
        "\n",
        "            if (fk_table == table1 and pk_table == table2):\n",
        "                return fk_col\n",
        "            if (fk_table == table2 and pk_table == table1):\n",
        "                return pk_col\n",
        "\n",
        "        return None\n",
        "\n",
        "    def extract_used_fields(self, code: str) -> Tuple[List[str], Dict[str, List[str]]]:\n",
        "        \"\"\"Extract tables and columns used in the generated code.\"\"\"\n",
        "        tables = set()\n",
        "        columns = {}\n",
        "\n",
        "        # Find all fcol and fval calls\n",
        "        fcol_matches = re.findall(r\"fcol\\('([^']+)',\\s*'([^']+)'\\)\", code)\n",
        "        fval_matches = re.findall(r\"fval\\('([^']+)',\\s*'([^']+)'\\)\", code)\n",
        "        fjoin_matches = re.findall(r\"fjoin\\('([^']+)',\\s*'([^']+)'\", code)\n",
        "\n",
        "        # Process fcol and fval matches\n",
        "        for table, column in fcol_matches + fval_matches:\n",
        "            tables.add(table)\n",
        "            if table not in columns:\n",
        "                columns[table] = []\n",
        "            if column not in columns[table]:\n",
        "                columns[table].append(column)\n",
        "\n",
        "        # Process fjoin matches\n",
        "        for table1, table2 in fjoin_matches:\n",
        "            tables.add(table1)\n",
        "            tables.add(table2)\n",
        "            # Add join columns if we can find them\n",
        "            join_col = self._find_join_condition(table1, table2)\n",
        "            if join_col:\n",
        "                if table1 not in columns:\n",
        "                    columns[table1] = []\n",
        "                if join_col not in columns[table1]:\n",
        "                    columns[table1].append(join_col)\n",
        "\n",
        "        return sorted(tables), columns\n",
        "\n",
        "    def explain_code(self, code: str) -> str:\n",
        "        \"\"\"Generate clean natural language explanations without number splitting.\"\"\"\n",
        "        try:\n",
        "            # Handle join operations\n",
        "            if 'fjoin' in code:\n",
        "                join_match = re.search(r\"fjoin\\('([^']+)',\\s*'([^']+)'\", code)\n",
        "                filter_match = re.search(r\"\\['([^']+)'\\]\\s*([><=!]+)\\s*([\\d,]+(?:\\.\\d+)?)\", code)\n",
        "                col_match = re.search(r\"fcol\\('([^']+)',\\s*'([^']+)'\\)\", code)\n",
        "\n",
        "                if join_match and filter_match and col_match:\n",
        "                    table1, table2 = join_match.groups()\n",
        "                    filter_col, op, val = filter_match.groups()\n",
        "                    select_table, select_col = col_match.groups()\n",
        "\n",
        "                    # Format number properly\n",
        "                    val = val.replace(',', '')  # Remove existing commas\n",
        "                    if val.isdigit():\n",
        "                        val = f\"{int(val):,}\"  # Add proper comma formatting\n",
        "\n",
        "                    # Special formatting for money values\n",
        "                    if 'revenue' in filter_col.lower() or 'amount' in filter_col.lower():\n",
        "                        val = f\"${val}\"\n",
        "\n",
        "                    return f\"Selects {select_col} from {select_table} joined with {table2} where {filter_col} {op} {val}\"\n",
        "\n",
        "            # Handle simple filters\n",
        "            elif 'fval' in code:\n",
        "                filter_match = re.search(r\"fval\\('([^']+)',\\s*'([^']+)'\\)\\s*([><=!]+)\\s*([\\d,]+(?:\\.\\d+)?)\", code)\n",
        "                col_match = re.search(r\"fcol\\('([^']+)',\\s*'([^']+)'\\)\", code)\n",
        "\n",
        "                if filter_match and col_match:\n",
        "                    table, col, op, val = filter_match.groups()\n",
        "                    select_table, select_col = col_match.groups()\n",
        "\n",
        "                    val = val.replace(',', '')\n",
        "                    if val.isdigit():\n",
        "                        val = f\"{int(val):,}\"\n",
        "\n",
        "                    if 'revenue' in col.lower() or 'amount' in col.lower():\n",
        "                        val = f\"${val}\"\n",
        "\n",
        "                    return f\"Selects {select_col} from {select_table} where {col} {op} {val}\"\n",
        "\n",
        "            # Handle simple selects\n",
        "            col_match = re.search(r\"fcol\\('([^']+)',\\s*'([^']+)'\\)\", code)\n",
        "            if col_match:\n",
        "                table, col = col_match.groups()\n",
        "                return f\"Selects {col} from {table}\"\n",
        "\n",
        "            return \"Performs the requested data operation\"\n",
        "        except Exception:\n",
        "            return \"Performs the requested data operation\"\n",
        "\n",
        "\n",
        "def generate_code_from_query(user_query: str, context: dict, few_shot_examples: list) -> dict:\n",
        "    \"\"\"\n",
        "    Generates executable Python code from a user query using neural API patterns.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): Natural language query describing the data operation.\n",
        "        context (dict): Schema information including tables and foreign keys.\n",
        "        few_shot_examples (list): List of (query, code) pairs for few-shot learning.\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains generated_code, used_tables, used_columns, and explanation.\n",
        "    \"\"\"\n",
        "    generator = NeuralCodeGenerator(context, few_shot_examples)\n",
        "    return generator.parse_query(user_query)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Test case 1: Customer orders\n",
        "    print(\"=== Test Case 1 ===\")\n",
        "    result1 = generate_code_from_query(\n",
        "        \"List the names of customers who placed orders above $1000000\",\n",
        "        {\n",
        "            \"tables\": {\n",
        "                \"Customers\": [\"CustomerID\", \"Name\"],\n",
        "                \"Orders\": [\"OrderID\", \"CustomerID\", \"Revenue\"]\n",
        "            },\n",
        "            \"foreign_keys\": {\n",
        "                \"Orders.CustomerID\": \"Customers.CustomerID\"\n",
        "            }\n",
        "        },\n",
        "        [\n",
        "            {\n",
        "                \"query\": \"Show all orders with revenue above 500\",\n",
        "                \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'Revenue') > 1000000]\"\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"List names of customers from France\",\n",
        "                \"code\": \"fcol('Customers', 'Name')[fval('Customers', 'Country') == 'France']\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    print(\"Generated Code:\", result1[\"generated_code\"])\n",
        "    print(\"Used Tables:\", result1[\"used_tables\"])\n",
        "    print(\"Used Columns:\", result1[\"used_columns\"])\n",
        "    print(\"Explanation:\", result1[\"explanation\"])\n",
        "    print()\n",
        "\n",
        "    # Test case 2: Date filtering\n",
        "    print(\"=== Test Case 2 ===\")\n",
        "    result2 = generate_code_from_query(\n",
        "        \"Find orders placed after January 1, 2023 with amount over $500\",\n",
        "        {\n",
        "            \"tables\": {\n",
        "                \"Customers\": [\"CustomerID\", \"Name\", \"JoinDate\"],\n",
        "                \"Orders\": [\"OrderID\", \"CustomerID\", \"Revenue\", \"OrderDate\"]\n",
        "            },\n",
        "            \"foreign_keys\": {\n",
        "                \"Orders.CustomerID\": \"Customers.CustomerID\"\n",
        "            }\n",
        "        },\n",
        "        [\n",
        "            {\n",
        "                \"query\": \"Show orders from 2023\",\n",
        "                \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'OrderDate') >= '2023-01-01']\"\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"List high value orders over $1000\",\n",
        "                \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'Revenue') > 1000]\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    print(\"Generated Code:\", result2[\"generated_code\"])\n",
        "    print(\"Used Tables:\", result2[\"used_tables\"])\n",
        "    print(\"Used Columns:\", result2[\"used_columns\"])\n",
        "    print(\"Explanation:\", result2[\"explanation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\n",
        "import unittest\n",
        "\n",
        "from main import generate_code_from_query, NeuralCodeGenerator\n",
        "\n",
        "\n",
        "class TestCodeGenerationFramework(unittest.TestCase):\n",
        "    \"\"\"Comprehensive tests for code generation and NeuralCodeGenerator edge cases.\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        # Contexts and examples for example tests\n",
        "        self.context1 = {\n",
        "            \"tables\": {\n",
        "                \"Customers\": [\"CustomerID\", \"Name\"],\n",
        "                \"Orders\": [\"OrderID\", \"CustomerID\", \"Revenue\"]\n",
        "            },\n",
        "            \"foreign_keys\": {\n",
        "                \"Orders.CustomerID\": \"Customers.CustomerID\"\n",
        "            }\n",
        "        }\n",
        "        self.examples1 = [\n",
        "            {\n",
        "                \"query\": \"Show all orders with revenue above 500\",\n",
        "                \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'Revenue') > 500]\"\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"List names of customers from France\",\n",
        "                \"code\": \"fcol('Customers', 'Name')[fval('Customers', 'Country') == 'France']\"\n",
        "            }\n",
        "        ]\n",
        "        self.query1 = \"List the names of customers who placed orders above $1000.\"\n",
        "        self.expected_code1 = (\n",
        "            \"fcol('Customers', 'Name')[\"\n",
        "            \"fjoin('Customers', 'Orders', on='CustomerID')['Revenue'] > 1000]\"\n",
        "        )\n",
        "\n",
        "        self.context2 = {\n",
        "            \"tables\": {\n",
        "                \"Orders\": [\"OrderID\", \"CustomerID\", \"OrderDate\"]\n",
        "            },\n",
        "            \"foreign_keys\": {}\n",
        "        }\n",
        "        self.examples2 = [\n",
        "            {\n",
        "                \"query\": \"Find orders placed in 2024\",\n",
        "                \"code\": \"fcol('Orders', 'OrderID')[fval('Orders', 'OrderDate').year == 2024]\"\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"Total number of orders\",\n",
        "                \"code\": \"len(fcol('Orders', 'OrderID'))\"\n",
        "            }\n",
        "        ]\n",
        "        self.query2 = \"Count the number of orders made in 2024.\"\n",
        "        self.expected_code2 = (\n",
        "            \"len(fcol('Orders', 'OrderID')[\"\n",
        "            \"fval('Orders', 'OrderDate').year == 2024])\"\n",
        "        )\n",
        "\n",
        "    def test_generate_example1(self):\n",
        "        \"\"\"Example 1: join and filter by revenue > 1000.\"\"\"\n",
        "        result = generate_code_from_query(\n",
        "            self.query1, self.context1, self.examples1\n",
        "        )\n",
        "        self.assertEqual(result[\"generated_code\"], self.expected_code1)\n",
        "        self.assertListEqual(result[\"used_tables\"], [\"Customers\", \"Orders\"])\n",
        "        self.assertDictEqual(\n",
        "            result[\"used_columns\"],\n",
        "            {\"Customers\": [\"Name\", \"CustomerID\"],\n",
        "             \"Orders\": [\"Revenue\", \"CustomerID\"]}\n",
        "        )\n",
        "        self.assertIn(\"Joins Customers and Orders\", result[\"explanation\"])\n",
        "\n",
        "    def test_generate_example2(self):\n",
        "        \"\"\"Example 2: count orders in 2024.\"\"\"\n",
        "        result = generate_code_from_query(\n",
        "            self.query2, self.context2, self.examples2\n",
        "        )\n",
        "        self.assertEqual(result[\"generated_code\"], self.expected_code2)\n",
        "        self.assertListEqual(result[\"used_tables\"], [\"Orders\"])\n",
        "        self.assertDictEqual(\n",
        "            result[\"used_columns\"],\n",
        "            {\"Orders\": [\"OrderID\", \"OrderDate\"]}\n",
        "        )\n",
        "        self.assertIn(\"Counts the number of orders\", result[\"explanation\"])\n",
        "\n",
        "    def test_parse_query_empty(self):\n",
        "        \"\"\"Empty USER_QUERY should raise ValueError.\"\"\"\n",
        "        gen = NeuralCodeGenerator(self.context2, self.examples2)\n",
        "        with self.assertRaises(ValueError):\n",
        "            gen.parse_query(\"\")\n",
        "\n",
        "    def test_parse_query_unknown_table(self):\n",
        "        \"\"\"Query referencing non-existent table should error.\"\"\"\n",
        "        gen = NeuralCodeGenerator(self.context1, self.examples1)\n",
        "        with self.assertRaises(ValueError):\n",
        "            gen.parse_query(\"Show me records from NonExistent\")\n",
        "\n",
        "    def test_extract_used_fields_simple(self):\n",
        "        \"\"\"extract_used_fields should list single table and its cols.\"\"\"\n",
        "        gen = NeuralCodeGenerator(self.context2, self.examples2)\n",
        "        code = \"fcol('Orders', 'OrderID')[fval('Orders', 'OrderDate').year == 2024]\"\n",
        "        tables, cols = gen.extract_used_fields(code)\n",
        "        self.assertListEqual(tables, [\"Orders\"])\n",
        "        self.assertDictEqual(cols, {\"Orders\": [\"OrderID\", \"OrderDate\"]})\n",
        "\n",
        "    def test_extract_used_fields_join(self):\n",
        "        \"\"\"extract_used_fields should detect both tables in join code.\"\"\"\n",
        "        gen = NeuralCodeGenerator(self.context1, self.examples1)\n",
        "        code = (\"fcol('Customers', 'Name')[\"\n",
        "                \"fjoin('Customers', 'Orders', on='CustomerID')['Revenue'] > 1000]\")\n",
        "        tables, cols = gen.extract_used_fields(code)\n",
        "        self.assertCountEqual(tables, [\"Customers\", \"Orders\"])\n",
        "        self.assertDictEqual(\n",
        "            cols,\n",
        "            {\"Customers\": [\"Name\", \"CustomerID\"],\n",
        "             \"Orders\": [\"Revenue\", \"CustomerID\"]}\n",
        "        )\n",
        "\n",
        "    def test_explain_code_counts(self):\n",
        "        \"\"\"explain_code should describe counting logic.\"\"\"\n",
        "        gen = NeuralCodeGenerator(self.context2, self.examples2)\n",
        "        code = self.expected_code2\n",
        "        explanation = gen.explain_code(code)\n",
        "        self.assertTrue(explanation.lower().startswith(\"counts the number of orders\"))\n",
        "        self.assertIn(\"2024\", explanation)\n",
        "\n",
        "    def test_explain_code_joins(self):\n",
        "        \"\"\"explain_code should describe join-based filter.\"\"\"\n",
        "        gen = NeuralCodeGenerator(self.context1, self.examples1)\n",
        "        code = self.expected_code1\n",
        "        explanation = gen.explain_code(code)\n",
        "        self.assertIn(\"Customers and Orders\", explanation)\n",
        "        self.assertIn(\"Revenue > 1000\", explanation)\n",
        "\n",
        "    def test_context_malformed(self):\n",
        "        \"\"\"Missing 'tables' key in context should raise ValueError.\"\"\"\n",
        "        bad_context = {\"foreign_keys\": {}}\n",
        "        with self.assertRaises(ValueError):\n",
        "            generate_code_from_query(\"Any query\", bad_context, self.examples1)\n",
        "\n",
        "    def test_ambiguous_column(self):\n",
        "        \"\"\"Ambiguous column name across tables should raise ValueError.\"\"\"\n",
        "        context = {\n",
        "            \"tables\": {\n",
        "                \"A\": [\"ID\", \"Value\"],\n",
        "                \"B\": [\"ID\", \"Other\"]\n",
        "            },\n",
        "            \"foreign_keys\": {}\n",
        "        }\n",
        "        with self.assertRaises(ValueError):\n",
        "            generate_code_from_query(\"Show me ID\", context, self.examples1)\n",
        "\n",
        "    def test_large_input_truncation(self):\n",
        "        \"\"\"Excessively long USER_QUERY should raise ValueError.\"\"\"\n",
        "        long_query = \"A\" * 3000\n",
        "        with self.assertRaises(ValueError):\n",
        "            generate_code_from_query(long_query, self.context1, self.examples1)\n",
        "\n",
        "    def test_deterministic_output(self):\n",
        "        \"\"\"generate_code_from_query should be deterministic.\"\"\"\n",
        "        res1 = generate_code_from_query(\n",
        "            self.query2, self.context2, self.examples2\n",
        "        )\n",
        "        res2 = generate_code_from_query(\n",
        "            self.query2, self.context2, self.examples2\n",
        "        )\n",
        "        self.assertEqual(res1, res2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/c623eb52-15f4-4cca-86bf-f7a75e7b7cd7?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F44335%2Fview\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "# code generated by the model\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "def generate_code_from_query(user_query: str, context: dict, few_shot_examples: list) -> dict:\n",
        "    \"\"\"\n",
        "    Generates executable Python code from a user query using neural API patterns.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): Natural language query describing the data operation.\n",
        "        context (dict): Schema information including tables and foreign keys.\n",
        "        few_shot_examples (list): List of (query, code) pairs for few-shot learning.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing:\n",
        "            - \"generated_code\": str\n",
        "            - \"used_tables\": list\n",
        "            - \"used_columns\": dict\n",
        "            - \"explanation\": str\n",
        "    \"\"\"\n",
        "    generator = NeuralCodeGenerator(context, few_shot_examples)\n",
        "    # 1. Parse the query and produce code\n",
        "    code_dict = generator.parse_query(user_query)\n",
        "    generated_code = code_dict[\"generated_code\"]\n",
        "\n",
        "    # 2. Extract used fields (tables and columns) from the code\n",
        "    used_tables, used_columns = generator.extract_used_fields(generated_code)\n",
        "\n",
        "    # 3. Generate an explanation for the code\n",
        "    explanation = generator.explain_code(generated_code)\n",
        "\n",
        "    return {\n",
        "        \"generated_code\": generated_code,\n",
        "        \"used_tables\": used_tables,\n",
        "        \"used_columns\": used_columns,\n",
        "        \"explanation\": explanation\n",
        "    }\n",
        "\n",
        "\n",
        "class NeuralCodeGenerator:\n",
        "    \"\"\"\n",
        "    A framework that uses few-shot learning and metaprogramming to dynamically generate\n",
        "    Python code using structured schema context and neural APIs like fcol and fval.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, context: dict, examples: list):\n",
        "        \"\"\"\n",
        "        context: A dictionary with keys:\n",
        "            - \"tables\": {table_name: [column_name, ...], ...}\n",
        "            - \"foreign_keys\": { \"tableA.col\": \"tableB.col\", ... }\n",
        "        examples: A list of dictionaries with \"query\" and \"code\" fields for few-shot learning.\n",
        "        \"\"\"\n",
        "        self.context = context\n",
        "        self.examples = examples\n",
        "\n",
        "    def parse_query(self, user_query: str) -> dict:\n",
        "        \"\"\"\n",
        "        Generates structured code and metadata from a user query by:\n",
        "          1) Looking at few-shot examples to find relevant patterns,\n",
        "          2) Inferring relevant table/column usage from the context,\n",
        "          3) Building a Python expression using fcol, fval, etc.\n",
        "\n",
        "        Returns a dictionary with key \"generated_code\" that contains the final code string.\n",
        "        \"\"\"\n",
        "        # ---------------------------------------------------------------------\n",
        "        # 1. Basic validation checks on the user_query\n",
        "        # ---------------------------------------------------------------------\n",
        "        if not user_query.strip():\n",
        "            # Edge case: empty user query\n",
        "            return {\"generated_code\": \"# Error: Empty user query. Cannot generate code.\"}\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        # 2. Attempt a naive approach to interpret the query in relation to the examples\n",
        "        #    This is a placeholder for a real LLM-driven approach.\n",
        "        # ---------------------------------------------------------------------\n",
        "        # We'll do a simplistic keyword search on the user_query to see if it\n",
        "        # resembles any of our few-shot examples. If it does, we glean some pattern.\n",
        "        # In production, you'd use a neural model or advanced prompt-based approach.\n",
        "\n",
        "        chosen_example_code = None\n",
        "        for ex in self.examples:\n",
        "            # <Issue>: Naive word inclusion check doesn't work for queries with different phrasing or added conditions.\n",
        "            if all(word.lower() in user_query.lower() for word in ex[\"query\"].split() if len(word) > 2):\n",
        "                chosen_example_code = ex[\"code\"]\n",
        "                break\n",
        "\n",
        "        # If no matching example, we fallback to a simple template\n",
        "        if not chosen_example_code:\n",
        "            # A minimal fallback: pick first table, attempt a filter if user query has \"above\" or \"==\"\n",
        "            table_names = list(self.context.get(\"tables\", {}).keys())\n",
        "            if not table_names:\n",
        "                return {\"generated_code\": \"# Error: No tables in context.\"}\n",
        "            fallback_table = table_names[0]\n",
        "            columns = self.context[\"tables\"][fallback_table]\n",
        "            # Heuristic: if \"above\" in user_query, we filter by first numeric-like column\n",
        "            if \"above\" in user_query.lower() and len(columns) > 1:\n",
        "                # <Issue>: Heuristically picks the last column for comparison without checking if it's numeric\n",
        "                code = f\"fcol('{fallback_table}', '{columns[0]}')[fval('{fallback_table}', '{columns[-1]}') > 100]\"\n",
        "            else:\n",
        "                # Just output entire column set\n",
        "                code = f\"fcol('{fallback_table}', '{columns[0]}')\"\n",
        "            chosen_example_code = code\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        # 3. Return a dictionary with the final code\n",
        "        # ---------------------------------------------------------------------\n",
        "        return {\"generated_code\": chosen_example_code}\n",
        "\n",
        "    def extract_used_fields(self, code: str) -> tuple:\n",
        "        \"\"\"\n",
        "        Extracts tables and columns used in the generated code by simple regex inspection,\n",
        "        returning (used_tables, used_columns_dict).\n",
        "\n",
        "        For example:\n",
        "          code = \"fcol('Customers', 'Name')[fval('Customers', 'Country') == 'France']\"\n",
        "        would yield:\n",
        "          used_tables = [\"Customers\"]\n",
        "          used_columns = {\n",
        "            \"Customers\": [\"Name\", \"Country\"]\n",
        "          }\n",
        "        \"\"\"\n",
        "        used_tables = set()\n",
        "        used_columns = {}\n",
        "\n",
        "        # Regex patterns to find calls like fcol('Table', 'Column') or fval('Table', 'Column')\n",
        "        # <Issue>: Regex ends with `$` so it only matches standalone calls, not those embedded inside filters or len().\n",
        "        pattern = r\"(fcol|fval)$\\s*'([^']+)'\\s*,\\s*'([^']+)'\\s*$\"\n",
        "        matches = re.findall(pattern, code)\n",
        "\n",
        "        for match in matches:\n",
        "            # match[1] -> table name\n",
        "            # match[2] -> column name\n",
        "            tbl = match[1]\n",
        "            col = match[2]\n",
        "            used_tables.add(tbl)\n",
        "            if tbl not in used_columns:\n",
        "                used_columns[tbl] = []\n",
        "            if col not in used_columns[tbl]:\n",
        "                used_columns[tbl].append(col)\n",
        "\n",
        "        # Attempt to detect fjoin usage:\n",
        "        # e.g., fjoin('Customers', 'Orders', on='CustomerID')\n",
        "        # <Issue>: Same `$` problem affects fjoin pattern too.\n",
        "        fjoin_pattern = r\"fjoin$\\s*'([^']+)'\\s*,\\s*'([^']+)'\\s*,\\s*on\\s*=\\s*'([^']+)'\\s*$\"\n",
        "        join_matches = re.findall(fjoin_pattern, code)\n",
        "        for jm in join_matches:\n",
        "            t1, t2, on_col = jm\n",
        "            used_tables.add(t1)\n",
        "            used_tables.add(t2)\n",
        "            # If the on_col is presumably a column in both tables, we add it\n",
        "            if t1 not in used_columns:\n",
        "                used_columns[t1] = []\n",
        "            if t2 not in used_columns:\n",
        "                used_columns[t2] = []\n",
        "            if on_col not in used_columns[t1]:\n",
        "                used_columns[t1].append(on_col)\n",
        "            if on_col not in used_columns[t2]:\n",
        "                used_columns[t2].append(on_col)\n",
        "\n",
        "        return list(used_tables), used_columns\n",
        "\n",
        "    def explain_code(self, code: str) -> str:\n",
        "        \"\"\"\n",
        "        Generates a naive, plain-English explanation of the code logic by string inspection.\n",
        "        In a realistic scenario, you'd parse the abstract syntax tree or use an LLM to\n",
        "        generate a coherent explanation. Here, we do a basic heuristic approach.\n",
        "        \"\"\"\n",
        "        # Simple rules-based approach:\n",
        "        explanation_parts = []\n",
        "        if \"fjoin\" in code:\n",
        "            explanation_parts.append(\"Performs a join between the mentioned tables on the specified foreign key.\")\n",
        "        if \">\" in code:\n",
        "            explanation_parts.append(\"Filters rows where a column is greater than a specified value.\")\n",
        "        if \"==\" in code:\n",
        "            explanation_parts.append(\"Filters rows where a column equals a specified value.\")\n",
        "        if \"len(\" in code:\n",
        "            explanation_parts.append(\"Counts the number of resulting rows or entries.\")\n",
        "        if \"fcol\" in code and \"fval\" not in code:\n",
        "            explanation_parts.append(\"Selects a column or columns from a single table.\")\n",
        "        if \"fval\" in code and \"fcol\" in code:\n",
        "            explanation_parts.append(\"Retrieves specific column values for filtering or comparison.\")\n",
        "\n",
        "        # <Issue>: Explanation doesn't cover nested filtering, chained logic, or implicit joins based on foreign_keys.\n",
        "        if not explanation_parts:\n",
        "            explanation_parts = [\"Generates code for a data operation using fcol/fval.\"]\n",
        "\n",
        "        # Combine them into a single short comment\n",
        "        return \" \".join(explanation_parts)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}