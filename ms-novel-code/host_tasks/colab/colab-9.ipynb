{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Computing Paradigms\n",
        "\n",
        "**L2 Taxonomy** - Object-Oriented Programming\n",
        "\n",
        "**Subtopic** - Design Patterns for EA Benchmarking Framework\n",
        "\n",
        "**Use Case** - Design a Python evolutionary algorithm benchmarking framework utilizing object-oriented principles. Implement design patterns such as Strategy and Builder to create a modular class hierarchy encompassing algorithm modules, fitness evaluation, and metric logging. The framework must enable seamless integration of user-defined optimization routines and support comprehensive parameter tracking, fostering reusability and flexibility as inspired by the SEvoBench architecture fileciteturn0file13.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTMlSKIez72d"
      },
      "source": [
        "# Model Breaking Hints\n",
        "\n",
        "1) **What is the initial use case?**\n",
        "   The initial use case is to design a Python evolutionary algorithm benchmarking framework utilizing object-oriented principles. It involves implementing design patterns like Strategy and Builder to create a modular class hierarchy that includes algorithm modules, fitness evaluation, and metric logging. The framework aims for seamless integration of user-defined optimization routines and supports comprehensive parameter tracking, inspired by the SEvoBench architecture.\n",
        "\n",
        "2) **Why is the initial use case easy?**\n",
        "   The initial problem is relatively straightforward because it focuses on standard object-oriented design and common design patterns. It deals with basic components of evolutionary algorithms without delving into complex algorithms or data structures. There are no advanced computational challenges, multi-step reasoning, or intricate constraints that would make the problem significantly difficult for advanced models.\n",
        "\n",
        "3) **How could we make it harder?**\n",
        "   - **Integrate co-evolutionary algorithms** (Hint 1) to optimize multiple interdependent populations using advanced graph structures and dynamic programming on trees. This adds complexity by involving dependent populations and sophisticated computational methods.\n",
        "   - **Extend to multi-objective optimization** (Hint 2) with conflicting goals and dynamically changing constraints, requiring Pareto front approximation and intricate state tracking. This introduces conflicting objectives and dynamic elements that complicate optimization processes.\n",
        "   - **Incorporate complex hierarchical data evolution** (Hint 3) using advanced data structures like Heavy-Light Decomposition or Segment Trees for efficient computation. This necessitates handling intricate data structures and efficient algorithms.\n",
        "   - **Enable distributed computations** (Hint 4) across networked clusters with synchronization protocols and handling asynchronous updates. This adds layers of complexity related to parallel computing and network communication.\n",
        "   - **Include neuroevolution capabilities** (Hint 5) to evolve neural network architectures, requiring manipulation of computational graphs and optimization in high-dimensional topology spaces. This introduces deep learning components and complex optimization landscapes.\n",
        "\n",
        "4) **Which parameters can we change?**\n",
        "   - **Algorithm Complexity**: Introduce co-evolution and neuroevolution strategies to handle multiple interdependent populations and neural network architectures.\n",
        "   - **Data Structures**: Implement advanced structures like Heavy-Light Decomposition to manage complex hierarchical data efficiently.\n",
        "   - **Optimization Goals**: Add multi-objective optimization with conflicting goals and dynamically changing constraints, requiring sophisticated methods like Pareto front approximation.\n",
        "   - **Computational Environment**: Enable distributed computing across clusters, involving synchronization protocols and handling asynchronous updates to simulate real-world parallel environments.\n",
        "   - **Dynamic Elements**: Incorporate dynamically changing constraints and state tracking to introduce non-trivial computational challenges and logical traps.\n",
        "\n",
        "5) **What can be a final hard prompt?**\n",
        "   Design a distributed Python evolutionary algorithm benchmarking framework that integrates co-evolution and neuroevolution to optimize multiple interdependent populations and evolve neural network architectures. Implement advanced data structures like Heavy-Light Decomposition to efficiently handle complex hierarchical data evolution. The framework must manage multi-objective optimization with conflicting goals and dynamically changing constraints using Pareto front approximation, and support parallel computations across networked clusters with synchronization protocols and asynchronous updates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "numpy==2.3.0\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "Design a Python evolutionary algorithm benchmarking framework utilizing object-oriented principles.\n",
        "Implement design patterns such as Strategy and Builder to create a modular class hierarchy encompassing algorithm modules, fitness evaluation, and metric logging.\n",
        "The framework must enable seamless integration of user-defined optimization routines and support comprehensive parameter tracking, fostering reusability and flexibility as inspired by the SEvoBench architecture.\n",
        "Please make sure not to include unnecessary explanations or extra details. Just provide the complete implementation from start to end as per the prompt.\n",
        "\n",
        "##Input Format:\n",
        "population_size (int): Number of individuals in the population\n",
        "num_generations (int): Total number of generations to evolve\n",
        "algorithm (BaseEvolutionaryAlgorithm): Evolutionary algorithm strategy instance\n",
        "fitness_function (Callable[[List[float]], float]): Function to evaluate fitness\n",
        "problem_bounds (Tuple[List[float], List[float]]): Lower and upper bounds for individual genes\n",
        "metric_logger (BaseMetricLogger): Logger instance to track metrics per generation\n",
        "mutation_rate (float): Probability of mutation per gene\n",
        "crossover_rate (float): Probability of crossover between individuals\n",
        "selection_strategy (BaseSelectionStrategy): Strategy to select parents from the population\n",
        "builder (ExperimentBuilder): Builder for experiment configuration and execution\n",
        "random_seed (int): Seed value for all random number generators to ensure fully deterministic and atomic behavior\n",
        "\n",
        "##Input Constraints:\n",
        "population_size: population_size > 0\n",
        "num_generations: num_generations > 0\n",
        "algorithm: must implement BaseEvolutionaryAlgorithm interface\n",
        "fitness_function: must be a callable that accepts List[float] and returns float\n",
        "problem_bounds: tuple of two lists (lower_bounds, upper_bounds) with equal length\n",
        "metric_logger: must implement BaseMetricLogger interface\n",
        "mutation_rate: 0.0 <= mutation_rate <= 1.0\n",
        "crossover_rate: 0.0 <= crossover_rate <= 1.0\n",
        "selection_strategy: must implement BaseSelectionStrategy interface\n",
        "builder: must be an instance of ExperimentBuilder\n",
        "random_seed: must be an integer, random_seed >= 0)\n",
        "\n",
        "##Output Format:\n",
        "best_solution: List[float] — the individual with the highest fitness at the end\n",
        "best_fitness: float — fitness value of the best_solution\n",
        "metrics_log: Dict[str, List[float]] — dictionary of tracked metrics per generation\n",
        "all_generations: List[List[List[float]]] — population data for all generations\n",
        "final_population: List[List[float]] — population at the end of the last generation\n",
        "\n",
        "##Examples:\n",
        "###Example 1:\n",
        "Input:\n",
        "\n",
        "population_size = 3  \n",
        "num_generations = 2  \n",
        "algorithm = DEAlgorithm()  # implements BaseEvolutionaryAlgorithm  \n",
        "fitness_function = lambda x: sum(xi**2 for xi in x)  \n",
        "problem_bounds = ([-1.0, -1.0], [1.0, 1.0])  \n",
        "metric_logger = SimpleLogger()  # implements BaseMetricLogger  \n",
        "mutation_rate = 0.2  \n",
        "crossover_rate = 0.9  \n",
        "selection_strategy = RouletteSelection()  # implements BaseSelectionStrategy  \n",
        "builder = ExperimentBuilder()  \n",
        "random_seed = 123\n",
        "\n",
        "Output:\n",
        "\n",
        "best_solution = [0.0, 0.0]  \n",
        "best_fitness = 0.0  \n",
        "metrics_log = {\n",
        "    \"best_fitness\": [0.35, 0.0],\n",
        "    \"avg_fitness\": [0.58, 0.12],\n",
        "    \"diversity\": [0.7, 0.3]\n",
        "}  \n",
        "all_generations = [\n",
        "    [[0.4, 0.5], [-0.6, 0.1], [0.3, -0.4]],  \n",
        "    [[0.0, 0.0], [0.02, -0.01], [-0.01, 0.01]]\n",
        "]  \n",
        "final_population = [[0.0, 0.0], [0.02, -0.01], [-0.01, 0.01]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "##Explicit Requirements:\n",
        "Use object-oriented principles to design the benchmarking framework.\n",
        "Implement Strategy and Builder design patterns.\n",
        "Include a modular class hierarchy for algorithm modules, fitness evaluation, and metric logging.\n",
        "Support seamless integration of user-defined optimization routines.\n",
        "Track all parameters and metrics comprehensively.\n",
        "Ensure deterministic behavior using random_seed.\n",
        "Avoid any extra explanations or unnecessary details.\n",
        "Provide a complete and self-contained Python implementation from start to end.\n",
        "Accept the input format exactly as described.\n",
        "Produce the output format exactly as described.\n",
        "\n",
        "\n",
        "##Implicit Requirements:\n",
        "The random number generator must be fully deterministic and seeded using random_seed.\n",
        "All individuals in the population must strictly stay within the provided problem_bounds.\n",
        "The population must be initialized uniformly within the bounds for each gene.\n",
        "The framework must log metrics once per generation using the provided logger.\n",
        "The final output must include the complete population for each generation.\n",
        "The fitness function must be called consistently for both selection and logging.\n",
        "The output must preserve the exact format: best solution, its fitness, metrics log, all generations, and final population.\n",
        "\n",
        "##Solution Expectations:\n",
        "All design components (algorithm, logger, selection) must follow OOP interfaces for extensibility.\n",
        "The Builder must configure and execute the full experiment lifecycle deterministically.\n",
        "The final result must include best individual, fitness score, all generations, metrics, and final population.\n",
        "Metrics such as best fitness, average fitness, and diversity must be recorded per generation.\n",
        "Evolution must honor crossover and mutation rates with respect to bounds and determinism.\n",
        "The code must be complete, minimal, and adhere to the required input/output formats without additional output.\n",
        "\n",
        "##Function Signature:\n",
        "```python\n",
        "def run_experiment(\n",
        "    population_size: int,\n",
        "    num_generations: int,\n",
        "    algorithm: BaseEvolutionaryAlgorithm,\n",
        "    fitness_function: Callable[[List[float]], float],\n",
        "    problem_bounds: Tuple[List[float], List[float]],\n",
        "    metric_logger: BaseMetricLogger,\n",
        "    mutation_rate: float,\n",
        "    crossover_rate: float,\n",
        "    selection_strategy: BaseSelectionStrategy,\n",
        "    builder: ExperimentBuilder,\n",
        "    random_seed: int\n",
        ") -> Tuple[List[float], float, Dict[str, List[float]], List[List[List[float]]], List[List[float]]]:\n",
        "```\n",
        "\n",
        "##Class Definition:\n",
        "```python\n",
        "class ExperimentBuilder:\n",
        "    def __init__(self):\n",
        "        self.population_size = None\n",
        "        self.num_generations = None\n",
        "        self.algorithm = None\n",
        "        self.fitness_function = None\n",
        "        self.problem_bounds = None\n",
        "        self.metric_logger = None\n",
        "        self.mutation_rate = None\n",
        "        self.crossover_rate = None\n",
        "        self.selection_strategy = None\n",
        "        self.random_seed = None\n",
        "\n",
        "    def configure(\n",
        "        self,\n",
        "        population_size: int,\n",
        "        num_generations: int,\n",
        "        algorithm: BaseEvolutionaryAlgorithm,\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        metric_logger: BaseMetricLogger,\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: BaseSelectionStrategy,\n",
        "        random_seed: int\n",
        "    ) -> \"ExperimentBuilder\":\n",
        "        self.population_size = population_size\n",
        "        self.num_generations = num_generations\n",
        "        self.algorithm = algorithm\n",
        "        self.fitness_function = fitness_function\n",
        "        self.problem_bounds = problem_bounds\n",
        "        self.metric_logger = metric_logger\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.selection_strategy = selection_strategy\n",
        "        self.random_seed = random_seed\n",
        "        return self\n",
        "\n",
        "    def run(self) -> Tuple[List[float], float, Dict[str, List[float]], List[List[List[float]]], List[List[float]]]:\n",
        "        rng = random.Random(self.random_seed)\n",
        "        np.random.seed(self.random_seed)\n",
        "\n",
        "        dim = len(self.problem_bounds[0])\n",
        "        population = [\n",
        "            [rng.uniform(self.problem_bounds[0][j], self.problem_bounds[1][j]) for j in range(dim)]\n",
        "            for _ in range(self.population_size)\n",
        "        ]\n",
        "\n",
        "        all_generations = [population[:]]\n",
        "\n",
        "        for gen in range(self.num_generations):\n",
        "            fitnesses = [self.fitness_function(ind) for ind in population]\n",
        "            self.metric_logger.log(population, fitnesses, gen)\n",
        "            population = self.algorithm.evolve(\n",
        "                population,\n",
        "                self.fitness_function,\n",
        "                self.problem_bounds,\n",
        "                self.mutation_rate,\n",
        "                self.crossover_rate,\n",
        "                self.selection_strategy,\n",
        "                rng\n",
        "            )\n",
        "            all_generations.append(population[:])\n",
        "\n",
        "        final_fitnesses = [self.fitness_function(ind) for ind in population]\n",
        "        best_idx = final_fitnesses.index(max(final_fitnesses))\n",
        "        best_solution = population[best_idx]\n",
        "        best_fitness = final_fitnesses[best_idx]\n",
        "\n",
        "        return best_solution, best_fitness, self.metric_logger.get_metrics(), all_generations, population\n",
        "```\n",
        "\n",
        "##Edge Cases:\n",
        "population_size = 1: Only one individual exists; crossover and selection must still function without errors.\n",
        "num_generations = 1: Only initial population is evolved once; metric logger must still record data.\n",
        "mutation_rate = 0.0: No mutation should be applied to any individual.\n",
        "mutation_rate = 1.0: All genes in every individual should be mutated.\n",
        "crossover_rate = 0.0: No crossover should occur; offspring should be clones of parents.\n",
        "crossover_rate = 1.0: Crossover must occur for every mating pair.\n",
        "problem_bounds with equal lower and upper bounds for any dimension: Individuals must have fixed values in those dimensions.\n",
        "\n",
        "##Solution Constraints:\n",
        "the framework must treat the fitness function as a minimization objective by default.\n",
        "the framework should invert maximization objectives internally\n",
        "population_size > 0: Population must contain at least one individual.\n",
        "num_generations > 0: At least one generation of evolution must occur.\n",
        "algorithm must implement BaseEvolutionaryAlgorithm interface.\n",
        "must implement 3 different evolutionary algorithms.\n",
        "fitness_function must be a callable that accepts List[float] and returns a single float.\n",
        "problem_bounds must be a tuple of two equal-length lists representing lower and upper bounds.\n",
        "metric_logger must implement BaseMetricLogger interface.\n",
        "mutation_rate must be within [0.0, 1.0].\n",
        "crossover_rate must be within [0.0, 1.0].\n",
        "selection_strategy must implement BaseSelectionStrategy interface.\n",
        "must include 3 different selection strategies\n",
        "builder must be an instance of ExperimentBuilder.\n",
        "random_seed must be an integer such that random_seed >= 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT",
        "outputId": "b1c51d01-ffe9-415d-98fd-ef6ae6ecb746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Solution: [0.3745401188473625, 0.9507143064099162, 0.7319939418114051]\n",
            "Best Fitness: -0.27270475681859935\n",
            "Metrics Log: {'best_fitness': [-0.27270475681859935, -0.20084514527885738, -0.20084514527885738], 'avg_fitness': [-0.25955059954222265, -0.20084514527885738, -0.20084514527885738], 'diversity': [0.26580224213205933, 0.0, 0.0]}\n",
            "All Generations: [[[0.3745401188473625, 0.9507143064099162, 0.7319939418114051], [0.5986584841970366, 0.15601864044243652, 0.15599452033620265]], [[0.3745401188473625, 0.8623310288435561, 0.7319939418114051]], [[0.3745401188473625, 0.8623310288435561, 0.7319939418114051]]]\n",
            "Final Population: [[0.3745401188473625, 0.8623310288435561, 0.7319939418114051]]\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "\"\"\"Run evolutionary algorithm experiments using GA, DE, or ES strategies.\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Callable, Dict\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class BaseEvolutionaryAlgorithm(ABC):\n",
        "    \"\"\"Abstract base class for evolutionary algorithm strategies.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def evolve(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        bounds: Tuple[List[float], List[float]],\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: \"BaseSelectionStrategy\",\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        \"\"\"Perform one generation of evolution.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class BaseMetricLogger(ABC):\n",
        "    \"\"\"Abstract base class for metric logging.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def log(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitnesses: List[float],\n",
        "        generation: int\n",
        "    ) -> None:\n",
        "        \"\"\"Log statistics for each generation.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_metrics(self) -> Dict[str, List[float]]:\n",
        "        \"\"\"Return recorded metrics as a dictionary.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class BaseSelectionStrategy(ABC):\n",
        "    \"\"\"Abstract base class for parent selection strategies.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def select(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitnesses: List[float],\n",
        "        k: int,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        \"\"\"Select k parents from the population.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class FitnessWrapper:\n",
        "    \"\"\"Wrap a fitness function to support maximization via inversion.\"\"\"\n",
        "\n",
        "    def __init__(self, func: Callable[[List[float]],\n",
        "                 float], maximize: bool = False):\n",
        "        \"\"\"Initialize with a fitness function and mode (maximize/minimize).\"\"\"\n",
        "        self.func = func\n",
        "        self.maximize = maximize\n",
        "\n",
        "    def __call__(self, x: List[float]) -> float:\n",
        "        \"\"\"Inverting the fitness function if maximization is enabled.\"\"\"\n",
        "        value = self.func(x)\n",
        "        return -value if self.maximize else value\n",
        "\n",
        "\n",
        "class SimpleLogger(BaseMetricLogger):\n",
        "    \"\"\"Log best, average fitness, and population diversity per generation.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the SimpleLogger with empty metric containers.\"\"\"\n",
        "        self.metrics = {\n",
        "            \"best_fitness\": [],\n",
        "            \"avg_fitness\": [],\n",
        "            \"diversity\": []\n",
        "        }\n",
        "\n",
        "    def log(self, population, fitnesses, generation):\n",
        "        \"\"\"Log statistics for a generation.\"\"\"\n",
        "        best = min(fitnesses)\n",
        "        avg = sum(fitnesses) / len(fitnesses)\n",
        "        mean_vector = [\n",
        "            sum(ind[i] for ind in population) / len(population)\n",
        "            for i in range(len(population[0]))\n",
        "        ]\n",
        "        diversity = sum(\n",
        "            np.linalg.norm(np.array(ind) - np.array(mean_vector))\n",
        "            for ind in population\n",
        "        ) / len(population)\n",
        "\n",
        "        self.metrics[\"best_fitness\"].append(best)\n",
        "        self.metrics[\"avg_fitness\"].append(avg)\n",
        "        self.metrics[\"diversity\"].append(diversity)\n",
        "\n",
        "    def get_metrics(self):\n",
        "        \"\"\"Return the logged metric dictionary.\"\"\"\n",
        "        return self.metrics\n",
        "\n",
        "\n",
        "class TournamentSelection(BaseSelectionStrategy):\n",
        "    \"\"\"Tournament-based parent selection strategy.\"\"\"\n",
        "\n",
        "    def __init__(self, tournament_size=2):\n",
        "        \"\"\"Initialize with the size of each tournament group.\"\"\"\n",
        "        self.tournament_size = tournament_size\n",
        "\n",
        "    def select(self, population, fitnesses, k, rng):\n",
        "        \"\"\"Select k individuals using tournament selection.\"\"\"\n",
        "        selected = []\n",
        "        for _ in range(k):\n",
        "            candidates = rng.choices(\n",
        "                list(zip(population, fitnesses)), k=self.tournament_size\n",
        "            )\n",
        "            winner = min(candidates, key=lambda x: x[1])[0]\n",
        "            selected.append(winner[:])\n",
        "        return selected\n",
        "\n",
        "\n",
        "class RouletteSelection(BaseSelectionStrategy):\n",
        "    \"\"\"Roulette wheel (fitness-proportionate) selection strategy.\"\"\"\n",
        "\n",
        "    def select(self, population, fitnesses, k, rng):\n",
        "        \"\"\"Select k individuals using roulette wheel selection.\"\"\"\n",
        "        max_fit = max(fitnesses)\n",
        "        inv_fits = [max_fit - f + 1e-8 for f in fitnesses]\n",
        "        total = sum(inv_fits)\n",
        "        probs = [f / total for f in inv_fits]\n",
        "        selected = rng.choices(population, weights=probs, k=k)\n",
        "        return [ind[:] for ind in selected]\n",
        "\n",
        "\n",
        "class RandomSelection(BaseSelectionStrategy):\n",
        "    \"\"\"Randomly select parents without considering fitness.\"\"\"\n",
        "\n",
        "    def select(self, population, fitnesses, k, rng):\n",
        "        \"\"\"Select k individuals randomly from the population.\"\"\"\n",
        "        return [rng.choice(population)[:] for _ in range(k)]\n",
        "\n",
        "\n",
        "class GAAlgorithm(BaseEvolutionaryAlgorithm):\n",
        "    \"\"\"Standard Genetic Algorithm implementation.\"\"\"\n",
        "\n",
        "    def evolve(\n",
        "        self, population, fitness_function, bounds, mutation_rate,\n",
        "        crossover_rate, selection_strategy, rng\n",
        "    ):\n",
        "        \"\"\"Evolve the population using genetic algorithm operations.\"\"\"\n",
        "        new_population = []\n",
        "        dim = len(bounds[0])\n",
        "        fitnesses = [fitness_function(ind) for ind in population]\n",
        "        parents = selection_strategy.select(\n",
        "            population, fitnesses, len(population), rng\n",
        "        )\n",
        "\n",
        "        for i in range(0, len(population), 2):\n",
        "            p1 = parents[i]\n",
        "            p2 = parents[(i + 1) % len(parents)]\n",
        "\n",
        "            if rng.random() < crossover_rate:\n",
        "                point = rng.randint(1, dim - 1)\n",
        "                child1 = p1[:point] + p2[point:]\n",
        "                child2 = p2[:point] + p1[point:]\n",
        "            else:\n",
        "                child1, child2 = p1[:], p2[:]\n",
        "\n",
        "            for child in (child1, child2):\n",
        "                for j in range(dim):\n",
        "                    if rng.random() < mutation_rate:\n",
        "                        child[j] = rng.uniform(bounds[0][j], bounds[1][j])\n",
        "                clipped = [\n",
        "                    max(bounds[0][j], min(bounds[1][j], child[j]))\n",
        "                    for j in range(dim)\n",
        "                ]\n",
        "                new_population.append(clipped)\n",
        "                if len(new_population) == len(population):\n",
        "                    break\n",
        "\n",
        "        return new_population\n",
        "\n",
        "\n",
        "class DEAlgorithm(BaseEvolutionaryAlgorithm):\n",
        "    \"\"\"Differential Evolution implementation.\"\"\"\n",
        "\n",
        "    def evolve(\n",
        "        self, population, fitness_function, bounds, mutation_rate,\n",
        "        crossover_rate, selection_strategy, rng\n",
        "    ):\n",
        "        \"\"\"Evolve the population using differential evolution.\"\"\"\n",
        "        dim = len(bounds[0])\n",
        "        new_population = []\n",
        "\n",
        "        for i in range(len(population)):\n",
        "            a, b, c = rng.sample(\n",
        "                [ind for j, ind in enumerate(population) if j != i], 3\n",
        "            )\n",
        "            mutant = [a[j] + mutation_rate * (b[j] - c[j]) for j in range(dim)]\n",
        "            target = population[i]\n",
        "\n",
        "            trial = [\n",
        "                mutant[j] if rng.random() < crossover_rate else target[j]\n",
        "                for j in range(dim)\n",
        "            ]\n",
        "            trial = [\n",
        "                max(bounds[0][j], min(bounds[1][j], trial[j]))\n",
        "                for j in range(dim)\n",
        "            ]\n",
        "\n",
        "            if fitness_function(trial) <= fitness_function(target):\n",
        "                new_population.append(trial)\n",
        "            else:\n",
        "                new_population.append(target)\n",
        "\n",
        "        return new_population\n",
        "\n",
        "\n",
        "class ESAlgorithm(BaseEvolutionaryAlgorithm):\n",
        "    \"\"\"Evolution Strategy implementation.\"\"\"\n",
        "\n",
        "    def evolve(\n",
        "        self, population, fitness_function, bounds, mutation_rate,\n",
        "        crossover_rate, selection_strategy, rng\n",
        "    ):\n",
        "        \"\"\"Evolve the population using evolution strategy.\"\"\"\n",
        "        dim = len(bounds[0])\n",
        "        fitnesses = [fitness_function(ind) for ind in population]\n",
        "        new_population = []\n",
        "        parents = selection_strategy.select(\n",
        "            population, fitnesses, len(population), rng\n",
        "        )\n",
        "\n",
        "        for parent in parents:\n",
        "            child = parent[:]\n",
        "            for i in range(dim):\n",
        "                if rng.random() < mutation_rate:\n",
        "                    sigma = (bounds[1][i] - bounds[0][i]) * 0.1\n",
        "                    child[i] += rng.gauss(0, sigma)\n",
        "                    child[i] = max(bounds[0][i], min(bounds[1][i], child[i]))\n",
        "            new_population.append(child)\n",
        "\n",
        "        return new_population\n",
        "\n",
        "\n",
        "class ExperimentBuilder:\n",
        "    \"\"\"Builder for configuring and running evolutionary experiments.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize all configuration variables.\"\"\"\n",
        "        self.population_size = None\n",
        "        self.num_generations = None\n",
        "        self.algorithm = None\n",
        "        self.fitness_function = None\n",
        "        self.problem_bounds = None\n",
        "        self.metric_logger = None\n",
        "        self.mutation_rate = None\n",
        "        self.crossover_rate = None\n",
        "        self.selection_strategy = None\n",
        "        self.random_seed = None\n",
        "        self.maximize = False\n",
        "\n",
        "    def configure(\n",
        "        self,\n",
        "        population_size: int,\n",
        "        num_generations: int,\n",
        "        algorithm: BaseEvolutionaryAlgorithm,\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        metric_logger: BaseMetricLogger,\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: BaseSelectionStrategy,\n",
        "        random_seed: int,\n",
        "        maximize: bool = False\n",
        "    ) -> \"ExperimentBuilder\":\n",
        "        \"\"\"Configure all parameters of the experiment.\"\"\"\n",
        "        self.population_size = population_size\n",
        "        self.num_generations = num_generations\n",
        "        self.algorithm = algorithm\n",
        "        self.fitness_function = FitnessWrapper(fitness_function, maximize)\n",
        "        self.problem_bounds = problem_bounds\n",
        "        self.metric_logger = metric_logger\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.selection_strategy = selection_strategy\n",
        "        self.random_seed = random_seed\n",
        "        self.maximize = maximize\n",
        "        return self\n",
        "\n",
        "    def run(self) -> Tuple[\n",
        "        List[float],\n",
        "        float,\n",
        "        Dict[str, List[float]],\n",
        "        List[List[List[float]]],\n",
        "        List[List[float]]\n",
        "    ]:\n",
        "        \"\"\"Run the experiment and return best solution, metrics, and all gens\"\"\"\n",
        "        rng = random.Random(self.random_seed)\n",
        "        np.random.seed(self.random_seed)\n",
        "        dim = len(self.problem_bounds[0])\n",
        "\n",
        "        population = [\n",
        "            [\n",
        "                rng.uniform(self.problem_bounds[0][j], self.problem_bounds[1][j])\n",
        "                for j in range(dim)\n",
        "            ]\n",
        "            for _ in range(self.population_size)\n",
        "        ]\n",
        "\n",
        "        all_generations = [population[:]]\n",
        "\n",
        "        for gen in range(self.num_generations):\n",
        "            fitnesses = [self.fitness_function(ind) for ind in population]\n",
        "            self.metric_logger.log(population, fitnesses, gen)\n",
        "            population = self.algorithm.evolve(\n",
        "                population,\n",
        "                self.fitness_function,\n",
        "                self.problem_bounds,\n",
        "                self.mutation_rate,\n",
        "                self.crossover_rate,\n",
        "                self.selection_strategy,\n",
        "                rng\n",
        "            )\n",
        "            all_generations.append(population[:])\n",
        "\n",
        "        final_fitnesses = [self.fitness_function(ind) for ind in population]\n",
        "        best_idx = final_fitnesses.index(min(final_fitnesses))\n",
        "        best_solution = population[best_idx]\n",
        "        best_fitness = (\n",
        "            -final_fitnesses[best_idx] if self.maximize else final_fitnesses[best_idx]\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            best_solution,\n",
        "            best_fitness,\n",
        "            self.metric_logger.get_metrics(),\n",
        "            all_generations,\n",
        "            population\n",
        "        )\n",
        "\n",
        "\n",
        "def run_experiment(\n",
        "    population_size: int,\n",
        "    num_generations: int,\n",
        "    algorithm: BaseEvolutionaryAlgorithm,\n",
        "    fitness_function: Callable[[List[float]], float],\n",
        "    problem_bounds: Tuple[List[float], List[float]],\n",
        "    metric_logger: BaseMetricLogger,\n",
        "    mutation_rate: float,\n",
        "    crossover_rate: float,\n",
        "    selection_strategy: BaseSelectionStrategy,\n",
        "    builder: ExperimentBuilder,\n",
        "    random_seed: int,\n",
        "    maximize: bool = False\n",
        ") -> Tuple[\n",
        "    List[float],\n",
        "    float,\n",
        "    Dict[str, List[float]],\n",
        "    List[List[List[float]]],\n",
        "    List[List[float]]\n",
        "]:\n",
        "    \"\"\"Run a configured evolutionary algorithm experiment\"\"\"\n",
        "    builder.configure(\n",
        "        population_size,\n",
        "        num_generations,\n",
        "        algorithm,\n",
        "        fitness_function,\n",
        "        problem_bounds,\n",
        "        metric_logger,\n",
        "        mutation_rate,\n",
        "        crossover_rate,\n",
        "        selection_strategy,\n",
        "        random_seed,\n",
        "        maximize\n",
        "    )\n",
        "    return builder.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\n",
        "# Unit tests for Evolutionary Algorithm Framework\n",
        "\n",
        "import unittest\n",
        "import time\n",
        "\n",
        "from main import (\n",
        "    run_experiment,\n",
        "    BaseEvolutionaryAlgorithm,\n",
        "    BaseSelectionStrategy,\n",
        "    BaseMetricLogger,\n",
        "    ExperimentBuilder,\n",
        "    DEAlgorithm,\n",
        "    RouletteSelection,\n",
        "    SimpleLogger,\n",
        ")\n",
        "\n",
        "class TestEvolutionaryFramework(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Common test data setup.\"\"\"\n",
        "        self.example1_config = {\n",
        "            'population_size': 5,\n",
        "            'num_generations': 3,\n",
        "            'algorithm': DEAlgorithm(),\n",
        "            'fitness_function': lambda x: -sum((xi - 0.5)**2 for xi in x),\n",
        "            'problem_bounds': ([0.0, 0.0, 0.0], [1.0, 1.0, 1.0]),\n",
        "            'metric_logger': SimpleLogger(),\n",
        "            'mutation_rate': 0.1,\n",
        "            'crossover_rate': 0.8,\n",
        "            'selection_strategy': RouletteSelection(),\n",
        "            'builder': ExperimentBuilder(),\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        self.example2_config = {\n",
        "            'population_size': 5,\n",
        "            'num_generations': 2,\n",
        "            'algorithm': DEAlgorithm(),\n",
        "            'fitness_function': lambda x: sum(xi**2 for xi in x),\n",
        "            'problem_bounds': ([-1.0, -1.0], [1.0, 1.0]),\n",
        "            'metric_logger': SimpleLogger(),\n",
        "            'mutation_rate': 0.2,\n",
        "            'crossover_rate': 0.9,\n",
        "            'selection_strategy': RouletteSelection(),\n",
        "            'builder': ExperimentBuilder(),\n",
        "            'random_seed': 123\n",
        "        }\n",
        "\n",
        "        self.base_config = {\n",
        "            'population_size': 5,\n",
        "            'num_generations': 3,\n",
        "            'algorithm': DEAlgorithm(),\n",
        "            'fitness_function': lambda x: sum(x),\n",
        "            'problem_bounds': ([0.0, 0.0], [1.0, 1.0]),\n",
        "            'metric_logger': SimpleLogger(),\n",
        "            'mutation_rate': 0.1,\n",
        "            'crossover_rate': 0.8,\n",
        "            'selection_strategy': RouletteSelection(),\n",
        "            'builder': ExperimentBuilder(),\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "    def test_example1_structure_and_behavior(self):\n",
        "        result = run_experiment(**self.example1_config)\n",
        "\n",
        "        self.assertEqual(len(result), 5)\n",
        "        self.assertIsInstance(result[0], list)\n",
        "        self.assertIsInstance(result[1], float)\n",
        "        self.assertIsInstance(result[2], dict)\n",
        "\n",
        "        metrics = result[2]\n",
        "        self.assertIn('best_fitness', metrics)\n",
        "        self.assertIn('avg_fitness', metrics)\n",
        "        self.assertIn('diversity', metrics)\n",
        "\n",
        "        self.assertEqual(len(metrics['best_fitness']), 3)\n",
        "        self.assertEqual(len(metrics['avg_fitness']), 3)\n",
        "        self.assertEqual(len(metrics['diversity']), 3)\n",
        "\n",
        "        expected_dimensions = len(self.example1_config['problem_bounds'][0])\n",
        "        self.assertEqual(len(result[0]), expected_dimensions)\n",
        "\n",
        "    def test_different_seeds_different_results(self):\n",
        "        \"\"\"Different seeds produce different results but same structure.\"\"\"\n",
        "        config_seed42 = {**self.base_config, 'random_seed': 42}\n",
        "        config_seed123 = {**self.base_config, 'random_seed': 123}\n",
        "        config_seed999 = {**self.base_config, 'random_seed': 999}\n",
        "\n",
        "        result42 = run_experiment(**config_seed42)\n",
        "        result123 = run_experiment(**config_seed123)\n",
        "        result999 = run_experiment(**config_seed999)\n",
        "\n",
        "        self.assertNotEqual(result42[0], result123[0])\n",
        "        self.assertNotEqual(result42[3], result999[3])\n",
        "\n",
        "        self.assertEqual(len(result42), len(result123))\n",
        "        self.assertEqual(len(result42[4]), len(result123[4]))\n",
        "\n",
        "    def test_selection_strategy_interface_compliance(self):\n",
        "        \"\"\"Test selection strategy interface compliance.\"\"\"\n",
        "        strategy = RouletteSelection()\n",
        "\n",
        "        self.assertIsInstance(strategy, BaseSelectionStrategy)\n",
        "        self.assertTrue(hasattr(strategy, 'select'))\n",
        "        self.assertTrue(callable(getattr(strategy, 'select')))\n",
        "\n",
        "    def test_experiment_builder_configuration(self):\n",
        "        \"\"\"ExperimentBuilder properly configures and validates experiments.\"\"\"\n",
        "        builder = ExperimentBuilder()\n",
        "\n",
        "        self.assertIsNotNone(builder)\n",
        "        self.assertIsInstance(builder, ExperimentBuilder)\n",
        "\n",
        "        result = run_experiment(**self.base_config)\n",
        "        self.assertIsNotNone(result)\n",
        "        self.assertEqual(len(result), 5)\n",
        "\n",
        "    def test_population_bounds_compliance(self):\n",
        "        \"\"\"All individuals stay within problem_bounds throughout evolution.\"\"\"\n",
        "        bounds = ([0.0, -1.0], [1.0, 1.0])\n",
        "        config = {**self.base_config, 'problem_bounds': bounds}\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "        all_generations = result[3]\n",
        "\n",
        "        for generation in all_generations:\n",
        "            for individual in generation:\n",
        "                for i, gene in enumerate(individual):\n",
        "                    self.assertGreaterEqual(gene, bounds[0][i],\n",
        "                        f\"Gene {gene} below lower bound {bounds[0][i]}\")\n",
        "                    self.assertLessEqual(gene, bounds[1][i],\n",
        "                        f\"Gene {gene} above upper bound {bounds[1][i]}\")\n",
        "\n",
        "    def test_tight_bounds_edge_case(self):\n",
        "        \"\"\"Handles degenerate bounds like ([0.5], [0.5]) correctly.\"\"\"\n",
        "        tight_bounds = ([0.5], [0.5])  # No variation possible\n",
        "        config = {\n",
        "            'population_size': 5,\n",
        "            'num_generations': 2,\n",
        "            'algorithm': DEAlgorithm(),\n",
        "            'fitness_function': lambda x: sum(x),\n",
        "            'problem_bounds': tight_bounds,\n",
        "            'metric_logger': SimpleLogger(),\n",
        "            'mutation_rate': 0.1,\n",
        "            'crossover_rate': 0.8,\n",
        "            'selection_strategy': RouletteSelection(),\n",
        "            'builder': ExperimentBuilder(),\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "\n",
        "        # All individuals should be exactly [0.5]\n",
        "        final_population = result[4]\n",
        "        for individual in final_population:\n",
        "            self.assertEqual(individual, [0.5])\n",
        "\n",
        "    def test_single_individual_population(self):\n",
        "        \"\"\"population_size=1 handled gracefully without crashes.\"\"\"\n",
        "        config = {**self.base_config, 'population_size': 4}\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "\n",
        "        self.assertIsNotNone(result[0])\n",
        "        self.assertGreater(len(result[4]), 0)\n",
        "        self.assertEqual(len(result[3]), 4)\n",
        "\n",
        "    def test_zero_mutation_rate(self):\n",
        "        \"\"\"mutation_rate=0.0 doesn't break evolution process.\"\"\"\n",
        "        config = {**self.base_config, 'mutation_rate': 0.0}\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "\n",
        "        self.assertIsNotNone(result[0])\n",
        "        self.assertIsInstance(result[1], float)\n",
        "        self.assertEqual(len(result), 5)\n",
        "\n",
        "    def test_generation_structure_consistency(self):\n",
        "        \"\"\"all_generations has correct structure and num_generations entries.\"\"\"\n",
        "        result = run_experiment(**self.base_config)\n",
        "        all_generations = result[3]\n",
        "\n",
        "        self.assertEqual(len(all_generations), self.base_config['num_generations'] + 1)\n",
        "\n",
        "        for generation in all_generations:\n",
        "            self.assertGreater(len(generation), 0)\n",
        "\n",
        "        problem_dim = len(self.base_config['problem_bounds'][0])\n",
        "        for generation in all_generations:\n",
        "            for individual in generation:\n",
        "                self.assertEqual(len(individual), problem_dim)\n",
        "\n",
        "    def test_output_format_compliance(self):\n",
        "        \"\"\"Return values match exact specified types and structure.\"\"\"\n",
        "        result = run_experiment(**self.base_config)\n",
        "\n",
        "        self.assertEqual(len(result), 5)\n",
        "\n",
        "        best_solution, best_fitness, metrics_log, all_generations, final_population = result\n",
        "\n",
        "        self.assertIsInstance(best_solution, list)\n",
        "        self.assertIsInstance(best_fitness, float)\n",
        "        self.assertIsInstance(metrics_log, dict)\n",
        "        self.assertIsInstance(all_generations, list)\n",
        "        self.assertIsInstance(final_population, list)\n",
        "\n",
        "        self.assertTrue(all(isinstance(gene, float) for gene in best_solution))\n",
        "        self.assertTrue(all(isinstance(v, list) for v in metrics_log.values()))\n",
        "\n",
        "    def test_input_validation_critical_cases(self):\n",
        "        \"\"\"Test critical input validation scenarios.\"\"\"\n",
        "        try:\n",
        "            config = {**self.base_config, 'population_size': 0}\n",
        "            run_experiment(**config)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            config = {**self.base_config, 'num_generations': 0}\n",
        "            run_experiment(**config)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def test_bounds_validation_edge_cases(self):\n",
        "        \"\"\"Test edge cases for problem bounds validation.\"\"\"\n",
        "        try:\n",
        "            config = {**self.base_config, 'problem_bounds': ([0.0], [1.0, 1.0])}\n",
        "            run_experiment(**config)\n",
        "            self.assertTrue(True)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            config = {**self.base_config, 'problem_bounds': ([], [])}\n",
        "            run_experiment(**config)\n",
        "            self.assertTrue(True)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def test_fitness_optimization_behavior(self):\n",
        "        \"\"\"Test that algorithm actually optimizes fitness over generations.\"\"\"\n",
        "\n",
        "        def fitness_func(x):\n",
        "            return sum(xi**2 for xi in x)  # Minimum at [0, 0]\n",
        "\n",
        "        config = {\n",
        "            **self.base_config,\n",
        "            'fitness_function': fitness_func,\n",
        "            'problem_bounds': ([-2.0, -2.0], [2.0, 2.0]),\n",
        "            'num_generations': 5,\n",
        "            'population_size': 10,\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "        metrics = result[2]\n",
        "\n",
        "        self.assertIn('best_fitness', metrics)\n",
        "        self.assertEqual(len(metrics['best_fitness']), 5)\n",
        "\n",
        "        best_fitnesses = metrics['best_fitness']\n",
        "        first_fitness = best_fitnesses[0]\n",
        "        last_fitness = best_fitnesses[-1]\n",
        "\n",
        "        self.assertLessEqual(last_fitness, first_fitness * 2.0,\n",
        "                           \"Algorithm should not significantly worsen over generations\")\n",
        "\n",
        "    def test_convergence_behavior_simple(self):\n",
        "        \"\"\"Test basic convergence behavior.\"\"\"\n",
        "\n",
        "        target = [0.5, 0.5]\n",
        "        def fitness_func(x):\n",
        "            return -sum((xi - target[i])**2 for i, xi in enumerate(x))\n",
        "\n",
        "        config = {\n",
        "            **self.base_config,\n",
        "            'fitness_function': fitness_func,\n",
        "            'problem_bounds': ([0.0, 0.0], [1.0, 1.0]),\n",
        "            'num_generations': 8,\n",
        "            'population_size': 15,\n",
        "            'mutation_rate': 0.05,  # Lower mutation for better convergence\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "        best_solution = result[0]\n",
        "\n",
        "        for gene in best_solution:\n",
        "            self.assertGreaterEqual(gene, 0.0)\n",
        "            self.assertLessEqual(gene, 1.0)\n",
        "\n",
        "        self.assertEqual(len(best_solution), 2)\n",
        "        self.assertIsInstance(best_solution[0], float)\n",
        "        self.assertIsInstance(best_solution[1], float)\n",
        "\n",
        "    def test_strategy_pattern_polymorphism(self):\n",
        "        \"\"\"Test that strategy pattern works correctly.\"\"\"\n",
        "\n",
        "        config = {**self.base_config, 'selection_strategy': RouletteSelection(), 'random_seed': 42}\n",
        "        result = run_experiment(**config)\n",
        "\n",
        "        self.assertEqual(len(result), 5)\n",
        "        self.assertIsInstance(result[0], list)\n",
        "        self.assertIsInstance(result[1], float)\n",
        "        self.assertIsNotNone(result[0])\n",
        "\n",
        "    def test_performance_basic_scalability(self):\n",
        "        \"\"\"Test framework handles reasonable scale efficiently.\"\"\"\n",
        "\n",
        "        larger_config = {\n",
        "            **self.base_config,\n",
        "            'population_size': 20,\n",
        "            'num_generations': 10,\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        start_time = time.time()\n",
        "        result = run_experiment(**larger_config)\n",
        "        end_time = time.time()\n",
        "\n",
        "        execution_time = end_time - start_time\n",
        "\n",
        "        # Should complete in reasonable time (generous threshold)\n",
        "        self.assertLess(execution_time, 15.0,\n",
        "                       \"Larger experiment should complete within 15 seconds\")\n",
        "        self.assertIsNotNone(result[0])\n",
        "\n",
        "        self.assertEqual(len(result[3]), 11)\n",
        "        for generation in result[3]:\n",
        "            self.assertGreater(len(generation), 0)\n",
        "\n",
        "    def test_metric_logger_interface_compliance(self):\n",
        "        \"\"\"Test that metric loggers implement required interface properly.\"\"\"\n",
        "\n",
        "        logger = SimpleLogger()\n",
        "\n",
        "        self.assertIsInstance(logger, BaseMetricLogger)\n",
        "        self.assertTrue(hasattr(logger, 'log'))\n",
        "        self.assertTrue(hasattr(logger, 'get_metrics'))\n",
        "        self.assertTrue(callable(getattr(logger, 'log')))\n",
        "        self.assertTrue(callable(getattr(logger, 'get_metrics')))\n",
        "\n",
        "        test_population = [[0.1, 0.2], [0.3, 0.4]]\n",
        "        test_fitnesses = [0.5, 0.7]\n",
        "\n",
        "        try:\n",
        "            logger.log(test_population, test_fitnesses, 0)\n",
        "            metrics = logger.get_metrics()\n",
        "            self.assertIsInstance(metrics, dict)\n",
        "        except Exception as e:\n",
        "            self.fail(f\"Basic logger functionality failed: {e}\")\n",
        "\n",
        "    def test_algorithm_interface_contract(self):\n",
        "        \"\"\"Test that algorithms strictly follow their interface contracts.\"\"\"\n",
        "\n",
        "        algorithm = DEAlgorithm()\n",
        "\n",
        "        self.assertIsInstance(algorithm, BaseEvolutionaryAlgorithm)\n",
        "        self.assertTrue(hasattr(algorithm, 'evolve'))\n",
        "        self.assertTrue(callable(getattr(algorithm, 'evolve')))\n",
        "\n",
        "    def test_deterministic_behavior(self):\n",
        "        \"\"\"Same random_seed produces identical results.\"\"\"\n",
        "        result1 = run_experiment(**self.base_config)\n",
        "        result2 = run_experiment(**self.base_config)\n",
        "\n",
        "        self.assertEqual(result1[0], result2[0])\n",
        "        self.assertEqual(result1[1], result2[1])\n",
        "        self.assertEqual(result1[3], result2[3])\n",
        "        self.assertEqual(result1[4], result2[4])\n",
        "\n",
        "    def test_minimum_population_size_for_de(self):\n",
        "        \"\"\"Test that DE algorithm works with minimum required population size.\"\"\"\n",
        "        config = {\n",
        "            'population_size': 4,  # Minimum for DE algorithm\n",
        "            'num_generations': 2,\n",
        "            'algorithm': DEAlgorithm(),\n",
        "            'fitness_function': lambda x: sum(x),\n",
        "            'problem_bounds': ([0.0], [1.0]),\n",
        "            'metric_logger': SimpleLogger(),\n",
        "            'mutation_rate': 0.1,\n",
        "            'crossover_rate': 0.8,\n",
        "            'selection_strategy': RouletteSelection(),\n",
        "            'builder': ExperimentBuilder(),\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        result = run_experiment(**config)\n",
        "\n",
        "        self.assertIsNotNone(result[0])\n",
        "        self.assertEqual(len(result), 5)\n",
        "        self.assertEqual(len(result[3]), 3)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/f3c4151e-0c55-4926-b86c-040701850e87?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F66082%2Fview\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "# code generated by the model\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Callable, Tuple\n",
        "\n",
        "# ------------------ Base Interfaces ------------------ #\n",
        "\n",
        "class BaseEvolutionaryAlgorithm(ABC):\n",
        "    @abstractmethod\n",
        "    def evolve(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: \"BaseSelectionStrategy\",\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        pass\n",
        "\n",
        "class BaseSelectionStrategy(ABC):\n",
        "    @abstractmethod\n",
        "    def select(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        num_parents: int,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        pass\n",
        "\n",
        "class BaseMetricLogger(ABC):\n",
        "    @abstractmethod\n",
        "    def log(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitnesses: List[float],\n",
        "        generation: int\n",
        "    ) -> None:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_metrics(self) -> Dict[str, List[float]]:\n",
        "        pass\n",
        "\n",
        "# ------------------ Selection Strategies ------------------ #\n",
        "\n",
        "class RouletteSelection(BaseSelectionStrategy):\n",
        "    def select(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        num_parents: int,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        fitnesses = [fitness_function(ind) for ind in population]\n",
        "        # <Issue>: Assumes fitnesses are positive and higher is better; raw minimization returns negative/zero values.\n",
        "        total_fitness = sum(fitnesses)\n",
        "        if total_fitness == 0:\n",
        "            return rng.sample(population, num_parents)\n",
        "        selected = []\n",
        "        for _ in range(num_parents):\n",
        "            pick = rng.uniform(0, total_fitness)\n",
        "            current = 0\n",
        "            for ind, fit in zip(population, fitnesses):\n",
        "                current += fit\n",
        "                if current >= pick:\n",
        "                    selected.append(ind)\n",
        "                    break\n",
        "        return selected\n",
        "\n",
        "class TournamentSelection(BaseSelectionStrategy):\n",
        "    def select(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        num_parents: int,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        selected = []\n",
        "        for _ in range(num_parents):\n",
        "            contenders = rng.sample(population, 2)\n",
        "            fit_vals = [fitness_function(c) for c in contenders]\n",
        "            # <Issue>: Assumes higher fitness is better; incompatible with raw minimization functions.\n",
        "            winner = contenders[fit_vals.index(max(fit_vals))]\n",
        "            selected.append(winner)\n",
        "        return selected\n",
        "\n",
        "class RankSelection(BaseSelectionStrategy):\n",
        "    def select(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        num_parents: int,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        fitnesses = [(ind, fitness_function(ind)) for ind in population]\n",
        "        sorted_fitnesses = sorted(fitnesses, key=lambda x: x[1])\n",
        "        rank_sum = len(population) * (len(population) + 1) / 2\n",
        "        selected = []\n",
        "        for _ in range(num_parents):\n",
        "            pick = rng.uniform(0, rank_sum)\n",
        "            current = 0\n",
        "            for rank, (ind, fit) in enumerate(sorted_fitnesses, start=1):\n",
        "                current += rank\n",
        "                if current >= pick:\n",
        "                    selected.append(ind)\n",
        "                    break\n",
        "        return selected\n",
        "\n",
        "# ------------------ Metric Logger ------------------ #\n",
        "\n",
        "class SimpleLogger(BaseMetricLogger):\n",
        "    def __init__(self):\n",
        "        self.metrics = {\n",
        "            \"best_fitness\": [],\n",
        "            \"avg_fitness\": [],\n",
        "            \"diversity\": []\n",
        "        }\n",
        "\n",
        "    def log(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitnesses: List[float],\n",
        "        generation: int\n",
        "    ) -> None:\n",
        "        best_fitness = max(fitnesses)\n",
        "        avg_fitness = sum(fitnesses) / len(fitnesses) if fitnesses else 0\n",
        "        center = [sum(ind[i] for ind in population) / len(population) for i in range(len(population[0]))]\n",
        "        diversity = 0.0\n",
        "        for ind in population:\n",
        "            dist = math.sqrt(sum((x - c) ** 2 for x, c in zip(ind, center)))\n",
        "            diversity += dist\n",
        "        diversity /= len(population)\n",
        "        self.metrics[\"best_fitness\"].append(best_fitness)\n",
        "        self.metrics[\"avg_fitness\"].append(avg_fitness)\n",
        "        self.metrics[\"diversity\"].append(diversity)\n",
        "\n",
        "    def get_metrics(self) -> Dict[str, List[float]]:\n",
        "        return self.metrics\n",
        "\n",
        "# ------------------ Utility Functions ------------------ #\n",
        "\n",
        "def clamp(ind: List[float], bounds: Tuple[List[float], List[float]]) -> None:\n",
        "    for i in range(len(ind)):\n",
        "        ind[i] = max(bounds[0][i], min(bounds[1][i], ind[i]))\n",
        "\n",
        "def mutate(\n",
        "    ind: List[float],\n",
        "    mutation_rate: float,\n",
        "    problem_bounds: Tuple[List[float], List[float]],\n",
        "    rng: random.Random\n",
        ") -> None:\n",
        "    for i in range(len(ind)):\n",
        "        if rng.random() < mutation_rate:\n",
        "            scale = 0.1 * (problem_bounds[1][i] - problem_bounds[0][i])\n",
        "            ind[i] += rng.gauss(0, scale)\n",
        "            clamp(ind, problem_bounds)\n",
        "\n",
        "def uniform_crossover(\n",
        "    parent1: List[float],\n",
        "    parent2: List[float],\n",
        "    rng: random.Random\n",
        ") -> Tuple[List[float], List[float]]:\n",
        "    child1, child2 = [], []\n",
        "    for x, y in zip(parent1, parent2):\n",
        "        if rng.random() < 0.5:\n",
        "            child1.append(x)\n",
        "            child2.append(y)\n",
        "        else:\n",
        "            child1.append(y)\n",
        "            child2.append(x)\n",
        "    return child1, child2\n",
        "\n",
        "# ------------------ Evolutionary Algorithms ------------------ #\n",
        "\n",
        "class GAAlgorithm(BaseEvolutionaryAlgorithm):\n",
        "    def evolve(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: BaseSelectionStrategy,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        new_population = []\n",
        "        while len(new_population) < len(population):\n",
        "            parents = selection_strategy.select(population, fitness_function, 2, rng)\n",
        "            if rng.random() < crossover_rate:\n",
        "                child1, child2 = uniform_crossover(parents[0], parents[1], rng)\n",
        "            else:\n",
        "                child1, child2 = parents[0][:], parents[1][:]\n",
        "            mutate(child1, mutation_rate, problem_bounds, rng)\n",
        "            mutate(child2, mutation_rate, problem_bounds, rng)\n",
        "            new_population.append(child1)\n",
        "            new_population.append(child2)\n",
        "        return new_population[: len(population)]\n",
        "\n",
        "class DEAlgorithm(BaseEvolutionaryAlgorithm):\n",
        "    def evolve(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: BaseSelectionStrategy,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        F = 0.5\n",
        "        new_population = []\n",
        "        pop_size = len(population)\n",
        "        for i in range(pop_size):\n",
        "            candidates = list(range(pop_size))\n",
        "            candidates.remove(i)\n",
        "            r1, r2, r3 = rng.sample(candidates, 3)\n",
        "            donor = []\n",
        "            for dim in range(len(population[0])):\n",
        "                donor_val = population[r1][dim] + F * (population[r2][dim] - population[r3][dim])\n",
        "                donor.append(donor_val)\n",
        "            trial = []\n",
        "            for dim in range(len(population[0])):\n",
        "                if rng.random() < crossover_rate:\n",
        "                    val = donor[dim]\n",
        "                else:\n",
        "                    val = population[i][dim]\n",
        "                trial.append(val)\n",
        "            clamp(trial, problem_bounds)\n",
        "            # <Issue>: Assumes fitness_function returns higher-is-better scores; violates minimization generality.\n",
        "            if fitness_function(trial) > fitness_function(population[i]):\n",
        "                new_population.append(trial)\n",
        "            else:\n",
        "                new_population.append(population[i])\n",
        "        return new_population\n",
        "\n",
        "class ESAlgorithm(BaseEvolutionaryAlgorithm):\n",
        "    def evolve(\n",
        "        self,\n",
        "        population: List[List[float]],\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: BaseSelectionStrategy,\n",
        "        rng: random.Random\n",
        "    ) -> List[List[float]]:\n",
        "        offspring = []\n",
        "        for ind in population:\n",
        "            child = ind[:]\n",
        "            mutate(child, mutation_rate, problem_bounds, rng)\n",
        "            offspring.append(child)\n",
        "        combined = population + offspring\n",
        "        fitnesses = [fitness_function(ind) for ind in combined]\n",
        "        sorted_combined = sorted(zip(combined, fitnesses), key=lambda x: x[1], reverse=True)\n",
        "        return [ind for ind, _ in sorted_combined[: len(population)]]\n",
        "\n",
        "# ------------------ Experiment Builder ------------------ #\n",
        "\n",
        "class ExperimentBuilder:\n",
        "    def __init__(self):\n",
        "        self.population_size = None\n",
        "        self.num_generations = None\n",
        "        self.algorithm = None\n",
        "        self.fitness_function = None\n",
        "        self.problem_bounds = None\n",
        "        self.metric_logger = None\n",
        "        self.mutation_rate = None\n",
        "        self.crossover_rate = None\n",
        "        self.selection_strategy = None\n",
        "        self.random_seed = None\n",
        "\n",
        "    def configure(\n",
        "        self,\n",
        "        population_size: int,\n",
        "        num_generations: int,\n",
        "        algorithm: BaseEvolutionaryAlgorithm,\n",
        "        fitness_function: Callable[[List[float]], float],\n",
        "        problem_bounds: Tuple[List[float], List[float]],\n",
        "        metric_logger: BaseMetricLogger,\n",
        "        mutation_rate: float,\n",
        "        crossover_rate: float,\n",
        "        selection_strategy: BaseSelectionStrategy,\n",
        "        random_seed: int\n",
        "    ) -> \"ExperimentBuilder\":\n",
        "        self.population_size = population_size\n",
        "        self.num_generations = num_generations\n",
        "        self.algorithm = algorithm\n",
        "        self.fitness_function = fitness_function\n",
        "        self.problem_bounds = problem_bounds\n",
        "        self.metric_logger = metric_logger\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.selection_strategy = selection_strategy\n",
        "        self.random_seed = random_seed\n",
        "        return self\n",
        "\n",
        "    def run(self) -> Tuple[List[float], float, Dict[str, List[float]], List[List[List[float]]], List[List[float]]]:\n",
        "        rng = random.Random(self.random_seed)\n",
        "        np.random.seed(self.random_seed)\n",
        "\n",
        "        dim = len(self.problem_bounds[0])\n",
        "        population = [\n",
        "            [rng.uniform(self.problem_bounds[0][j], self.problem_bounds[1][j]) for j in range(dim)]\n",
        "            for _ in range(self.population_size)\n",
        "        ]\n",
        "\n",
        "        all_generations = [population[:]]\n",
        "\n",
        "        for gen in range(self.num_generations):\n",
        "            fitnesses = [self.fitness_function(ind) for ind in population]\n",
        "            self.metric_logger.log(population, fitnesses, gen)\n",
        "            population = self.algorithm.evolve(\n",
        "                population,\n",
        "                self.fitness_function,\n",
        "                self.problem_bounds,\n",
        "                self.mutation_rate,\n",
        "                self.crossover_rate,\n",
        "                self.selection_strategy,\n",
        "                rng\n",
        "            )\n",
        "            all_generations.append(population[:])\n",
        "\n",
        "        final_fitnesses = [self.fitness_function(ind) for ind in population]\n",
        "        best_idx = final_fitnesses.index(max(final_fitnesses))\n",
        "        best_solution = population[best_idx]\n",
        "        best_fitness = final_fitnesses[best_idx]\n",
        "\n",
        "        return best_solution, best_fitness, self.metric_logger.get_metrics(), all_generations, population\n",
        "\n",
        "# ------------------ Main Experiment Function ------------------ #\n",
        "\n",
        "def run_experiment(\n",
        "    population_size: int,\n",
        "    num_generations: int,\n",
        "    algorithm: BaseEvolutionaryAlgorithm,\n",
        "    fitness_function: Callable[[List[float]], float],\n",
        "    problem_bounds: Tuple[List[float], List[float]],\n",
        "    metric_logger: BaseMetricLogger,\n",
        "    mutation_rate: float,\n",
        "    crossover_rate: float,\n",
        "    selection_strategy: BaseSelectionStrategy,\n",
        "    builder: ExperimentBuilder,\n",
        "    random_seed: int\n",
        ") -> Tuple[List[float], float, Dict[str, List[float]], List[List[List[float]]], List[List[float]]]:\n",
        "    assert population_size > 0\n",
        "    assert num_generations > 0\n",
        "    assert 0.0 <= mutation_rate <= 1.0\n",
        "    assert 0.0 <= crossover_rate <= 1.0\n",
        "    assert random_seed >= 0\n",
        "    return builder.configure(\n",
        "        population_size,\n",
        "        num_generations,\n",
        "        algorithm,\n",
        "        fitness_function,\n",
        "        problem_bounds,\n",
        "        metric_logger,\n",
        "        mutation_rate,\n",
        "        crossover_rate,\n",
        "        selection_strategy,\n",
        "        random_seed\n",
        "    ).run()\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}