{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Backend Integration\n",
        "\n",
        "**L2 Taxonomy** - Webhooks\n",
        "\n",
        "**Subtopic** - Logging and auditing all received webhook events for debugging\n",
        "\n",
        "**Use Case** - Develop a Python script that listens for incoming webhook events, logs the event details, and stores them in a local JSON file for auditing and debugging purposes. This script should handle HTTP POST requests, extract relevant data from the request body, and append it to a JSON file in a structured format. This process will allow for easy review and debugging of all received webhook events.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSg66GeEbDAT",
        "outputId": "4b8358b8-2586-49bc-9d8b-566699c4e479"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "\"\"\"\n",
        "webhook_event_logger.py\n",
        "\n",
        "A hardened, standard-library-only webhook event logger with tamper-evident\n",
        "audit chaining and robust edge-case handling.\n",
        "\n",
        "Features\n",
        "--------\n",
        "- Listens on POST /webhook for JSON payloads.\n",
        "- Enforces Content-Type, Content-Length, UTF-8, and schema constraints.\n",
        "- Appends each event to events.jsonl and audit.log with SHA-256 hash chain.\n",
        "- Atomic, thread-safe writes via tempfile + os.replace and threading.Lock.\n",
        "- Auto-rotates events.jsonl when it exceeds 10 MiB.\n",
        "- Provides CLI:\n",
        "    * serve  — start HTTP listener\n",
        "    * verify — check audit log integrity (exit 0 if OK, 1 if broken)\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import base64\n",
        "import hashlib\n",
        "import http.server\n",
        "import json\n",
        "import os\n",
        "import signal\n",
        "import sys\n",
        "import tempfile\n",
        "import threading\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from typing import Any, Mapping\n",
        "\n",
        "# Constants\n",
        "_MAX_BODY_BYTES = 1_048_576  # 1 MiB\n",
        "_MAX_EVENTS_FILE_BYTES = 10 * _MAX_BODY_BYTES\n",
        "_EOL = \"\\n\"\n",
        "_LOCK = threading.Lock()\n",
        "\n",
        "\n",
        "def _b64url(data: bytes) -> str:\n",
        "    \"\"\"\n",
        "    Return a URL-safe Base64 encoding of `data` without padding.\n",
        "    \"\"\"\n",
        "    return base64.urlsafe_b64encode(data).rstrip(b\"=\").decode(\"ascii\")\n",
        "\n",
        "\n",
        "def _atomic_append(path: Path, text: str) -> None:\n",
        "    \"\"\"\n",
        "    Atomically append `text` (with newline) to the file at `path`.\n",
        "\n",
        "    Creates a temporary file in the same directory, writes the existing\n",
        "    contents plus `text`, then replaces the original via os.replace.\n",
        "    \"\"\"\n",
        "    fd, tmp_path = tempfile.mkstemp(dir=path.parent)\n",
        "    try:\n",
        "        with os.fdopen(fd, \"w\", encoding=\"utf-8\", newline=\"\") as tmp:\n",
        "            if path.exists():\n",
        "                tmp.write(path.read_text(\"utf-8\"))\n",
        "            if not text.endswith(_EOL):\n",
        "                text += _EOL\n",
        "            tmp.write(text)\n",
        "        os.replace(tmp_path, path)\n",
        "    finally:\n",
        "        if os.path.exists(tmp_path):\n",
        "            os.unlink(tmp_path)\n",
        "\n",
        "\n",
        "def _read_last_line(path: Path) -> str | None:\n",
        "    \"\"\"\n",
        "    Return the last line of the file at `path`, or None if missing/empty.\n",
        "    \"\"\"\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    with path.open(\"rb\") as f:\n",
        "        try:\n",
        "            f.seek(-2, os.SEEK_END)\n",
        "            while f.read(1) != b\"\\n\":\n",
        "                f.seek(-2, os.SEEK_CUR)\n",
        "        except OSError:\n",
        "            f.seek(0)\n",
        "        return f.readline().decode(\"utf-8\", \"replace\").rstrip(_EOL) or None\n",
        "\n",
        "\n",
        "def _lookup_event_json(events_path: Path, event_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Find and return the JSON line in `events_path` whose SHA-256 hash matches\n",
        "    `event_id`. Raises ValueError if not found.\n",
        "    \"\"\"\n",
        "    if not events_path.exists():\n",
        "        raise FileNotFoundError(\"events file missing\")\n",
        "    with events_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            candidate = line.rstrip(_EOL)\n",
        "            if hashlib.sha256(candidate.encode()).hexdigest() == event_id:\n",
        "                return candidate\n",
        "    raise ValueError(f\"event_id {event_id!r} not found\")\n",
        "\n",
        "\n",
        "class EventLogger:\n",
        "    \"\"\"\n",
        "    Thread-safe event logger with tamper-evident SHA-256 hash chain.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir: str | os.PathLike[str]) -> None:\n",
        "        \"\"\"\n",
        "        Initialize storage under `root_dir`, creating directories as needed.\n",
        "\n",
        "        Files:\n",
        "        - events.jsonl : JSON lines of {\"ts\": ..., \"payload\": ...}\n",
        "        - audit.log    : lines of \"<b64url(chain)> <event_id>\"\n",
        "        \"\"\"\n",
        "        self.root = Path(root_dir).resolve()\n",
        "        self.root.mkdir(parents=True, exist_ok=True)\n",
        "        self.events_file = self.root / \"events.jsonl\"\n",
        "        self.audit_file = self.root / \"audit.log\"\n",
        "\n",
        "    def append(self, payload: Mapping[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        Validate and persist `payload`. Return the deterministic `event_id`.\n",
        "\n",
        "        Raises:\n",
        "          TypeError  — if payload is not a mapping.\n",
        "          ValueError — if 'event' key is missing or malformed.\n",
        "        \"\"\"\n",
        "        if not isinstance(payload, Mapping):\n",
        "            raise TypeError(\"payload must be a mapping type\")\n",
        "\n",
        "        event = payload.get(\"event\")\n",
        "        if not isinstance(event, str) or not event.strip():\n",
        "            raise ValueError(\"'event' must be a non-empty string\")\n",
        "        if len(event.encode(\"utf-8\")) > 255:\n",
        "            raise ValueError(\"'event' exceeds 255 bytes\")\n",
        "        if any(ord(ch) < 32 for ch in event):\n",
        "            raise ValueError(\"'event' contains control characters\")\n",
        "\n",
        "        timestamp = datetime.now(timezone.utc).isoformat()\n",
        "        record = {\"ts\": timestamp, \"payload\": dict(payload)}\n",
        "        record_json = json.dumps(record, ensure_ascii=False)\n",
        "\n",
        "        # Compute event_id and hash-chain line\n",
        "        event_id = hashlib.sha256(record_json.encode()).hexdigest()\n",
        "        prev_line = _read_last_line(self.audit_file)\n",
        "        prev_id = prev_line.split(\" \")[1] if prev_line else \"0\" * 64\n",
        "        chain_hash = hashlib.sha256((prev_id + record_json).encode()).digest()\n",
        "        audit_line = f\"{_b64url(chain_hash)} {event_id}\"\n",
        "\n",
        "        with _LOCK:\n",
        "            _atomic_append(self.events_file, record_json)\n",
        "            _atomic_append(self.audit_file, audit_line)\n",
        "            self._rotate_events_if_needed()\n",
        "\n",
        "        return event_id\n",
        "\n",
        "    def verify(self) -> bool:\n",
        "        \"\"\"\n",
        "        Verify the integrity of the audit log's hash chain.\n",
        "\n",
        "        Returns True if intact or if no audit file; False on any mismatch.\n",
        "        \"\"\"\n",
        "        if not self.audit_file.exists():\n",
        "            return True\n",
        "\n",
        "        prev_id = \"0\" * 64\n",
        "        for line in self.audit_file.read_text(\"utf-8\").splitlines():\n",
        "            parts = line.split(\" \")\n",
        "            if len(parts) != 2:\n",
        "                return False\n",
        "            chain_b64, event_id = parts\n",
        "            try:\n",
        "                event_json = _lookup_event_json(self.events_file, event_id)\n",
        "            except (FileNotFoundError, ValueError):\n",
        "                return False\n",
        "            expected = hashlib.sha256((prev_id + event_json).encode()).digest()\n",
        "            if chain_b64 != _b64url(expected):\n",
        "                return False\n",
        "            prev_id = event_id\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _rotate_events_if_needed(self) -> None:\n",
        "        \"\"\"\n",
        "        Rotate events.jsonl to events-<timestamp>.jsonl if its size > 10 MiB,\n",
        "        then create a fresh events.jsonl.\n",
        "        \"\"\"\n",
        "        if self.events_file.stat().st_size <= _MAX_EVENTS_FILE_BYTES:\n",
        "            return\n",
        "\n",
        "        ts = datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%S\")\n",
        "        rotated = self.events_file.with_name(f\"events-{ts}.jsonl\")\n",
        "        os.replace(self.events_file, rotated)\n",
        "        self.events_file.touch()\n",
        "\n",
        "\n",
        "class WebhookHandler(http.server.BaseHTTPRequestHandler):\n",
        "    \"\"\"\n",
        "    HTTP request handler for POST /webhook.\n",
        "    Inject `logger: EventLogger` before starting server.\n",
        "    \"\"\"\n",
        "\n",
        "    logger: EventLogger  # to be set by server factory\n",
        "\n",
        "    def log_message(self, *args: Any) -> None:\n",
        "        \"\"\"Suppress default logging.\"\"\"\n",
        "        return\n",
        "\n",
        "    def _respond(self, code: int, body: dict[str, Any]) -> None:\n",
        "        \"\"\"Send JSON response with status `code` and JSON `body`.\"\"\"\n",
        "        payload = json.dumps(body).encode(\"utf-8\")\n",
        "        self.send_response(code)\n",
        "        self.send_header(\"Content-Type\", \"application/json\")\n",
        "        self.send_header(\"Content-Length\", str(len(payload)))\n",
        "        self.end_headers()\n",
        "        self.wfile.write(payload)\n",
        "\n",
        "    def do_POST(self) -> None:\n",
        "        \"\"\"Handle POST /webhook with full validation.\"\"\"\n",
        "        if self.path != \"/webhook\":\n",
        "            return self._respond(404, {\"error\": \"Not Found\"})\n",
        "\n",
        "        # Content-Type\n",
        "        ct = self.headers.get(\"Content-Type\", \"\").split(\";\", 1)[0]\n",
        "        if ct != \"application/json\":\n",
        "            return self._respond(415,\n",
        "                                 {\n",
        "                                     \"error\":\n",
        "                                     \"Content-Type must be application/json\"})\n",
        "\n",
        "        # Content-Length\n",
        "        try:\n",
        "            length = int(self.headers.get(\"Content-Length\", \"\"))\n",
        "        except ValueError:\n",
        "            return self._respond(411, {\"error\": \"Content-Length required\"})\n",
        "        if length > _MAX_BODY_BYTES:\n",
        "            return self._respond(413, {\"error\": \"Payload too large\"})\n",
        "\n",
        "        # Body read & UTF-8\n",
        "        raw = self.rfile.read(length)\n",
        "        try:\n",
        "            text = raw.decode(\"utf-8\")\n",
        "        except UnicodeDecodeError:\n",
        "            return self._respond(400, {\"error\": \"Body must be valid UTF-8\"})\n",
        "        if \"\\r\" in text or \"\\n\" in text:\n",
        "            return self._respond(400,\n",
        "\n",
        "                                  {\"error\":\n",
        "                                  \"Body contains forbidden control characters\"\n",
        "\n",
        "                                  })\n",
        "\n",
        "        # JSON parse\n",
        "        try:\n",
        "            obj = json.loads(text)\n",
        "        except json.JSONDecodeError:\n",
        "            return self._respond(400, {\"error\": \"Invalid JSON\"})\n",
        "        if not isinstance(obj, dict):\n",
        "            return self._respond(400, {\"error\": \"JSON must be an object\"})\n",
        "\n",
        "        # Pass to logger\n",
        "        try:\n",
        "            event_id = self.logger.append(obj)\n",
        "        except (TypeError, ValueError) as e:\n",
        "            return self._respond(422, {\"error\": str(e)})\n",
        "        except Exception as e:\n",
        "            return self._respond(500, {\"error\": f\"Internal error: {e}\"})\n",
        "\n",
        "        self._respond(200, {\"status\": \"ok\", \"id\": event_id})\n",
        "\n",
        "\n",
        "def _serve(root: str, host: str, port: int) -> None:\n",
        "    \"\"\"\n",
        "    Start the HTTP server on (host, port), serving WebhookHandler.\n",
        "    \"\"\"\n",
        "    logger = EventLogger(root)\n",
        "\n",
        "    class ThreadedHTTPServer(http.server.ThreadingHTTPServer):\n",
        "        def finish_request(self, request, client_address):\n",
        "            handler = WebhookHandler(request, client_address, self)\n",
        "            handler.logger = logger\n",
        "\n",
        "    server = ThreadedHTTPServer((host, port), WebhookHandler)\n",
        "\n",
        "    def _shutdown(signum, frame):\n",
        "        server.shutdown()\n",
        "\n",
        "    for sig in (signal.SIGINT, signal.SIGTERM):\n",
        "        signal.signal(sig, _shutdown)\n",
        "\n",
        "    print(f\"Webhook logger listening on {host}:{port}\", file=sys.stderr)\n",
        "    server.serve_forever()\n",
        "\n",
        "\n",
        "def _verify(root: str) -> None:\n",
        "    \"\"\"\n",
        "    CLI command to verify audit log. Exits 0 if OK, 1 otherwise.\n",
        "    \"\"\"\n",
        "    ok = EventLogger(root).verify()\n",
        "    sys.exit(0 if ok else 1)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"\n",
        "    Parse CLI args and dispatch to serve or verify.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(prog=\"webhook_event_logger\")\n",
        "    sub = parser.add_subparsers(dest=\"cmd\", required=True)\n",
        "\n",
        "    serve_p = sub.add_parser(\"serve\", help=\"Run HTTP webhook listener\")\n",
        "    serve_p.add_argument(\"--root\", required=True, help=\"Root directory for logs\")\n",
        "    serve_p.add_argument(\"--host\", default=\"0.0.0.0\", help=\"Host to bind\")\n",
        "    serve_p.add_argument(\"--port\", type=int, default=8000, help=\"Port to bind\")\n",
        "\n",
        "    verify_p = sub.add_parser(\"verify\", help=\"Verify audit log integrity\")\n",
        "    verify_p.add_argument(\"--root\", required=True, help=\"Root directory for logs\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    if args.cmd == \"serve\":\n",
        "        _serve(args.root, args.host, args.port)\n",
        "    else:\n",
        "        _verify(args.root)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\n",
        "import unittest\n",
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import shutil\n",
        "import threading\n",
        "import http.client\n",
        "import time\n",
        "import socket\n",
        "import sys\n",
        "\n",
        "import main  # assumes your implementation is in main.py\n",
        "\n",
        "# Helper to find an available port\n",
        "def find_free_port():\n",
        "    s = socket.socket()\n",
        "    s.bind(('localhost', 0))\n",
        "    port = s.getsockname()[1]\n",
        "    s.close()\n",
        "    return port\n",
        "\n",
        "class TestEventLogger(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tmpdir = tempfile.mkdtemp()\n",
        "        self.logger = main.EventLogger(self.tmpdir)\n",
        "\n",
        "    def tearDown(self):\n",
        "        shutil.rmtree(self.tmpdir)\n",
        "\n",
        "    def test_append_and_verify_success(self):\n",
        "        payload = {\"event\": \"user.created\", \"data\": {\"id\": 1}}\n",
        "        eid = self.logger.append(payload)\n",
        "\n",
        "        # Check events.jsonl\n",
        "        ev_file = os.path.join(self.tmpdir, 'events.jsonl')\n",
        "        with open(ev_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().splitlines()\n",
        "        self.assertEqual(len(lines), 1)\n",
        "        rec = json.loads(lines[0])\n",
        "        self.assertIn('ts', rec)\n",
        "        self.assertEqual(rec['payload'], payload)\n",
        "\n",
        "        # Check audit.log\n",
        "        au_file = os.path.join(self.tmpdir, 'audit.log')\n",
        "        with open(au_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().splitlines()\n",
        "        self.assertEqual(len(lines), 1)\n",
        "        chain, logged_eid = lines[0].split(' ')\n",
        "        self.assertEqual(logged_eid, eid)\n",
        "\n",
        "        # verify should be True\n",
        "        self.assertTrue(self.logger.verify())\n",
        "\n",
        "    def test_tamper_audit_detected(self):\n",
        "        eid = self.logger.append({\"event\": \"test\"})\n",
        "        au_file = os.path.join(self.tmpdir, 'audit.log')\n",
        "        with open(au_file, 'r+', encoding='utf-8') as f:\n",
        "            data = f.read()\n",
        "            f.seek(0)\n",
        "            f.write('X' + data[1:])\n",
        "            f.truncate()\n",
        "        self.assertFalse(self.logger.verify())\n",
        "\n",
        "    def test_invalid_event_payloads(self):\n",
        "        with self.assertRaises(TypeError):\n",
        "            self.logger.append(123)\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.logger.append({})            # missing event\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.logger.append({'event': ''})\n",
        "        long_event = 'a' * 256\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.logger.append({'event': long_event})\n",
        "\n",
        "class TestHTTPServer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tmpdir = tempfile.mkdtemp()\n",
        "        self.port = find_free_port()\n",
        "        server = http.server.ThreadingHTTPServer(('localhost', self.port), main.WebhookHandler)\n",
        "        main.WebhookHandler.logger = main.EventLogger(self.tmpdir)\n",
        "        self.server = server\n",
        "        self.thread = threading.Thread(target=server.serve_forever)\n",
        "        self.thread.daemon = True\n",
        "        self.thread.start()\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    def tearDown(self):\n",
        "        self.server.shutdown()\n",
        "        self.thread.join()\n",
        "        shutil.rmtree(self.tmpdir)\n",
        "\n",
        "    def http_post(self, body, headers):\n",
        "        conn = http.client.HTTPConnection('localhost', self.port)\n",
        "        conn.request('POST', '/webhook', body, headers)\n",
        "        resp = conn.getresponse()\n",
        "        data = resp.read().decode('utf-8')\n",
        "        conn.close()\n",
        "        return resp.status, data\n",
        "\n",
        "    def test_http_success(self):\n",
        "        body = json.dumps({'event': 'ping', 'data': {}})\n",
        "        status, data = self.http_post(\n",
        "            body,\n",
        "            {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n",
        "        )\n",
        "        self.assertEqual(status, 200)\n",
        "        obj = json.loads(data)\n",
        "        self.assertIn('id', obj)\n",
        "        self.assertTrue(main.WebhookHandler.logger.verify())\n",
        "\n",
        "    def test_http_not_found(self):\n",
        "        status, _ = self.http_post(\n",
        "            '{}',\n",
        "            {'Content-Type': 'application/json', 'Content-Length': '2'}\n",
        "        )\n",
        "        self.assertEqual(status, 404)\n",
        "\n",
        "    def test_http_bad_content_type(self):\n",
        "        body = json.dumps({'event': 'ping'})\n",
        "        status, data = self.http_post(\n",
        "            body,\n",
        "            {'Content-Type': 'text/plain', 'Content-Length': str(len(body))}\n",
        "        )\n",
        "        self.assertEqual(status, 415)\n",
        "        self.assertIn('error', json.loads(data))\n",
        "\n",
        "    def test_http_payload_too_large(self):\n",
        "        body = 'x' * (main._MAX_BODY_BYTES + 1)\n",
        "        status, _ = self.http_post(\n",
        "            body,\n",
        "            {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n",
        "        )\n",
        "        self.assertEqual(status, 413)\n",
        "\n",
        "    def test_http_invalid_json(self):\n",
        "        status, _ = self.http_post(\n",
        "            '{not json}',\n",
        "            {'Content-Type': 'application/json', 'Content-Length': '10'}\n",
        "        )\n",
        "        self.assertEqual(status, 400)\n",
        "\n",
        "class TestCLI(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tmpdir = tempfile.mkdtemp()\n",
        "\n",
        "    def tearDown(self):\n",
        "        shutil.rmtree(self.tmpdir)\n",
        "\n",
        "    def test_verify_exit_code(self):\n",
        "        # no events → exit 0\n",
        "        with self.assertRaises(SystemExit) as cm:\n",
        "            main._verify(self.tmpdir)\n",
        "        self.assertEqual(cm.exception.code, 0)\n",
        "\n",
        "        # tamper → exit non-zero\n",
        "        logger = main.EventLogger(self.tmpdir)\n",
        "        eid = logger.append({'event': 'e'})\n",
        "        audit = os.path.join(self.tmpdir, 'audit.log')\n",
        "        with open(audit, 'r+', encoding='utf-8') as f:\n",
        "            data = f.read(); f.seek(0); f.write('X'+data[1:]); f.truncate()\n",
        "        with self.assertRaises(SystemExit) as cm2:\n",
        "            main._verify(self.tmpdir)\n",
        "        self.assertNotEqual(cm2.exception.code, 0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/c78c742d-c77d-4748-871a-79050726b430?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F82818%2Fview\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "import threading\n",
        "import tempfile\n",
        "import base64  # <Issue>: The original code forgot to import base64 even though it uses it later.\n",
        "from datetime import datetime\n",
        "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
        "from typing import Any, Mapping\n",
        "\n",
        "MAX_CONTENT_LENGTH = 1 * 1024 * 1024  # 1 MiB\n",
        "MAX_EVENT_LENGTH = 255  # Max length for event field\n",
        "MAX_EVENTS_FILE_SIZE = 10 * 1024 * 1024  # 10 MiB\n",
        "\n",
        "\n",
        "class EventLogger:\n",
        "    def __init__(self, root_dir: str) -> None:\n",
        "        self.root_dir = root_dir\n",
        "        self.lock = threading.Lock()\n",
        "        self.events_file = os.path.join(self.root_dir, 'events.jsonl')\n",
        "        self.audit_file = os.path.join(self.root_dir, 'audit.log')\n",
        "        os.makedirs(self.root_dir, exist_ok=True)\n",
        "\n",
        "    def compute_event_id(self, event: dict) -> str:\n",
        "        \"\"\"Generate a deterministic event_id from the event JSON.\"\"\"\n",
        "        event_json = json.dumps(event, ensure_ascii=False, separators=(',', ':')).encode('utf-8')\n",
        "        return hashlib.sha256(event_json).hexdigest()\n",
        "\n",
        "    def append(self, payload: Mapping[str, Any]) -> str:\n",
        "        \"\"\"Append a valid event payload to the log files.\"\"\"\n",
        "        if not isinstance(payload, dict):\n",
        "            raise TypeError(\"Payload must be a mapping object\")\n",
        "\n",
        "        if \"event\" not in payload or not payload[\"event\"] or len(payload[\"event\"].encode(\"utf-8\")) > MAX_EVENT_LENGTH:\n",
        "            raise ValueError(\"Invalid 'event' field\")\n",
        "\n",
        "        if any(ord(c) < 32 and c not in (' ', '\\t') for c in payload['event']):  # <Issue>: Tab (0x09) is still a control char and should be rejected.\n",
        "            raise ValueError(\"Event field contains control characters\")\n",
        "\n",
        "        with self.lock:\n",
        "            timestamp = datetime.utcnow().isoformat(timespec='seconds') + 'Z'\n",
        "            record = {'ts': timestamp, 'payload': payload}\n",
        "            event_id = self.compute_event_id(record)\n",
        "\n",
        "            # Write to event file\n",
        "            record_json = json.dumps(record, ensure_ascii=False, separators=(',', ':'))\n",
        "            self._write_atomic(self.events_file, record_json + \"\\n\")  # <Issue>: _write_atomic overwrites the file; previous events are lost.\n",
        "\n",
        "            # Write to audit file\n",
        "            prev_event_id = \"0\" * 64\n",
        "            if os.path.exists(self.audit_file):\n",
        "                with open(self.audit_file, 'rb') as f:\n",
        "                    try:\n",
        "                        last_line = f.readlines()[-1].strip()\n",
        "                        prev_event_id = last_line.split()[1].decode()\n",
        "                    except IndexError:\n",
        "                        pass  # If audit file is empty\n",
        "\n",
        "            # <Issue>: Chain formula should be sha256(prev_event_id || record_json), but code uses json.dumps(record) again (may differ) and mismatches verify().\n",
        "            chain_hash = hashlib.sha256((prev_event_id + json.dumps(record)).encode()).digest()\n",
        "            self._write_atomic(self.audit_file, f\"{base64.urlsafe_b64encode(chain_hash).decode()} {event_id}\\n\")\n",
        "\n",
        "            self._rotate_events_if_needed()\n",
        "\n",
        "        return event_id\n",
        "\n",
        "    def _write_atomic(self, file_path: str, content: str) -> None:\n",
        "        \"\"\"Write content to a file atomically.\"\"\"\n",
        "        # <Issue>: This function writes only *content*, discarding all existing lines instead of appending.\n",
        "        with tempfile.NamedTemporaryFile('w', delete=False, dir=self.root_dir) as temp_file:\n",
        "            temp_file.write(content)\n",
        "            temp_path = temp_file.name\n",
        "        os.replace(temp_path, file_path)\n",
        "\n",
        "    def _rotate_events_if_needed(self) -> None:\n",
        "        \"\"\"Rotate the events file if its size exceeds the maximum limit.\"\"\"\n",
        "        if os.path.getsize(self.events_file) > MAX_EVENTS_FILE_SIZE:\n",
        "            timestamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "            new_name = f'events-{timestamp}.jsonl'\n",
        "            os.rename(self.events_file, os.path.join(self.root_dir, new_name))  # <Issue>: Does not create a fresh empty events.jsonl after rotation.\n",
        "\n",
        "    def verify(self) -> bool:\n",
        "        \"\"\"Verify the integrity of the audit log.\"\"\"\n",
        "        if not os.path.exists(self.audit_file):\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            with open(self.audit_file, 'r') as f:\n",
        "                prev_event_id = \"0\" * 64\n",
        "                for line in f:\n",
        "                    chain_hash_encoded, event_id = line.strip().split()\n",
        "                    expected_chain_hash = hashlib.sha256((prev_event_id + event_id).encode()).digest()  # <Issue>: Should hash prev_event_id || event_json, not event_id.\n",
        "                    if base64.urlsafe_b64encode(expected_chain_hash).decode() != chain_hash_encoded:\n",
        "                        return False\n",
        "                    prev_event_id = event_id\n",
        "        except Exception:\n",
        "            return False  # <Issue>: Broad except hides bugs; should log or re‑raise specific errors.\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "class WebhookRequestHandler(BaseHTTPRequestHandler):\n",
        "    def __init__(self, *args, root_dir=None, logger: EventLogger = None, **kwargs):\n",
        "        self.root_dir = root_dir\n",
        "        self.logger = logger\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def do_POST(self):\n",
        "        if self.path != '/webhook':\n",
        "            self.send_error(404, 'Not Found', '{\"error\":\"Path not found\"}')  # <Issue>: send_error returns HTML by default; custom body may be ignored.\n",
        "            return\n",
        "\n",
        "        content_length = self.headers.get('Content-Length')\n",
        "        if content_length is None:\n",
        "            self.send_error(411, 'Length Required', '{\"error\":\"Content-Length header is required\"}')\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            content_length = int(content_length)\n",
        "            if content_length > MAX_CONTENT_LENGTH:\n",
        "                self.send_error(413, 'Payload Too Large', '{\"error\":\"Payload too large\"}')\n",
        "                return\n",
        "        except ValueError:\n",
        "            self.send_error(411, 'Length Required', '{\"error\":\"Content-Length header is invalid\"}')\n",
        "            return\n",
        "\n",
        "        content_type = self.headers.get('Content-Type')\n",
        "        if content_type != 'application/json':  # <Issue>: Rejects valid 'application/json; charset=utf-8'.\n",
        "            self.send_error(415, 'Unsupported Media Type', '{\"error\":\"Content-Type must be application/json\"}')\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            post_data = self.rfile.read(content_length)\n",
        "            if b'\\r' in post_data or b'\\n' in post_data:\n",
        "                raise ValueError(\"Control character in body\")\n",
        "            payload = json.loads(post_data.decode('utf-8'))\n",
        "        except (json.JSONDecodeError, UnicodeDecodeError, ValueError):\n",
        "            self.send_error(400, 'Bad Request', '{\"error\":\"Invalid JSON or UTF-8 encoding\"}')\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            event_id = self.logger.append(payload)\n",
        "            self.send_response(200)\n",
        "            self.send_header('Content-Type', 'application/json')\n",
        "            self.end_headers()\n",
        "            self.wfile.write(json.dumps({'status': 'ok', 'id': event_id}).encode('utf-8'))\n",
        "        except (TypeError, ValueError) as e:\n",
        "            self.send_error(422, 'Unprocessable Entity', f'{{\"error\":\"{str(e)}\"}}')\n",
        "\n",
        "    def log_message(self, format, *args):\n",
        "        # Override to prevent default stdout logging\n",
        "        return  # <Issue>: Good – suppresses noisy server logs.\n",
        "\n",
        "\n",
        "def run_server(root_dir, host='0.0.0.0', port=8000):\n",
        "    logger = EventLogger(root_dir)\n",
        "\n",
        "    def handler(*args, **kwargs):\n",
        "        WebhookRequestHandler(*args, root_dir=root_dir, logger=logger, **kwargs)\n",
        "\n",
        "    httpd = HTTPServer((host, port), handler)\n",
        "    print(f\"Starting server on {host}:{port}\")\n",
        "    try:\n",
        "        httpd.serve_forever()\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    finally:\n",
        "        httpd.server_close()\n",
        "        print(\"Server stopped.\")\n",
        "\n",
        "\n",
        "def cli():\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Webhook Event Logger\")\n",
        "    subparsers = parser.add_subparsers(dest='command', help='sub-command help')\n",
        "\n",
        "    serve_parser = subparsers.add_parser('serve', help='Start the HTTP server')\n",
        "    serve_parser.add_argument('--root', required=True, help='Root directory for event logs')\n",
        "    serve_parser.add_argument('--host', default='0.0.0.0', help='Host to run the server on')\n",
        "    serve_parser.add_argument('--port', type=int, default=8000, help='Port to run the server on')\n",
        "\n",
        "    verify_parser = subparsers.add_parser('verify', help='Verify the audit log')\n",
        "    verify_parser.add_argument('--root', required=True, help='Root directory for event logs')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.command == 'serve':\n",
        "        run_server(root_dir=args.root, host=args.host, port=args.port)\n",
        "    elif args.command == 'verify':\n",
        "        logger = EventLogger(args.root)\n",
        "        result = logger.verify()\n",
        "        if result:\n",
        "            print(\"Audit log OK\")\n",
        "        else:\n",
        "            print(\"Audit log tampered\")\n",
        "        exit(0 if result else 1)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cli()\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
