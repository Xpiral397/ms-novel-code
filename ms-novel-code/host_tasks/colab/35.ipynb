{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Backend Development\n",
        "\n",
        "**L2 Taxonomy** - API Gateways\n",
        "\n",
        "**Subtopic** - Implementing API Gateway Rate Limiting\n",
        "\n",
        "**Use Case** - Develop an anomaly detection module using scikit-learn to identify and alert on unusual spikes in API request rates within an Istio service mesh.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "\n",
        "TechAI Corp operates an AI platform serving three subscriber tiers (Free, Professional, Enterprise) with different usage limits and priorities. Different AI operations consume varying computational resources based on input content length. The system must enforce rate limits across multiple time windows (per-second, per-minute, per-day) while providing priority queuing during high traffic. You must implement a decorator-based rate limiting system that handles tokenization, multi-tier limits, and intelligent queuing to protect API endpoints while ensuring fair resource allocation.\n",
        "\n",
        "**Input Format**\n",
        "* Methods: list of method names to call [\"AIRateLimiter\", \"create_limiter\", \"generate_text\"]\n",
        "* Parameters: list of parameter lists for each method call\n",
        "* Constructor parameters: tier_configs, time_windows, operation_costs, limiter_type\n",
        "\n",
        "**Output Format**\n",
        "* Results: list of return values for each method call\n",
        "* Constructor/void methods return null\n",
        "* Successful calls: original response + rate limiting metadata\n",
        "* Queued calls: queue position, wait time, priority level\n",
        "* Rejected calls: error response with retry timing\n",
        "\n",
        "**Examples**\n",
        "\n",
        "```python\n",
        "# Example 1: Request-based rate limiting\n",
        "Input: [\"AIRateLimiter\", \"create_limiter\", \"generate_text\", \"generate_text\", \"generate_text\"]\n",
        "       [[{\"pro\": {\"limits\": [2, 10], \"priority\": 2}}, [1, 60], {}, \"request\"], [], [\"user1\", \"pro\", \"text_gen\", \"hello\"], [\"user1\", \"pro\", \"text_gen\", \"world\"], [\"user1\", \"pro\", \"text_gen\", \"test\"]]\n",
        "Output: [null, decorator_function, {\"result\": \"hello\", \"rate_limit_info\": {\"requests_consumed\": 1, \"remaining_requests\": [1, 9]}}, {\"result\": \"world\", \"rate_limit_info\": {\"requests_consumed\": 1, \"remaining_requests\": [0, 8]}}, {\"status\": \"queued\", \"queue_position\": 1, \"estimated_wait_time\": 1}]\n",
        "\n",
        "# Example 2: Token-based rate limiting  \n",
        "Input: [\"AIRateLimiter\", \"create_limiter\", \"generate_text\"]\n",
        "       [[{\"pro\": {\"token_limits\": [5, 50], \"priority\": 2}}, [1, 60], {\"text_gen\": 2}, \"token\"], [], [\"user1\", \"pro\", \"text_gen\", \"one two three\"]]\n",
        "Output: [null, decorator_function, {\"status\": \"queued\", \"queue_position\": 1, \"estimated_wait_time\": 1}]\n",
        "\n",
        "# Example 3: Successful token consumption\n",
        "Input: [\"AIRateLimiter\", \"create_limiter\", \"get_token_count\", \"generate_text\"]\n",
        "       [[{\"pro\": {\"token_limits\": [5, 50], \"priority\": 2}}, [1, 60], {\"text_gen\": 2}, \"token\"], [], [\"hello\"], [\"user1\", \"pro\", \"text_gen\", \"hello\"]]\n",
        "Output: [null, decorator_function, 1, {\"result\": \"hello\", \"rate_limit_info\": {\"tokens_consumed\": 2, \"remaining_tokens\": [3, 48]}}]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "**Explicit and Implicit Points**\n",
        "* Implement factory pattern creating two rate limiter types: \"token\" and \"request\" based\n",
        "* Token type: calculates consumption as content_word_count × operation_cost\n",
        "* Request type: each API call consumes 1 from limits regardless of content size\n",
        "* Support three time windows simultaneously with independent limits\n",
        "* Implement priority queuing when limits exceeded (enterprise > pro > free)\n",
        "* Return appropriate metadata based on limiter type (tokens_consumed vs requests_consumed)\n",
        "\n",
        "**Solution Expectations**\n",
        "* Create AIRateLimiter class as factory for generating decorator functions\n",
        "* Implement get_token_count method for content tokenization by splitting on whitespace\n",
        "* Design extensible architecture allowing dynamic configuration changes\n",
        "* Store per-user state across multiple time windows using dictionaries\n",
        "* Handle queue management with priority levels and wait time estimation\n",
        "* Preserve original function behavior while adding rate limit metadata\n",
        "\n",
        "**Function Signatures**\n",
        "```python\n",
        "class AIRateLimiter:\n",
        "    def __init__(self, tier_configs: dict, time_windows: list, operation_costs: dict, limiter_type: str):\n",
        "        # Initialize factory with configurations and limiter type (\"token\" or \"request\")\n",
        "        pass\n",
        "    \n",
        "    def get_token_count(self, content: str) -> int:\n",
        "        # Tokenization method - split content and return token count\n",
        "        pass\n",
        "    \n",
        "    def create_limiter(self):\n",
        "        # Factory method that returns appropriate decorator based on limiter_type\n",
        "        pass\n",
        "```\n",
        "\n",
        "**Edge Case Behavior**\n",
        "* New users start with full token allocation for their tier\n",
        "* Handle time window boundary crossings and limit resets accurately\n",
        "* Empty content defaults to 1 token minimum consumption\n",
        "* Process queued requests by priority then FIFO order\n",
        "\n",
        "**Constraints**\n",
        "* Use only Python standard library modules\n",
        "* Store all state in memory using dictionaries\n",
        "* Support up to 1000 users with 10000 total requests\n",
        "* Content limited to 1000 words maximum\n",
        "* All configuration values must be positive integers\n",
        "* Decorated functions must have (user_id, tier, operation, content) as first parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "\"\"\"AI Rate Limiter Implementation for Task 69308.\"\"\"\n",
        "\n",
        "import time\n",
        "import heapq\n",
        "from functools import wraps\n",
        "from typing import Dict, List, Tuple, Any, Callable\n",
        "\n",
        "\n",
        "class AIRateLimiter:\n",
        "    \"\"\"Factory class for creating AI platform rate limiters.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tier_configs: Dict[str, Dict],\n",
        "        time_windows: List[int],\n",
        "        operation_costs: Dict[str, int],\n",
        "        limiter_type: str,\n",
        "    ):\n",
        "        \"\"\"Initialize the rate limiter factory.\"\"\"\n",
        "        self.tier_configs = tier_configs\n",
        "        self.time_windows = time_windows\n",
        "        self.operation_costs = operation_costs\n",
        "        self.limiter_type = limiter_type\n",
        "        self.user_state: Dict[str, Dict[int, List[Tuple[float, int]]]] = {}\n",
        "        self.request_queue: List[Tuple[int, float, str, Dict]] = []\n",
        "        self._priority_map = {\n",
        "            tier: config[\"priority\"] for tier, config in tier_configs.items()\n",
        "        }\n",
        "        self.user_tiers: Dict[str, str] = {}\n",
        "\n",
        "    def _validate_inputs(\n",
        "        self, user_id: str, tier: str, operation: str, content: str\n",
        "    ) -> None:\n",
        "        \"\"\"Validate all inputs before processing.\"\"\"\n",
        "        if not isinstance(user_id, str) or not user_id.strip():\n",
        "            raise ValueError(\"user_id must be a non-empty string\")\n",
        "\n",
        "        if not isinstance(tier, str) or tier not in self.tier_configs:\n",
        "            raise ValueError(\n",
        "                f\"Unknown tier: {tier}. Available tiers: \"\n",
        "                f\"{list(self.tier_configs.keys())}\"\n",
        "            )\n",
        "\n",
        "        if not isinstance(operation, str) or not operation.strip():\n",
        "            raise ValueError(\"operation must be a non-empty string\")\n",
        "\n",
        "        if not isinstance(content, str):\n",
        "            raise ValueError(\"content must be a string\")\n",
        "\n",
        "        tier_config = self.tier_configs[tier]\n",
        "        required_key = \"token_limits\" if self.limiter_type == \"token\" else \"limits\"\n",
        "        if required_key not in tier_config:\n",
        "            raise ValueError(f\"Tier {tier} missing {required_key} configuration\")\n",
        "\n",
        "        limits = tier_config[required_key]\n",
        "        if len(limits) != len(self.time_windows):\n",
        "            raise ValueError(\n",
        "                f\"Tier {tier} has {len(limits)} limits but \"\n",
        "                f\"{len(self.time_windows)} time windows\"\n",
        "            )\n",
        "\n",
        "    def get_token_count(self, content: str) -> int:\n",
        "        \"\"\"Calculate token count from content.\"\"\"\n",
        "        if not content or not content.strip():\n",
        "            return 1\n",
        "        return len(content.split())\n",
        "\n",
        "    def create_limiter(self) -> Callable:\n",
        "        \"\"\"Create appropriate decorator based on limiter_type.\"\"\"\n",
        "        if self.limiter_type == \"token\":\n",
        "            return self._create_token_limiter()\n",
        "        elif self.limiter_type == \"request\":\n",
        "            return self._create_request_limiter()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown limiter type: {self.limiter_type}\")\n",
        "\n",
        "    def _create_token_limiter(self) -> Callable:\n",
        "        \"\"\"Create token-based rate limiter decorator.\"\"\"\n",
        "\n",
        "        @wraps(self._create_token_limiter)\n",
        "        def token_limiter(func: Callable) -> Callable:\n",
        "            @wraps(func)\n",
        "            def wrapper(\n",
        "                user_id: str, tier: str, operation: str, content: str\n",
        "            ) -> Dict[str, Any]:\n",
        "                self._validate_inputs(user_id, tier, operation, content)\n",
        "                current_time = time.time()\n",
        "                self.user_tiers[user_id] = tier\n",
        "                token_count = self.get_token_count(content)\n",
        "                consumption = token_count * self.operation_costs.get(operation, 1)\n",
        "\n",
        "                if self._check_rate_limits(user_id, tier, consumption, current_time):\n",
        "                    self._record_consumption(user_id, consumption, current_time)\n",
        "                    result = func(user_id, tier, operation, content)\n",
        "                    remaining_tokens = self._calculate_remaining_capacity(\n",
        "                        user_id, tier, current_time\n",
        "                    )\n",
        "                    return {\n",
        "                        \"result\": result,\n",
        "                        \"rate_limit_info\": {\n",
        "                            \"tokens_consumed\": consumption,\n",
        "                            \"remaining_tokens\": remaining_tokens,\n",
        "                        },\n",
        "                    }\n",
        "                else:\n",
        "                    return self._add_to_queue(\n",
        "                        user_id,\n",
        "                        tier,\n",
        "                        {\n",
        "                            \"operation\": operation,\n",
        "                            \"content\": content,\n",
        "                            \"consumption\": consumption,\n",
        "                        },\n",
        "                    )\n",
        "\n",
        "            return wrapper\n",
        "\n",
        "        return token_limiter\n",
        "\n",
        "    def _create_request_limiter(self) -> Callable:\n",
        "        \"\"\"Create request-based rate limiter decorator.\"\"\"\n",
        "\n",
        "        @wraps(self._create_request_limiter)\n",
        "        def request_limiter(func: Callable) -> Callable:\n",
        "            @wraps(func)\n",
        "            def wrapper(\n",
        "                user_id: str, tier: str, operation: str, content: str\n",
        "            ) -> Dict[str, Any]:\n",
        "                self._validate_inputs(user_id, tier, operation, content)\n",
        "                current_time = time.time()\n",
        "                self.user_tiers[user_id] = tier\n",
        "                consumption = 1\n",
        "\n",
        "                if self._check_rate_limits(user_id, tier, consumption, current_time):\n",
        "                    self._record_consumption(user_id, consumption, current_time)\n",
        "                    result = func(user_id, tier, operation, content)\n",
        "                    remaining_requests = self._calculate_remaining_capacity(\n",
        "                        user_id, tier, current_time\n",
        "                    )\n",
        "                    return {\n",
        "                        \"result\": result,\n",
        "                        \"rate_limit_info\": {\n",
        "                            \"requests_consumed\": consumption,\n",
        "                            \"remaining_requests\": remaining_requests,\n",
        "                        },\n",
        "                    }\n",
        "                else:\n",
        "                    return self._add_to_queue(\n",
        "                        user_id,\n",
        "                        tier,\n",
        "                        {\n",
        "                            \"operation\": operation,\n",
        "                            \"content\": content,\n",
        "                            \"consumption\": consumption,\n",
        "                        },\n",
        "                    )\n",
        "\n",
        "            return wrapper\n",
        "\n",
        "        return request_limiter\n",
        "\n",
        "    def _check_rate_limits(\n",
        "        self, user_id: str, tier: str, consumption: int, current_time: float\n",
        "    ) -> bool:\n",
        "        \"\"\"Check if request is within rate limits for all time windows.\"\"\"\n",
        "        self._cleanup_expired_entries(user_id, current_time)\n",
        "        tier_config = self.tier_configs.get(tier, {})\n",
        "        limits = (\n",
        "            tier_config.get(\"limits\", [])\n",
        "            if self.limiter_type == \"request\"\n",
        "            else tier_config.get(\"token_limits\", [])\n",
        "        )\n",
        "\n",
        "        for window_idx, limit in enumerate(limits):\n",
        "            current_usage = self._get_window_usage(user_id, window_idx)\n",
        "            if current_usage + consumption > limit:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _cleanup_expired_entries(self, user_id: str, current_time: float) -> None:\n",
        "        \"\"\"Remove expired entries from user state.\"\"\"\n",
        "        if user_id not in self.user_state:\n",
        "            return\n",
        "\n",
        "        for window_idx, window_seconds in enumerate(self.time_windows):\n",
        "            if window_idx in self.user_state[user_id]:\n",
        "                cutoff_time = current_time - window_seconds\n",
        "                self.user_state[user_id][window_idx] = [\n",
        "                    (timestamp, consumption)\n",
        "                    for timestamp, consumption in self.user_state[user_id][window_idx]\n",
        "                    if timestamp > cutoff_time\n",
        "                ]\n",
        "\n",
        "    def _get_window_usage(self, user_id: str, window_idx: int) -> int:\n",
        "        \"\"\"Get current usage for a specific time window.\"\"\"\n",
        "        if user_id not in self.user_state or window_idx not in self.user_state[user_id]:\n",
        "            return 0\n",
        "        return sum(\n",
        "            consumption for _, consumption in self.user_state[user_id][window_idx]\n",
        "        )\n",
        "\n",
        "    def _record_consumption(\n",
        "        self, user_id: str, consumption: int, timestamp: float\n",
        "    ) -> None:\n",
        "        \"\"\"Record consumption across all time windows.\"\"\"\n",
        "        if user_id not in self.user_state:\n",
        "            self.user_state[user_id] = {}\n",
        "\n",
        "        for window_idx in range(len(self.time_windows)):\n",
        "            if window_idx not in self.user_state[user_id]:\n",
        "                self.user_state[user_id][window_idx] = []\n",
        "            self.user_state[user_id][window_idx].append((timestamp, consumption))\n",
        "\n",
        "    def _calculate_remaining_capacity(\n",
        "        self, user_id: str, tier: str, current_time: float\n",
        "    ) -> List[int]:\n",
        "        \"\"\"Calculate remaining capacity for each time window.\"\"\"\n",
        "        self._cleanup_expired_entries(user_id, current_time)\n",
        "        tier_config = self.tier_configs.get(tier, {})\n",
        "        limits = (\n",
        "            tier_config.get(\"limits\", [])\n",
        "            if self.limiter_type == \"request\"\n",
        "            else tier_config.get(\"token_limits\", [])\n",
        "        )\n",
        "\n",
        "        remaining = []\n",
        "        for window_idx, limit in enumerate(limits):\n",
        "            current_usage = self._get_window_usage(user_id, window_idx)\n",
        "            remaining.append(max(0, limit - current_usage))\n",
        "\n",
        "        return remaining\n",
        "\n",
        "    def _add_to_queue(\n",
        "        self, user_id: str, tier: str, request_data: Dict\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Add request to priority queue.\"\"\"\n",
        "        current_time = time.time()\n",
        "        priority = self._priority_map.get(tier, 999)\n",
        "\n",
        "        queue_position = (\n",
        "            sum(\n",
        "                1\n",
        "                for p, t, _, _ in self.request_queue\n",
        "                if p < priority or (p == priority and t < current_time)\n",
        "            )\n",
        "            + 1\n",
        "        )\n",
        "\n",
        "        heapq.heappush(\n",
        "            self.request_queue, (priority, current_time, user_id, request_data)\n",
        "        )\n",
        "\n",
        "        estimated_wait_time = min(self.time_windows)\n",
        "\n",
        "        return {\n",
        "            \"status\": \"queued\",\n",
        "            \"queue_position\": queue_position,\n",
        "            \"estimated_wait_time\": estimated_wait_time,\n",
        "        }\n",
        "\n",
        "    def process_queue(self) -> List[Dict]:\n",
        "        \"\"\"Process queued requests that can now be executed.\"\"\"\n",
        "        processed = []\n",
        "        current_time = time.time()\n",
        "\n",
        "        while self.request_queue:\n",
        "            priority, timestamp, user_id, request_data = self.request_queue[0]\n",
        "            tier = self.user_tiers.get(user_id, \"unknown\")\n",
        "            if tier == \"unknown\":\n",
        "                heapq.heappop(self.request_queue)\n",
        "                continue\n",
        "\n",
        "            if self._check_rate_limits(\n",
        "                user_id, tier, request_data[\"consumption\"], current_time\n",
        "            ):\n",
        "                heapq.heappop(self.request_queue)\n",
        "                self._record_consumption(\n",
        "                    user_id, request_data[\"consumption\"], current_time\n",
        "                )\n",
        "                processed.append(\n",
        "                    {\n",
        "                        \"user_id\": user_id,\n",
        "                        \"tier\": tier,\n",
        "                        \"operation\": request_data[\"operation\"],\n",
        "                        \"content\": request_data[\"content\"],\n",
        "                        \"processed\": True,\n",
        "                    }\n",
        "                )\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return processed\n",
        "\n",
        "## Optional code to run test cases, and check main file for issue\n",
        "\n",
        "def generate_text(user_id: str, tier: str, operation: str, content: str) -> str:\n",
        "    \"\"\"Mock function that generates text.\"\"\"\n",
        "    return content\n",
        "\n",
        "\n",
        "def run_examples():\n",
        "    \"\"\"Run the examples from the problem statement.\"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Example 1: Request-based rate limiting\n",
        "    methods = [\n",
        "        \"AIRateLimiter\",\n",
        "        \"create_limiter\",\n",
        "        \"generate_text\",\n",
        "        \"generate_text\",\n",
        "        \"generate_text\",\n",
        "    ]\n",
        "    parameters = [\n",
        "        [{\"pro\": {\"limits\": [2, 10], \"priority\": 2}}, [1, 60], {}, \"request\"],\n",
        "        [],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"hello\"],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"world\"],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"test\"],\n",
        "    ]\n",
        "\n",
        "    # Execute methods\n",
        "    limiter = None\n",
        "    decorator_func = None\n",
        "\n",
        "    for i, (method, params) in enumerate(zip(methods, parameters)):\n",
        "        if method == \"AIRateLimiter\":\n",
        "            limiter = AIRateLimiter(*params)\n",
        "            results.append(None)\n",
        "        elif method == \"create_limiter\":\n",
        "            decorator_func = limiter.create_limiter()\n",
        "            results.append(\"decorator_function\")\n",
        "        elif method == \"generate_text\":\n",
        "            if decorator_func:\n",
        "                decorated_func = decorator_func(generate_text)\n",
        "                result = decorated_func(*params)\n",
        "                results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_all_examples():\n",
        "    \"\"\"Run all examples from the problem statement.\"\"\"\n",
        "    print(\"=== Testing All Examples ===\\n\")\n",
        "\n",
        "    # Example 1: Request-based rate limiting\n",
        "    print(\"Example 1: Request-based rate limiting\")\n",
        "    methods1 = [\n",
        "        \"AIRateLimiter\",\n",
        "        \"create_limiter\",\n",
        "        \"generate_text\",\n",
        "        \"generate_text\",\n",
        "        \"generate_text\",\n",
        "    ]\n",
        "    parameters1 = [\n",
        "        [{\"pro\": {\"limits\": [2, 10], \"priority\": 2}}, [1, 60], {}, \"request\"],\n",
        "        [],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"hello\"],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"world\"],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"test\"],\n",
        "    ]\n",
        "\n",
        "    results1 = []\n",
        "    limiter1 = None\n",
        "    decorator_func1 = None\n",
        "\n",
        "    for i, (method, params) in enumerate(zip(methods1, parameters1)):\n",
        "        if method == \"AIRateLimiter\":\n",
        "            limiter1 = AIRateLimiter(*params)\n",
        "            results1.append(None)\n",
        "        elif method == \"create_limiter\":\n",
        "            decorator_func1 = limiter1.create_limiter()\n",
        "            results1.append(\"decorator_function\")\n",
        "        elif method == \"generate_text\":\n",
        "            if decorator_func1:\n",
        "                decorated_func1 = decorator_func1(generate_text)\n",
        "                result = decorated_func1(*params)\n",
        "                results1.append(result)\n",
        "\n",
        "    for i, result in enumerate(results1):\n",
        "        print(f\"  {i+1}: {result}\")\n",
        "\n",
        "    # Example 2: Token-based rate limiting\n",
        "    print(\"\\nExample 2: Token-based rate limiting\")\n",
        "    methods2 = [\"AIRateLimiter\", \"create_limiter\", \"generate_text\"]\n",
        "    parameters2 = [\n",
        "        [\n",
        "            {\"pro\": {\"token_limits\": [5, 50], \"priority\": 2}},\n",
        "            [1, 60],\n",
        "            {\"text_gen\": 2},\n",
        "            \"token\",\n",
        "        ],\n",
        "        [],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"one two three\"],\n",
        "    ]\n",
        "\n",
        "    results2 = []\n",
        "    limiter2 = None\n",
        "    decorator_func2 = None\n",
        "\n",
        "    for i, (method, params) in enumerate(zip(methods2, parameters2)):\n",
        "        if method == \"AIRateLimiter\":\n",
        "            limiter2 = AIRateLimiter(*params)\n",
        "            results2.append(None)\n",
        "        elif method == \"create_limiter\":\n",
        "            decorator_func2 = limiter2.create_limiter()\n",
        "            results2.append(\"decorator_function\")\n",
        "        elif method == \"generate_text\":\n",
        "            if decorator_func2:\n",
        "                decorated_func2 = decorator_func2(generate_text)\n",
        "                result = decorated_func2(*params)\n",
        "                results2.append(result)\n",
        "\n",
        "    for i, result in enumerate(results2):\n",
        "        print(f\"  {i+1}: {result}\")\n",
        "\n",
        "    # Example 3: Successful token consumption\n",
        "    print(\"\\nExample 3: Successful token consumption\")\n",
        "    methods3 = [\"AIRateLimiter\", \"create_limiter\", \"get_token_count\", \"generate_text\"]\n",
        "    parameters3 = [\n",
        "        [\n",
        "            {\"pro\": {\"token_limits\": [5, 50], \"priority\": 2}},\n",
        "            [1, 60],\n",
        "            {\"text_gen\": 2},\n",
        "            \"token\",\n",
        "        ],\n",
        "        [],\n",
        "        [\"hello\"],\n",
        "        [\"user1\", \"pro\", \"text_gen\", \"hello\"],\n",
        "    ]\n",
        "\n",
        "    results3 = []\n",
        "    limiter3 = None\n",
        "    decorator_func3 = None\n",
        "\n",
        "    for i, (method, params) in enumerate(zip(methods3, parameters3)):\n",
        "        if method == \"AIRateLimiter\":\n",
        "            limiter3 = AIRateLimiter(*params)\n",
        "            results3.append(None)\n",
        "        elif method == \"create_limiter\":\n",
        "            decorator_func3 = limiter3.create_limiter()\n",
        "            results3.append(\"decorator_function\")\n",
        "        elif method == \"get_token_count\":\n",
        "            token_count = limiter3.get_token_count(*params)\n",
        "            results3.append(token_count)\n",
        "        elif method == \"generate_text\":\n",
        "            if decorator_func3:\n",
        "                decorated_func3 = decorator_func3(generate_text)\n",
        "                result = decorated_func3(*params)\n",
        "                results3.append(result)\n",
        "\n",
        "    for i, result in enumerate(results3):\n",
        "        print(f\"  {i+1}: {result}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    example_results = run_examples()\n",
        "    print(\"Example Results:\")\n",
        "    for i, result in enumerate(example_results):\n",
        "        print(f\"  {i+1}: {result}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "    # Test all examples\n",
        "    run_all_examples()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KUlcq7ycbHYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "391fc602-bf41-4567-c12d-bb9a9078991c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'main'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-975905666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'main'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# tests\n",
        "\n",
        "\"\"\"Comprehensive tests for AIRateLimiter in a single TestCase class.\"\"\"\n",
        "import unittest\n",
        "from unittest.mock import patch\n",
        "from main import AIRateLimiter\n",
        "\n",
        "\n",
        "class _FakeClock:\n",
        "    def __init__(self, start: int = 0) -> None:\n",
        "        self._now = start\n",
        "\n",
        "    def time(self) -> int:\n",
        "        return self._now\n",
        "\n",
        "    def tick(self, seconds: int = 1) -> None:\n",
        "        self._now += seconds\n",
        "\n",
        "\n",
        "class TestAIRateLimiter(unittest.TestCase):\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        cls.clock = _FakeClock()\n",
        "        cls._patcher = patch(\"time.time\", cls.clock.time)\n",
        "        cls._patcher.start()\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls):\n",
        "        cls._patcher.stop()\n",
        "\n",
        "    # Helper fabricators\n",
        "    def _request_limiter(self):\n",
        "        cfg = {\n",
        "            \"free\": {\"limits\": [2, 5, 10], \"priority\": 1},\n",
        "            \"enterprise\": {\"limits\": [2, 5, 10], \"priority\": 3},\n",
        "        }\n",
        "        win = [1, 60, 86400]\n",
        "        return main.AIRateLimiter(cfg, win, {}, \"request\").create_limiter()\n",
        "\n",
        "    def _token_limiter(self):\n",
        "        cfg = {\"pro\": {\"token_limits\": [5, 50, 100], \"priority\": 2}}\n",
        "        win = [1, 60, 86400]\n",
        "        costs = {\"text_gen\": 2}\n",
        "        rl = main.AIRateLimiter(cfg, win, costs, \"token\")\n",
        "        return rl.create_limiter(), rl\n",
        "\n",
        "    # Request-based tests\n",
        "    def test_request_success_counts(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        r = api(\"u1\", \"free\", \"op\", \"x\")\n",
        "        self.assertEqual(r[\"rate_limit_info\"][\"requests_consumed\"], 1)\n",
        "        self.assertEqual(r[\"rate_limit_info\"][\"remaining_requests\"][0], 1)\n",
        "\n",
        "    def test_request_window_exhaustion_queue(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        api(\"u2\", \"free\", \"op\", \"a\")\n",
        "        api(\"u2\", \"free\", \"op\", \"b\")\n",
        "        q = api(\"u2\", \"free\", \"op\", \"c\")\n",
        "        self.assertEqual(q[\"status\"], \"queued\")\n",
        "\n",
        "    def test_request_reset_after_window(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        api(\"u3\", \"free\", \"op\", \"a\")\n",
        "        api(\"u3\", \"free\", \"op\", \"b\")\n",
        "        self.clock.tick(1)\n",
        "        r = api(\"u3\", \"free\", \"op\", \"c\")\n",
        "        self.assertIn(\"rate_limit_info\", r)\n",
        "\n",
        "    # Token-based tests\n",
        "    def test_token_success_counts(self):\n",
        "        deco, _ = self._token_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        r = api(\"u4\", \"pro\", \"text_gen\", \"one two\")\n",
        "        self.assertEqual(r[\"tokens_consumed\"], 4)\n",
        "        self.assertEqual(r[\"remaining_tokens\"][0], 1)\n",
        "\n",
        "    def test_token_empty_content_minimum(self):\n",
        "        deco, rl = self._token_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        self.assertEqual(rl.get_token_count(\"\"), 1)\n",
        "        r = api(\"u5\", \"pro\", \"text_gen\", \"\")\n",
        "        self.assertEqual(r[\"tokens_consumed\"], 2)  # 1 token × cost 2\n",
        "\n",
        "    def test_token_queue_on_exceed(self):\n",
        "        deco, _ = self._token_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        api(\"u6\", \"pro\", \"text_gen\", \"one two\")\n",
        "        q = api(\"u6\", \"pro\", \"text_gen\", \"one two three\")\n",
        "        self.assertEqual(q[\"status\"], \"queued\")\n",
        "\n",
        "    # Priority and FIFO tests\n",
        "    def test_priority_enterprise_ahead_of_free(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        api(\"f1\", \"free\", \"op\", \"x\")\n",
        "        api(\"f2\", \"free\", \"op\", \"y\")\n",
        "        q_free = api(\"f3\", \"free\", \"op\", \"z\")\n",
        "        q_ent = api(\"e1\", \"enterprise\", \"op\", \"z\")\n",
        "        self.assertLess(q_ent[\"queue_position\"], q_free[\"queue_position\"])\n",
        "\n",
        "    def test_fifo_within_same_priority(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        api(\"f4\", \"free\", \"op\", \"x\")\n",
        "        api(\"f5\", \"free\", \"op\", \"y\")\n",
        "        q1 = api(\"f6\", \"free\", \"op\", \"z\")\n",
        "        q2 = api(\"f7\", \"free\", \"op\", \"z\")\n",
        "        self.assertLess(q1[\"queue_position\"], q2[\"queue_position\"])\n",
        "\n",
        "    # Helper method accuracy\n",
        "    def test_helper_token_count_accuracy(self):\n",
        "        _, rl = self._token_limiter()\n",
        "        self.assertEqual(rl.get_token_count(\"one two three\"), 3)\n",
        "\n",
        "    def test_helper_token_count_empty(self):\n",
        "        _, rl = self._token_limiter()\n",
        "        self.assertEqual(rl.get_token_count(\"\"), 1)\n",
        "\n",
        "    # New user state\n",
        "    def test_new_user_full_allocation(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        r = api(\"newbie\", \"free\", \"op\", \"hi\")\n",
        "        self.assertEqual(r[\"rate_limit_info\"][\"remaining_requests\"][0], 1)\n",
        "\n",
        "    # Long window reset\n",
        "    def test_daily_window_reset(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        api(\"u7\", \"free\", \"op\", \"a\")\n",
        "        self.clock.tick(86400)\n",
        "        r = api(\"u7\", \"free\", \"op\", \"b\")\n",
        "        self.assertEqual(r[\"rate_limit_info\"][\"remaining_requests\"][2], 9)\n",
        "\n",
        "    # Multi-user isolation\n",
        "    def test_multi_user_isolated_state(self):\n",
        "        deco = self._request_limiter()\n",
        "\n",
        "        @deco\n",
        "        def api(u, t, o, c):\n",
        "            return c\n",
        "\n",
        "        r1 = api(\"userA\", \"free\", \"op\", \"x\")\n",
        "        r2 = api(\"userB\", \"free\", \"op\", \"x\")\n",
        "        self.assertEqual(r1[\"rate_limit_info\"][\"remaining_requests\"][0], 1)\n",
        "        self.assertEqual(r2[\"rate_limit_info\"][\"remaining_requests\"][0], 1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: <https://rlhf-v3.turing.com/prompt/b8ad475f-17f2-42bb-9adf-c79be63d9a89?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F66273%2Fview>\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "# code generated by the model\n",
        "\n",
        "import time\n",
        "from collections import deque, defaultdict\n",
        "\n",
        "class AIRateLimiter:\n",
        "    def __init__(self, tier_configs: dict, time_windows: list, operation_costs: dict, limiter_type: str):\n",
        "        \"\"\"\n",
        "        tier_configs: ex) {\n",
        "            'free': {'limits': [5, 100, 1000], 'priority': 1},\n",
        "            'pro': {'limits': [20, 300, 3000], 'priority': 2},\n",
        "            'enterprise': {'limits': [100, 2000, 10000], 'priority': 3},\n",
        "            ...\n",
        "        }\n",
        "        or for token-based:\n",
        "            'pro': {'token_limits': [5, 50], 'priority': 2}, ...\n",
        "        \n",
        "        time_windows: list of time window sizes in seconds (e.g., [1, 60, 86400] for second, minute, day)\n",
        "        operation_costs: dict mapping operation -> token cost (for token-based mode)\n",
        "        limiter_type: \"request\" or \"token\"\n",
        "        \"\"\"\n",
        "        # <Issue>: Missing validation of positive integer constraints for configuration values\n",
        "        self.tier_configs = tier_configs\n",
        "        self.time_windows = time_windows  # e.g. [1, 60, 86400]\n",
        "        self.operation_costs = operation_costs  # e.g. {\"text_gen\": 2}\n",
        "        self.limiter_type = limiter_type  # \"token\" or \"request\"\n",
        "\n",
        "        # usage stores rolling usage for each user & tier & window index\n",
        "        # usage[(user_id, tier, i)] = {\"count\": <count_in_current_window>, \"start_time\": <epoch>}\n",
        "        self.usage = {}\n",
        "\n",
        "        # A global queue for requests that exceed rate limits.\n",
        "        # In a real system, you might process this queue asynchronously.\n",
        "        # For simplicity, we store them, and return \"queued\" responses.\n",
        "        self.request_queue = deque()\n",
        "\n",
        "        # This will track a global incremental ID for queued requests.\n",
        "        # In a real system, you might want more robust queue management.\n",
        "        # <Issue>: Global counter doesn't provide correct per-user queue positions\n",
        "        self.queue_counter = 0\n",
        "\n",
        "    def get_token_count(self, content: str) -> int:\n",
        "        \"\"\"\n",
        "        Tokenization method - split content and return token count.\n",
        "        Content with zero tokens defaults to 1 token consumption.\n",
        "        \"\"\"\n",
        "        tokens = content.split()\n",
        "        count = len(tokens)\n",
        "        return count if count > 0 else 1\n",
        "\n",
        "    def _check_and_consume_tokens(self, user_id: str, tier: str, operation: str, content: str):\n",
        "        \"\"\"\n",
        "        Internal helper: checks token usage against the user's tier token limits.\n",
        "        Returns (proceed: bool, data: dict).\n",
        "           If proceed == True, data contains rate limit metadata.\n",
        "           If proceed == False, data contains queue or reject info.\n",
        "        \"\"\"\n",
        "        now = time.time()\n",
        "        tier_conf = self.tier_configs.get(tier)\n",
        "        if not tier_conf or \"token_limits\" not in tier_conf:\n",
        "            return (False, {\"status\": \"error\", \"message\": f\"No token limits for tier '{tier}'\"})\n",
        "\n",
        "        token_limits = tier_conf[\"token_limits\"]  # e.g. [5, 50, 500]\n",
        "        priority = tier_conf.get(\"priority\", 1)\n",
        "\n",
        "        # Calculate how many tokens are required for this request\n",
        "        token_count = self.get_token_count(content)\n",
        "        operation_cost = self.operation_costs.get(operation, 1)\n",
        "        tokens_needed = token_count * operation_cost\n",
        "\n",
        "        # Check usage in each time window\n",
        "        for i, window_size in enumerate(self.time_windows):\n",
        "            limit = token_limits[i]\n",
        "            usage_key = (user_id, tier, i)\n",
        "            usage_data = self.usage.get(usage_key, {\"count\": 0, \"start_time\": now})\n",
        "\n",
        "            # Reset window if the time has elapsed\n",
        "            if (now - usage_data[\"start_time\"]) >= window_size:\n",
        "                usage_data[\"count\"] = 0\n",
        "                usage_data[\"start_time\"] = now\n",
        "\n",
        "            # If adding tokens_needed exceeds the limit, queue or reject\n",
        "            if usage_data[\"count\"] + tokens_needed > limit:\n",
        "                # Queue the request\n",
        "                # <Issue>: Queue counter incremented before assignment, causing incorrect position numbering\n",
        "           \n",
        "                self.queue_counter += 1\n",
        "                queue_pos = self.queue_counter\n",
        "                queued_info = {\n",
        "                    \"status\": \"queued\",\n",
        "                    \"queue_position\": queue_pos,\n",
        "                    \"estimated_wait_time\": 1,  # simplistic wait estimate\n",
        "                    \"priority_level\": priority\n",
        "                }\n",
        "                return (False, queued_info)\n",
        "\n",
        "        # If we can proceed, update usage across all windows\n",
        "        for i, window_size in enumerate(self.time_windows):\n",
        "            usage_key = (user_id, tier, i)\n",
        "            usage_data = self.usage.get(usage_key, {\"count\": 0, \"start_time\": now})\n",
        "            if (now - usage_data[\"start_time\"]) >= window_size:\n",
        "                usage_data[\"count\"] = 0\n",
        "                usage_data[\"start_time\"] = now\n",
        "            usage_data[\"count\"] += tokens_needed\n",
        "            self.usage[usage_key] = usage_data\n",
        "\n",
        "        # Build metadata about consumed tokens and remaining for each window\n",
        "        remaining_tokens = []\n",
        "        for i, limit in enumerate(token_limits):\n",
        "            usage_key = (user_id, tier, i)\n",
        "            usage_data = self.usage[usage_key]\n",
        "            used = usage_data[\"count\"]\n",
        "            remain = limit - used\n",
        "            remaining_tokens.append(remain)\n",
        "\n",
        "        rate_limit_info = {\n",
        "            \"tokens_consumed\": tokens_needed,\n",
        "            \"remaining_tokens\": remaining_tokens\n",
        "        }\n",
        "        return (True, rate_limit_info)\n",
        "\n",
        "    def _check_and_consume_requests(self, user_id: str, tier: str):\n",
        "        \"\"\"\n",
        "        Internal helper: checks request usage against the user's tier request limits.\n",
        "        Returns (proceed: bool, data: dict).\n",
        "        \"\"\"\n",
        "        now = time.time()\n",
        "        tier_conf = self.tier_configs.get(tier)\n",
        "        if not tier_conf or \"limits\" not in tier_conf:\n",
        "            return (False, {\"status\": \"error\", \"message\": f\"No request limits for tier '{tier}'\"})\n",
        "\n",
        "        request_limits = tier_conf[\"limits\"]  # e.g. [2, 10, 100]\n",
        "        priority = tier_conf.get(\"priority\", 1)\n",
        "\n",
        "        # Each request consumes 1 usage\n",
        "        for i, window_size in enumerate(self.time_windows):\n",
        "            limit = request_limits[i]\n",
        "            usage_key = (user_id, tier, i)\n",
        "            usage_data = self.usage.get(usage_key, {\"count\": 0, \"start_time\": now})\n",
        "\n",
        "            # Reset window if the time has elapsed\n",
        "            if (now - usage_data[\"start_time\"]) >= window_size:\n",
        "                usage_data[\"count\"] = 0\n",
        "                usage_data[\"start_time\"] = now\n",
        "\n",
        "            # Check if adding 1 usage would exceed the limit\n",
        "            if usage_data[\"count\"] + 1 > limit:\n",
        "                self.queue_counter += 1\n",
        "                queue_pos = self.queue_counter\n",
        "                queued_info = {\n",
        "                    \"status\": \"queued\",\n",
        "                    \"queue_position\": queue_pos,\n",
        "                    \"estimated_wait_time\": 1,  # simplistic wait estimate\n",
        "                    \"priority_level\": priority\n",
        "                }\n",
        "                return (False, queued_info)\n",
        "\n",
        "        # If we can proceed, update usage\n",
        "        for i, window_size in enumerate(self.time_windows):\n",
        "            usage_key = (user_id, tier, i)\n",
        "            usage_data = self.usage.get(usage_key, {\"count\": 0, \"start_time\": now})\n",
        "            if (now - usage_data[\"start_time\"]) >= window_size:\n",
        "                usage_data[\"count\"] = 0\n",
        "                usage_data[\"start_time\"] = now\n",
        "            usage_data[\"count\"] += 1\n",
        "            self.usage[usage_key] = usage_data\n",
        "\n",
        "        # Build rate limit metadata\n",
        "        remaining_requests = []\n",
        "        for i, limit in enumerate(request_limits):\n",
        "            usage_key = (user_id, tier, i)\n",
        "            usage_data = self.usage[usage_key]\n",
        "            used = usage_data[\"count\"]\n",
        "            remain = limit - used\n",
        "            remaining_requests.append(remain)\n",
        "\n",
        "        rate_limit_info = {\n",
        "            \"requests_consumed\": 1,\n",
        "            \"remaining_requests\": remaining_requests\n",
        "        }\n",
        "        return (True, rate_limit_info)\n",
        "\n",
        "    def create_limiter(self):\n",
        "        \"\"\"\n",
        "        Factory method that returns a decorator enforcing either token-based or request-based\n",
        "        rate limiting, depending on the initialized limiter_type.\n",
        "        \"\"\"\n",
        "        if self.limiter_type == \"token\":\n",
        "            def token_decorator(func):\n",
        "                def wrapper(user_id, tier, operation, content, *args, **kwargs):\n",
        "                    can_proceed, info = self._check_and_consume_tokens(user_id, tier, operation, content)\n",
        "                    if can_proceed:\n",
        "                        # Proceed with the original function call\n",
        "                        result = func(user_id, tier, operation, content, *args, **kwargs)\n",
        "                        return {\n",
        "                            \"result\": result,\n",
        "                            \"rate_limit_info\": info\n",
        "                        }\n",
        "                    else:\n",
        "                        # Return the queue or error info\n",
        "                        return info\n",
        "                return wrapper\n",
        "            return token_decorator\n",
        "\n",
        "        elif self.limiter_type == \"request\":\n",
        "            def request_decorator(func):\n",
        "                def wrapper(user_id, tier, operation, content, *args, **kwargs):\n",
        "                    can_proceed, info = self._check_and_consume_requests(user_id, tier)\n",
        "                    if can_proceed:\n",
        "                        result = func(user_id, tier, operation, content, *args, **kwargs)\n",
        "                        return {\n",
        "                            \"result\": result,\n",
        "                            \"rate_limit_info\": info\n",
        "                        }\n",
        "                    else:\n",
        "                        return info\n",
        "                return wrapper\n",
        "            return request_decorator\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid limiter type. Must be 'token' or 'request'.\")\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Below is an optional helper to demonstrate how one might process inputs and\n",
        "# produce outputs in the format described in the problem statement.\n",
        "###############################################################################\n",
        "\n",
        "def simulate_api_calls(methods, parameters):\n",
        "    \"\"\"\n",
        "    Demonstrates how to handle the Input/Output format described in the prompt.\n",
        "\n",
        "    methods: list of method names, e.g. [\"AIRateLimiter\", \"create_limiter\", \"generate_text\", ...]\n",
        "    parameters: list of parameter lists, one for each method call.\n",
        "    \n",
        "    Returns a list of results parallel to the method calls:\n",
        "      - Constructor or void methods return None to match \"null\" in the output\n",
        "      - Decorator creation returns a placeholder string (e.g., \"decorator_function\")\n",
        "      - Actual API calls return either success or queue info as specified\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    instance = None\n",
        "    decorator = None\n",
        "\n",
        "    # We'll create a dummy function to illustrate usage:\n",
        "    def generate_text(user_id, tier, operation, content, *args, **kwargs):\n",
        "        # Just echo the content as if we \"generated\" it\n",
        "        return content\n",
        "\n",
        "    for method, args in zip(methods, parameters):\n",
        "        if method == \"AIRateLimiter\":\n",
        "            # Instantiate the rate limiter\n",
        "            # args[0] = tier_configs, args[1] = time_windows, args[2] = operation_costs, args[3] = limiter_type\n",
        "            tier_configs, time_windows, operation_costs, limiter_type = args\n",
        "            instance = AIRateLimiter(tier_configs, time_windows, operation_costs, limiter_type)\n",
        "            results.append(None)  # constructor returns null\n",
        "        elif method == \"create_limiter\":\n",
        "            # Must have an instance\n",
        "            if not instance:\n",
        "                results.append({\"error\": \"No AIRateLimiter instance exists\"})\n",
        "                continue\n",
        "            decorator = instance.create_limiter()\n",
        "            # Return a placeholder to mimic the example (decorator functions can't easily be serialized)\n",
        "            results.append(\"decorator_function\")\n",
        "        elif method == \"get_token_count\":\n",
        "            # Simple pass-through\n",
        "            if not instance:\n",
        "                results.append({\"error\": \"No AIRateLimiter instance exists\"})\n",
        "                continue\n",
        "            content = args[0]\n",
        "            count = instance.get_token_count(content)\n",
        "            results.append(count)\n",
        "        else:\n",
        "            # Any other method is presumably an API call like \"generate_text\"\n",
        "            if not decorator:\n",
        "                results.append({\"error\": f\"No decorator created before calling {method}\"})\n",
        "                continue\n",
        "            # Wrap the dummy function with the chosen decorator\n",
        "            wrapped_func = decorator(generate_text)\n",
        "            # Call the wrapped function with the provided arguments\n",
        "            outputs = wrapped_func(*args)\n",
        "            results.append(outputs)\n",
        "\n",
        "    return results\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}