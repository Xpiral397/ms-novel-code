{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Software Architecture & Design\n",
        "\n",
        "**L2 Taxonomy** - Event-Driven Architecture\n",
        "\n",
        "**Subtopic** - Implementing a Simple Event-Driven System\n",
        "\n",
        "**Use Case** - Develop a simple event-driven system in Python. This system should consist of an event dispatcher and multiple event handlers. The event dispatcher will generate random events and the event handlers will process these events. All events and their handlers should be defined within the system. Use the Python standard library for the implementation.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "\n",
        "Design an event processing pipeline for a message routing system. The system routes messages through different processors based on message types and processing rules. Each message must go through specific validation, transformation, and delivery stages while maintaining order and dependencies.\n",
        "\n",
        "## Input Format\n",
        "\n",
        "- A list of dictionaries representing messages:\n",
        "\n",
        "```\n",
        "[{\n",
        "    \"id\": str,           # Unique message identifier\n",
        "    \"type\": str,         # One of: \"DATA\", \"CONTROL\", \"STATUS\"\n",
        "    \"payload\": dict,     # Message content and metadata\n",
        "    \"dependencies\": list # List of message IDs that must be processed first\n",
        "}]\n",
        "```\n",
        "\n",
        "## Output Format\n",
        "\n",
        "- A list of dictionaries representing processed results:\n",
        "\n",
        "```\n",
        "[{\n",
        "    \"id\": str,          # Original message ID\n",
        "    \"status\": str,      # \"SUCCESS\", \"FAILED\", or \"SKIPPED\"\n",
        "    \"processors\": list, # List of processor IDs that handled the message\n",
        "    \"result\": dict     # Final transformed payload\n",
        "}]\n",
        "```\n",
        "\n",
        "## Examples\n",
        "\n",
        "Input:\n",
        "\n",
        "```\n",
        "messages = [\n",
        "    {\n",
        "        \"id\": \"msg1\",\n",
        "        \"type\": \"DATA\",\n",
        "        \"payload\": {\"content\": \"hello\", \"checksum\": \"abc123\"},\n",
        "        \"dependencies\": []\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"msg2\",\n",
        "        \"type\": \"CONTROL\",\n",
        "        \"payload\": {\"command\": \"validate\", \"target\": \"msg1\"},\n",
        "        \"dependencies\": [\"msg1\"]\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "[\n",
        "    {\n",
        "        \"id\": \"msg1\",\n",
        "        \"status\": \"SUCCESS\",\n",
        "        \"processors\": [\"validate_p1\", \"transform_p1\", \"route_p1\"],\n",
        "        \"result\": {\"content\": \"HELLO\", \"validated\": True}\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"msg2\",\n",
        "        \"status\": \"SUCCESS\",\n",
        "        \"processors\": [\"control_p1\", \"route_p2\"],\n",
        "        \"result\": {\"command_status\": \"completed\"}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "## Explicit Requirements\n",
        "\n",
        "1. Messages must be processed only after their dependencies\n",
        "2. Each message type requires specific processor chain\n",
        "3. All processors must validate input before processing\n",
        "4. Failed processor should stop the chain for that message\n",
        "5. System must maintain processing order for dependent messages\n",
        "6. Must use event-driven approach.\n",
        "\n",
        "## Implicit Requirements\n",
        "\n",
        "1. Message IDs must be unique\n",
        "2. Circular dependencies must be detected and rejected\n",
        "3. Unknown message types must be marked as SKIPPED\n",
        "4. Processors must not modify original input\n",
        "5. System must track all processors that touched a message\n",
        "\n",
        "## Function Signature\n",
        "\n",
        "```python\n",
        "def process_message_pipeline(messages: List[Dict]) -> List[Dict]\n",
        "```\n",
        "\n",
        "## Edge Cases\n",
        "\n",
        "1. Skip processing if message references non-existent dependency\n",
        "2. Mark as FAILED if message payload is missing required fields\n",
        "3. Return empty list for empty input\n",
        "4. Skip duplicate message IDs and keep first occurrence\n",
        "5. Mark messages with circular dependencies as FAILED\n",
        "\n",
        "## Constraints\n",
        "\n",
        "1. Maximum 100 messages in input list\n",
        "2. Message IDs must be alphanumeric and max 32 characters\n",
        "3. Maximum 10 dependencies per message\n",
        "4. Payload dictionary maximum depth of 3 levels\n",
        "5. Processor chain maximum length of 5 processors\n",
        "6. The solution should be contained in single file and must have driver function.\n",
        "7. Implementation code must run on an online python compiler and must be testable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "\"\"\"Message processing pipeline using event-driven architecture.\"\"\"\n",
        "\n",
        "from typing import List, Dict, Set, Optional\n",
        "from abc import ABC, abstractmethod\n",
        "import re\n",
        "import copy\n",
        "\n",
        "\n",
        "class EventDispatcher:\n",
        "    \"\"\"Handles event subscriptions and notifies processors.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes event dispatcher with observer dictionary.\"\"\"\n",
        "        self._observers = {}\n",
        "\n",
        "    def subscribe(self, event_type: str, observer: 'MessageProcessor'):\n",
        "        \"\"\"Registers a processor for a specific event type.\"\"\"\n",
        "        if event_type not in self._observers:\n",
        "            self._observers[event_type] = []\n",
        "        self._observers[event_type].append(observer)\n",
        "\n",
        "    def notify(self, event_type: str, message: Dict) -> (List[str], Dict):\n",
        "        \"\"\"Notifies processors subscribed to an event type.\"\"\"\n",
        "        if event_type not in self._observers:\n",
        "            return [], message[\"payload\"]\n",
        "        processor_ids = []\n",
        "        payload_copy = copy.deepcopy(message[\"payload\"])\n",
        "        for observer in self._observers[event_type]:\n",
        "            result, payload_copy = observer.process(message, payload_copy)\n",
        "            if result:\n",
        "                processor_ids.append(observer.processor_id)\n",
        "            else:\n",
        "                break\n",
        "        return processor_ids, payload_copy\n",
        "\n",
        "\n",
        "class MessageProcessor(ABC):\n",
        "    \"\"\"Abstract base class for all message processors.\"\"\"\n",
        "\n",
        "    def __init__(self, processor_id: str):\n",
        "        \"\"\"Initializes processor with processor ID.\"\"\"\n",
        "        self.processor_id = processor_id\n",
        "\n",
        "    @abstractmethod\n",
        "    def validate(self, message: Dict, payload: Dict) -> bool:\n",
        "        \"\"\"Validates incoming message and payload.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def process(self, message: Dict, payload: Dict) -> (bool, Dict):\n",
        "        \"\"\"Processes and optionally modifies payload.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class RoutingProcessor(MessageProcessor):\n",
        "    \"\"\"Routes messages without changing them.\"\"\"\n",
        "\n",
        "    def validate(self, message: Dict, payload: Dict) -> bool:\n",
        "        \"\"\"Validates message for routing.\"\"\"\n",
        "        return True\n",
        "\n",
        "    def process(self, message: Dict, payload: Dict) -> (bool, Dict):\n",
        "        \"\"\"Returns the payload.\"\"\"\n",
        "        return True, payload\n",
        "\n",
        "\n",
        "class ValidationProcessor(MessageProcessor):\n",
        "    \"\"\"Validates required fields in the payload.\"\"\"\n",
        "\n",
        "    def validate(self, message: Dict, payload: Dict) -> bool:\n",
        "        \"\"\"Checks if required fields exist in payload.\"\"\"\n",
        "        required_fields = {\"content\", \"checksum\"}\n",
        "        return all(field in payload for field in required_fields)\n",
        "\n",
        "    def process(self, message: Dict, payload: Dict) -> (bool, Dict):\n",
        "        \"\"\"Marks payload as validated if valid.\"\"\"\n",
        "        if not self.validate(message, payload):\n",
        "            return False, payload\n",
        "        payload = payload.copy()\n",
        "        payload[\"validated\"] = True\n",
        "        return True, payload\n",
        "\n",
        "\n",
        "class TransformProcessor(MessageProcessor):\n",
        "    \"\"\"Transforms message content to uppercase.\"\"\"\n",
        "\n",
        "    def validate(self, message: Dict, payload: Dict) -> bool:\n",
        "        \"\"\"Checks if content is a string.\"\"\"\n",
        "        return isinstance(payload.get(\"content\"), str)\n",
        "\n",
        "    def process(self, message: Dict, payload: Dict) -> (bool, Dict):\n",
        "        \"\"\"Converts content to uppercase.\"\"\"\n",
        "        if not self.validate(message, payload):\n",
        "            return False, payload\n",
        "        payload = payload.copy()\n",
        "        payload[\"content\"] = payload[\"content\"].upper()\n",
        "        return True, payload\n",
        "\n",
        "\n",
        "class ControlProcessor(MessageProcessor):\n",
        "    \"\"\"Processes control messages with commands.\"\"\"\n",
        "\n",
        "    def validate(self, message: Dict, payload: Dict) -> bool:\n",
        "        \"\"\"Checks for command and target in payload.\"\"\"\n",
        "        return all(k in payload for k in [\"command\", \"target\"])\n",
        "\n",
        "    def process(self, message: Dict, payload: Dict) -> (bool, Dict):\n",
        "        \"\"\"Returns command status if valid.\"\"\"\n",
        "        if not self.validate(message, payload):\n",
        "            return False, payload\n",
        "        return True, {\"command_status\": \"completed\"}\n",
        "\n",
        "\n",
        "class StatusProcessor(MessageProcessor):\n",
        "    \"\"\"Echoes status message payload.\"\"\"\n",
        "\n",
        "    def validate(self, message: Dict, payload: Dict) -> bool:\n",
        "        \"\"\"Checks if status message is valid.\"\"\"\n",
        "        return True\n",
        "\n",
        "    def process(self, message: Dict, payload: Dict) -> (bool, Dict):\n",
        "        \"\"\"Returns a copy of the payload.\"\"\"\n",
        "        return True, payload.copy()\n",
        "\n",
        "\n",
        "class MessageRouter:\n",
        "    \"\"\"Handles validation, routing, and processing of messages.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes dispatcher, processors, and tracking fields.\"\"\"\n",
        "        self.dispatcher = EventDispatcher()\n",
        "        self._setup_processors()\n",
        "        self.processed_msgs: Set[str] = set()\n",
        "        self.results: Dict[str, Dict] = {}\n",
        "\n",
        "    def _setup_processors(self):\n",
        "        \"\"\"Subscribes processors to event types.\"\"\"\n",
        "        d = self.dispatcher\n",
        "        d.subscribe(\"DATA\", ValidationProcessor(\"validate_p1\"))\n",
        "        d.subscribe(\"DATA\", TransformProcessor(\"transform_p1\"))\n",
        "        d.subscribe(\"DATA\", RoutingProcessor(\"route_p1\"))\n",
        "        d.subscribe(\"CONTROL\", ControlProcessor(\"control_p1\"))\n",
        "        d.subscribe(\"CONTROL\", RoutingProcessor(\"route_p2\"))\n",
        "        d.subscribe(\"STATUS\", StatusProcessor(\"status_p1\"))\n",
        "\n",
        "    def _validate_message(self, message: Dict, all_ids: Set[str]) -> Optional[str]:\n",
        "        \"\"\"Validates structure, ID, dependencies, and payload.\"\"\"\n",
        "        if not isinstance(message.get(\"id\"), str):\n",
        "            return \"Invalid message ID\"\n",
        "        if not re.match(\"^[a-zA-Z0-9]{1,32}$\", message[\"id\"]):\n",
        "            return \"Invalid message ID format\"\n",
        "        if message[\"id\"] in self.processed_msgs:\n",
        "            return \"Duplicate message ID\"\n",
        "        if not isinstance(message.get(\"dependencies\"), list):\n",
        "            return \"Invalid dependencies format\"\n",
        "        if len(message[\"dependencies\"]) > 10:\n",
        "            return \"Too many dependencies\"\n",
        "        for dep in message[\"dependencies\"]:\n",
        "            if dep not in all_ids:\n",
        "                return \"Non-existent dependency\"\n",
        "\n",
        "        def dict_depth(d, level=1):\n",
        "            \"\"\"Computes dictionary depth.\"\"\"\n",
        "            if not isinstance(d, dict) or not d:\n",
        "                return level\n",
        "            return max(\n",
        "                dict_depth(v, level + 1) if isinstance(v, dict)\n",
        "                else level + 1 for v in d.values()\n",
        "            )\n",
        "\n",
        "        if dict_depth(message.get(\"payload\", {})) > 3:\n",
        "            return \"Payload too deep\"\n",
        "        return None\n",
        "\n",
        "    def _has_circular_dependency(\n",
        "        self, msg_id: str, deps: Set[str], visited: Set[str]\n",
        "    ) -> bool:\n",
        "        \"\"\"Detects cycles in message dependencies.\"\"\"\n",
        "        if msg_id in visited:\n",
        "            return True\n",
        "        visited.add(msg_id)\n",
        "        for dep_id in deps:\n",
        "            if dep_id in self.results:\n",
        "                dep_msg = self.results[dep_id]\n",
        "                if self._has_circular_dependency(\n",
        "                    dep_id, set(dep_msg[\"dependencies\"]), visited\n",
        "                ):\n",
        "                    return True\n",
        "        visited.remove(msg_id)\n",
        "        return False\n",
        "\n",
        "    def _can_process_message(self, message: Dict) -> bool:\n",
        "        \"\"\"Checks if dependencies are already processed.\"\"\"\n",
        "        return all(\n",
        "            dep in self.processed_msgs for dep in message[\"dependencies\"]\n",
        "        )\n",
        "\n",
        "    def _create_result(\n",
        "        self,\n",
        "        msg_id: str,\n",
        "        status: str,\n",
        "        processors: List[str] = None,\n",
        "        result: Dict = None,\n",
        "    ) -> Dict:\n",
        "        \"\"\"Constructs a result dictionary.\"\"\"\n",
        "        return {\n",
        "            \"id\": msg_id,\n",
        "            \"status\": status,\n",
        "            \"processors\": processors or [],\n",
        "            \"result\": result or {},\n",
        "        }\n",
        "\n",
        "    def process_messages(self, messages: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Processes messages via validation and dispatch.\"\"\"\n",
        "        if not messages or len(messages) > 100:\n",
        "            return []\n",
        "        seen = set()\n",
        "        filtered = []\n",
        "        for msg in messages:\n",
        "            if msg[\"id\"] not in seen:\n",
        "                filtered.append(msg)\n",
        "                seen.add(msg[\"id\"])\n",
        "        messages = filtered\n",
        "        all_ids = set(msg[\"id\"] for msg in messages)\n",
        "        msg_status = {msg[\"id\"]: None for msg in messages}\n",
        "        msg_result = {msg[\"id\"]: None for msg in messages}\n",
        "        msg_processors = {msg[\"id\"]: [] for msg in messages}\n",
        "        msg_map = {msg[\"id\"]: msg for msg in messages}\n",
        "        processed = set()\n",
        "        results = []\n",
        "        pending = set(msg[\"id\"] for msg in messages)\n",
        "        while pending:\n",
        "            progress = False\n",
        "            to_remove = set()\n",
        "            for mid in list(pending):\n",
        "                msg = msg_map[mid]\n",
        "                error = self._validate_message(msg, all_ids)\n",
        "                if error == \"Duplicate message ID\":\n",
        "                    to_remove.add(mid)\n",
        "                    continue\n",
        "                if error == \"Non-existent dependency\":\n",
        "                    msg_status[mid] = \"SKIPPED\"\n",
        "                    to_remove.add(mid)\n",
        "                    continue\n",
        "                if error:\n",
        "                    msg_status[mid] = \"FAILED\"\n",
        "                    to_remove.add(mid)\n",
        "                    continue\n",
        "                if self._has_circular_dependency(\n",
        "                    mid, set(msg[\"dependencies\"]), set()\n",
        "                ):\n",
        "                    msg_status[mid] = \"FAILED\"\n",
        "                    to_remove.add(mid)\n",
        "                    continue\n",
        "                dep_statuses = [\n",
        "                    msg_status.get(dep) for dep in msg[\"dependencies\"]\n",
        "                ]\n",
        "                if any(s is None for s in dep_statuses):\n",
        "                    continue\n",
        "                if any(s in (\"FAILED\", \"SKIPPED\") for s in dep_statuses):\n",
        "                    msg_status[mid] = \"SKIPPED\"\n",
        "                    to_remove.add(mid)\n",
        "                    continue\n",
        "                if msg[\"type\"] not in [\"DATA\", \"CONTROL\", \"STATUS\"]:\n",
        "                    msg_status[mid] = \"SKIPPED\"\n",
        "                    to_remove.add(mid)\n",
        "                    continue\n",
        "                processor_ids = []\n",
        "                payload_copy = copy.deepcopy(msg[\"payload\"])\n",
        "                success = True\n",
        "                failed_at = None\n",
        "                for observer in self.dispatcher._observers[msg[\"type\"]]:\n",
        "                    result, payload_copy_new = observer.process(\n",
        "                        msg, payload_copy\n",
        "                    )\n",
        "                    processor_ids.append(observer.processor_id)\n",
        "                    if not result:\n",
        "                        failed_at = len(processor_ids) - 1\n",
        "                        success = False\n",
        "                        break\n",
        "                    payload_copy = payload_copy_new\n",
        "                if not success and failed_at is not None:\n",
        "                    msg_processors[mid] = processor_ids[:failed_at + 1]\n",
        "                else:\n",
        "                    msg_processors[mid] = processor_ids if success else []\n",
        "                if success:\n",
        "                    msg_status[mid] = \"SUCCESS\"\n",
        "                    if msg[\"type\"] == \"DATA\":\n",
        "                        msg_result[mid] = {\n",
        "                            k: v for k, v in payload_copy.items()\n",
        "                            if k in [\"content\", \"validated\"]\n",
        "                        }\n",
        "                    else:\n",
        "                        msg_result[mid] = payload_copy\n",
        "                else:\n",
        "                    msg_status[mid] = \"FAILED\"\n",
        "                to_remove.add(mid)\n",
        "                progress = True\n",
        "            pending -= to_remove\n",
        "            if not progress:\n",
        "                for mid in pending:\n",
        "                    msg_status[mid] = \"FAILED\"\n",
        "                break\n",
        "        for msg in messages:\n",
        "            results.append(\n",
        "                self._create_result(\n",
        "                    msg[\"id\"],\n",
        "                    msg_status[msg[\"id\"]] or \"FAILED\",\n",
        "                    msg_processors[msg[\"id\"]],\n",
        "                    msg_result[msg[\"id\"]],\n",
        "                )\n",
        "            )\n",
        "        return results\n",
        "\n",
        "\n",
        "def process_message_pipeline(messages: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"Processes messages using router pipeline.\"\"\"\n",
        "    router = MessageRouter()\n",
        "    return router.process_messages(messages)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_messages = [\n",
        "        {\n",
        "            \"id\": \"msg1\",\n",
        "            \"type\": \"DATA\",\n",
        "            \"payload\": {\"content\": \"hello\", \"checksum\": \"abc123\"},\n",
        "            \"dependencies\": [],\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"msg2\",\n",
        "            \"type\": \"CONTROL\",\n",
        "            \"payload\": {\"command\": \"validate\", \"target\": \"msg1\"},\n",
        "            \"dependencies\": [\"msg1\"],\n",
        "        },\n",
        "    ]\n",
        "    results = process_message_pipeline(test_messages)\n",
        "    for result in results:\n",
        "        print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\"\"\"Minimal unit tests for process_message_pipeline.\"\"\"\n",
        "\n",
        "import unittest\n",
        "\n",
        "from main import process_message_pipeline\n",
        "\n",
        "\n",
        "class TestProcessMessagePipeline(unittest.TestCase):\n",
        "    \"\"\"Minimal tests for process_message_pipeline.\"\"\"\n",
        "\n",
        "    def test_success_and_chain_order(self):\n",
        "        \"\"\"Success and dependency chain order.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"A\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"a\", \"checksum\": \"c\"},\n",
        "                \"dependencies\": [],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"B\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"b\", \"checksum\": \"c\"},\n",
        "                \"dependencies\": [\"A\"],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"C\",\n",
        "                \"type\": \"CONTROL\",\n",
        "                \"payload\": {\"command\": \"go\", \"target\": \"B\"},\n",
        "                \"dependencies\": [\"B\"],\n",
        "            },\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual([r[\"id\"] for r in result], [\"A\", \"B\", \"C\"])\n",
        "        self.assertTrue(all(r[\"status\"] == \"SUCCESS\" for r in result))\n",
        "        self.assertEqual(result[2][\"result\"], {\"command_status\": \"completed\"})\n",
        "\n",
        "    def test_circular_dependency(self):\n",
        "        \"\"\"Circular dependencies are FAILED.\"\"\"\n",
        "        messages = [\n",
        "            {\"id\": \"A\", \"type\": \"DATA\", \"payload\": {}, \"dependencies\": [\"B\"]},\n",
        "            {\"id\": \"B\", \"type\": \"DATA\", \"payload\": {}, \"dependencies\": [\"A\"]},\n",
        "            {\"id\": \"C\", \"type\": \"DATA\", \"payload\": {}, \"dependencies\": [\"B\"]},\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertTrue(all(r[\"status\"] == \"FAILED\" for r in result))\n",
        "\n",
        "    def test_nonexistent_dependency(self):\n",
        "        \"\"\"Missing dependency is SKIPPED.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"A2\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"abc\", \"checksum\": \"xyz\"},\n",
        "                \"dependencies\": [\"NOPE\"],\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"SKIPPED\")\n",
        "\n",
        "    def test_dependency_on_failed_message(self):\n",
        "        \"\"\"Dependency on failed message is FAILED.\"\"\"\n",
        "        messages = [\n",
        "            {\"id\": \"A\", \"type\": \"DATA\", \"payload\": {}, \"dependencies\": [\"A\"]},\n",
        "            {\n",
        "                \"id\": \"B\",\n",
        "                \"type\": \"CONTROL\",\n",
        "                \"payload\": {\"command\": \"go\", \"target\": \"A\"},\n",
        "                \"dependencies\": [\"A\"],\n",
        "            },\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        msgA = next(r for r in result if r[\"id\"] == \"A\")\n",
        "        msgB = next(r for r in result if r[\"id\"] == \"B\")\n",
        "        self.assertEqual(msgA[\"status\"], \"FAILED\")\n",
        "        self.assertEqual(msgB[\"status\"], \"FAILED\")\n",
        "\n",
        "    def test_missing_payload_field(self):\n",
        "        \"\"\"DATA missing required fields is FAILED.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"M1\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"checksum\": \"xyz\"},\n",
        "                \"dependencies\": [],\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"FAILED\")\n",
        "\n",
        "    def test_unknown_message_type(self):\n",
        "        \"\"\"Unknown type is SKIPPED.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"X1\",\n",
        "                \"type\": \"UNKNOWN\",\n",
        "                \"payload\": {},\n",
        "                \"dependencies\": []\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"SKIPPED\")\n",
        "\n",
        "    def test_duplicate_message_ids(self):\n",
        "        \"\"\"Only first duplicate ID is processed.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"DUP\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"a\", \"checksum\": \"b\"},\n",
        "                \"dependencies\": [],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"DUP\",\n",
        "                \"type\": \"CONTROL\",\n",
        "                \"payload\": {\"command\": \"c\", \"target\": \"DUP\"},\n",
        "                \"dependencies\": [\"DUP\"],\n",
        "            },\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(len(result), 1)\n",
        "        self.assertEqual(result[0][\"id\"], \"DUP\")\n",
        "        self.assertEqual(result[0][\"status\"], \"SUCCESS\")\n",
        "\n",
        "    def test_empty_input(self):\n",
        "        \"\"\"Empty input returns empty list.\"\"\"\n",
        "        self.assertEqual(process_message_pipeline([]), [])\n",
        "\n",
        "    def test_complex_valid_dag(self):\n",
        "        \"\"\"Valid DAG of dependencies is SUCCESS.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"D\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"d\", \"checksum\": \"dchk\"},\n",
        "                \"dependencies\": [\"B\", \"C\"],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"C\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"c\", \"checksum\": \"cchk\"},\n",
        "                \"dependencies\": [\"A\"],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"B\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"b\", \"checksum\": \"bchk\"},\n",
        "                \"dependencies\": [\"A\"],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"A\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"a\", \"checksum\": \"achk\"},\n",
        "                \"dependencies\": [],\n",
        "            },\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(len(result), 4)\n",
        "        self.assertTrue(all(r[\"status\"] == \"SUCCESS\" for r in result))\n",
        "\n",
        "    def test_processor_chain_stops_on_failure(self):\n",
        "        \"\"\"Processor chain stops on failure.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"M1\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {},\n",
        "                \"dependencies\": []\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"FAILED\")\n",
        "        self.assertEqual(len(result[0][\"processors\"]), 1)\n",
        "\n",
        "    def test_basic_data_message(self):\n",
        "        \"\"\"Basic DATA message is SUCCESS.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"A1\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"abc\", \"checksum\": \"xyz\"},\n",
        "                \"dependencies\": [],\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"SUCCESS\")\n",
        "        self.assertEqual(result[0][\"result\"],\n",
        "                         {\"content\": \"ABC\", \"validated\": True})\n",
        "\n",
        "    def test_control_message_with_dependency(self):\n",
        "        \"\"\"CONTROL message with dependency is SUCCESS.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"A1\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": \"abc\", \"checksum\": \"xyz\"},\n",
        "                \"dependencies\": [],\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"B1\",\n",
        "                \"type\": \"CONTROL\",\n",
        "                \"payload\": {\"command\": \"run\", \"target\": \"A1\"},\n",
        "                \"dependencies\": [\"A1\"],\n",
        "            },\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[1][\"status\"], \"SUCCESS\")\n",
        "        self.assertEqual(result[1][\"result\"], {\"command_status\": \"completed\"})\n",
        "\n",
        "    def test_status_message(self):\n",
        "        \"\"\"STATUS message is SUCCESS.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"S1\",\n",
        "                \"type\": \"STATUS\",\n",
        "                \"payload\": {\"info\": \"ok\"},\n",
        "                \"dependencies\": []\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"SUCCESS\")\n",
        "        self.assertEqual(result[0][\"result\"], {\"info\": \"ok\"})\n",
        "\n",
        "    def test_processor_chain_stops_on_failure_2(self):\n",
        "        \"\"\"Processor chain stops on non-string content.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": \"F1\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": 123, \"checksum\": \"xyz\"},\n",
        "                \"dependencies\": [],\n",
        "            }\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result[0][\"status\"], \"FAILED\")\n",
        "        self.assertEqual(len(result[0][\"processors\"]), 2)\n",
        "\n",
        "    def test_max_boundary(self):\n",
        "        \"\"\"Max boundary of 100 messages is SUCCESS.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": f\"ID{i}\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": str(i), \"checksum\": \"c\"},\n",
        "                \"dependencies\": [],\n",
        "            }\n",
        "            for i in range(100)\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(len(result), 100)\n",
        "        self.assertTrue(all(r[\"status\"] == \"SUCCESS\" for r in result))\n",
        "\n",
        "    def test_over_max_boundary(self):\n",
        "        \"\"\"Over max boundary returns empty list.\"\"\"\n",
        "        messages = [\n",
        "            {\n",
        "                \"id\": f\"ID{i}\",\n",
        "                \"type\": \"DATA\",\n",
        "                \"payload\": {\"content\": str(i), \"checksum\": \"c\"},\n",
        "                \"dependencies\": [],\n",
        "            }\n",
        "            for i in range(101)\n",
        "        ]\n",
        "        result = process_message_pipeline(messages)\n",
        "        self.assertEqual(result, [])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://labeling-ms.turing.com/conversations/73650/view\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "########################################################################\n",
        "# Event-Driven Message Processing Pipeline\n",
        "#\n",
        "# This module defines a single function `process_message_pipeline(messages)`\n",
        "# that processes a list of message dictionaries and returns a list of\n",
        "# result dictionaries. It demonstrates an event-driven architecture with\n",
        "# validation, transformation, routing, dependency management, and\n",
        "# processor chaining.\n",
        "#\n",
        "# USAGE:\n",
        "#   You can run this module as-is. It includes a simple driver function\n",
        "#   at the bottom with example input. Adjust or replace the driver code\n",
        "#   to run other tests.\n",
        "#\n",
        "#   The main entry point to use from another piece of code is:\n",
        "#       results = process_message_pipeline(messages)\n",
        "########################################################################\n",
        "\n",
        "from typing import List, Dict, Set\n",
        "\n",
        "# <Issue>: Model's implementation is not event-driven; processors are called\n",
        "# directly, not via event subscriptions/notifications\n",
        "def process_message_pipeline(messages: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Processes messages through a pipeline with validations,\n",
        "    transformations, and routing, while respecting dependencies.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    messages : List[Dict]\n",
        "        A list of dictionaries. Each dictionary must have:\n",
        "        - \"id\": str           # Unique message identifier\n",
        "        - \"type\": str         # One of: \"DATA\", \"CONTROL\", \"STATUS\"\n",
        "        - \"payload\": dict     # Message content and metadata\n",
        "        - \"dependencies\": list # List of message IDs that must be processed first\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    List[Dict]\n",
        "        A list of dictionaries representing processed results:\n",
        "        - \"id\": str                # Original message ID\n",
        "        - \"status\": \"SUCCESS\" | \"FAILED\" | \"SKIPPED\"\n",
        "        - \"processors\": list       # List of processor names that handled the message\n",
        "        - \"result\": dict           # Final transformed payload (empty if SKIPPED or FAILED)\n",
        "    \"\"\"\n",
        "\n",
        "    ########################################################################\n",
        "    # Edge case 3: Return empty list for empty input\n",
        "    ########################################################################\n",
        "    if not messages:\n",
        "        return []\n",
        "\n",
        "    ########################################################################\n",
        "    # Configuration for required fields by message type.\n",
        "    # If a message is missing any of these fields, it is marked FAILED.\n",
        "    ########################################################################\n",
        "    REQUIRED_FIELDS = {\n",
        "        \"DATA\": [\"content\", \"checksum\"],\n",
        "        \"CONTROL\": [\"command\", \"target\"],\n",
        "        # For demonstration, assume \"STATUS\" requires \"info\".\n",
        "        \"STATUS\": [\"info\"],\n",
        "    }\n",
        "\n",
        "    ########################################################################\n",
        "    # Processor-chains for each message type. These are the names of the\n",
        "    # \"processors\" that will handle the message. The actual functions that\n",
        "    # do the processing are defined below.\n",
        "    #\n",
        "    # Note the maximum chain length ≤ 5 from the constraints.\n",
        "    ########################################################################\n",
        "    PROCESSOR_CHAINS = {\n",
        "        \"DATA\":   [\"validate_p1\", \"transform_p1\", \"route_p1\"],\n",
        "        \"CONTROL\": [\"control_p1\", \"route_p2\"],\n",
        "        \"STATUS\": [\"status_p1\", \"route_p3\"],\n",
        "    }\n",
        "\n",
        "    ########################################################################\n",
        "    # Helper: Check whether a message ID is valid (alphanumeric, ≤ 32 chars).\n",
        "    ########################################################################\n",
        "    def is_valid_message_id(msg_id: str) -> bool:\n",
        "        if not msg_id:\n",
        "            return False\n",
        "        if len(msg_id) > 32:\n",
        "            return False\n",
        "        return msg_id.isalnum()\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 1: Gather unique messages in the order they appear.\n",
        "    #         - Skip duplicates (only keep first).\n",
        "    #         - Skip invalid IDs.\n",
        "    ########################################################################\n",
        "    seen_ids = set()\n",
        "    valid_messages = []\n",
        "    for msg in messages:\n",
        "        msg_id = msg.get(\"id\")\n",
        "        # If \"id\" is missing or invalid or a duplicate, skip this message.\n",
        "        if not msg_id or not is_valid_message_id(msg_id):\n",
        "            continue\n",
        "        if msg_id in seen_ids:\n",
        "            # Edge case 4: Skip duplicate message IDs, keep first occurrence\n",
        "            continue\n",
        "        seen_ids.add(msg_id)\n",
        "        valid_messages.append(msg)\n",
        "\n",
        "    # If no valid messages remain, return empty\n",
        "    if not valid_messages:\n",
        "        return []\n",
        "\n",
        "    # Build a dictionary for quick lookup by ID\n",
        "    messages_by_id = {m[\"id\"]: m for m in valid_messages}\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 2: Prepare base results for each message, defaulting to PENDING.\n",
        "    #         We'll fill in status, processors, and result later.\n",
        "    ########################################################################\n",
        "    results_map = {\n",
        "        m[\"id\"]: {\n",
        "            \"id\": m[\"id\"],\n",
        "            \"status\": \"PENDING\",\n",
        "            \"processors\": [],\n",
        "            \"result\": {}\n",
        "        } for m in valid_messages\n",
        "    }\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 3: Build adjacency structures for dependency graph.\n",
        "    #\n",
        "    # We'll store edges as:\n",
        "    #   graph[dep] -> list of messages that directly depend on 'dep'.\n",
        "    #\n",
        "    # Then we can do a topological sort or DFS-based approach to detect cycles.\n",
        "    #\n",
        "    # Meanwhile, handle \"skip if references non-existent dependency\".\n",
        "    ########################################################################\n",
        "    # <Issue>: Model makes import inside the code instead of at the top.\n",
        "    from collections import defaultdict\n",
        "\n",
        "    graph = defaultdict(list)\n",
        "    indegree = defaultdict(int)\n",
        "\n",
        "    # Initialize in-degree for all message IDs\n",
        "    for m in valid_messages:\n",
        "        indegree[m[\"id\"]] = 0\n",
        "\n",
        "    # Check dependencies for existence. If non-existent, we mark the message SKIPPED\n",
        "    # immediately (and effectively remove it from the graph).\n",
        "    for m in valid_messages:\n",
        "        msg_id = m[\"id\"]\n",
        "        dependencies = m.get(\"dependencies\", [])\n",
        "        # If any dependency doesn't exist in messages_by_id, skip this message\n",
        "        # as per edge case #1.\n",
        "        for d in dependencies:\n",
        "            if d not in messages_by_id:\n",
        "                # Skip\n",
        "                results_map[msg_id][\"status\"] = \"SKIPPED\"\n",
        "                break\n",
        "        else:\n",
        "            # If we did not break, all dependencies exist. Build adjacency.\n",
        "            for d in dependencies:\n",
        "                graph[d].append(msg_id)\n",
        "                indegree[msg_id] += 1\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 4: Detect circular dependencies (and mark them FAILED).\n",
        "    #         We'll do a DFS-based cycle detection. If a node is SKIPPED,\n",
        "    #         we ignore it. If a cycle is found, all nodes in that cycle\n",
        "    #         get marked as FAILED.\n",
        "    #\n",
        "    #         We'll do a standard DFS with color states:\n",
        "    #            0 = unvisited, 1 = visiting, 2 = visited\n",
        "    #\n",
        "    #         If we detect a cycle, mark all nodes in the current recursion\n",
        "    #         stack as FAILED.\n",
        "    ########################################################################\n",
        "    visited = {m[\"id\"]: 0 for m in valid_messages}  # 0=unvisited\n",
        "    recursion_stack = []\n",
        "\n",
        "    def dfs_cycle_detect(node: str):\n",
        "        if results_map[node][\"status\"] in (\"SKIPPED\", \"FAILED\"):\n",
        "            return  # Already decided, skip\n",
        "        if visited[node] == 1:\n",
        "            # Found a cycle -> mark entire recursion stack as FAILED\n",
        "            for n in recursion_stack:\n",
        "                results_map[n][\"status\"] = \"FAILED\"\n",
        "            return\n",
        "        if visited[node] == 2:\n",
        "            return\n",
        "\n",
        "        visited[node] = 1\n",
        "        recursion_stack.append(node)\n",
        "\n",
        "        # Explore neighbors\n",
        "        for nxt in graph[node]:\n",
        "            # If neighbor not skipped/failed, DFS\n",
        "            if results_map[nxt][\"status\"] not in (\"SKIPPED\", \"FAILED\"):\n",
        "                dfs_cycle_detect(nxt)\n",
        "\n",
        "        visited[node] = 2\n",
        "        recursion_stack.pop()\n",
        "\n",
        "    # Run DFS cycle detection on each unvisited node\n",
        "    for m in valid_messages:\n",
        "        mid = m[\"id\"]\n",
        "        if visited[mid] == 0:\n",
        "            dfs_cycle_detect(mid)\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 5: Perform a topological sort among the messages that are not\n",
        "    #         SKIPPED or FAILED. We'll use Kahn's algorithm for clarity.\n",
        "    ########################################################################\n",
        "    # We'll only topologically sort messages with status==\"PENDING\".\n",
        "    # Everyone else (SKIPPED/FAILED) won't be processed further.\n",
        "    #\n",
        "    # Because we have potentially removed some edges by skipping, let's\n",
        "    # make a fresh queue of 0 in-degree nodes that are still PENDING.\n",
        "    ########################################################################\n",
        "    from collections import deque\n",
        "\n",
        "    topo_order = []\n",
        "    queue = deque()\n",
        "\n",
        "    # Initialize queue with PENDING, in-degree=0\n",
        "    for m in valid_messages:\n",
        "        mid = m[\"id\"]\n",
        "        if results_map[mid][\"status\"] == \"PENDING\" and indegree[mid] == 0:\n",
        "            queue.append(mid)\n",
        "\n",
        "    while queue:\n",
        "        cur = queue.popleft()\n",
        "        topo_order.append(cur)\n",
        "        # For each neighbor, reduce in-degree if neighbor is still PENDING\n",
        "        for nxt in graph[cur]:\n",
        "            if results_map[nxt][\"status\"] == \"PENDING\":\n",
        "                indegree[nxt] -= 1\n",
        "                if indegree[nxt] == 0:\n",
        "                    queue.append(nxt)\n",
        "\n",
        "    # Any PENDING message not in topo_order but still PENDING is unreachable\n",
        "    # or part of a cycle that got only partially flagged.\n",
        "    # Typically they'd remain if they had non-zero in-degree. If not in topo_order\n",
        "    # and status is still PENDING, it means there's a cycle. Mark them FAILED.\n",
        "    for m in valid_messages:\n",
        "        mid = m[\"id\"]\n",
        "        if (\n",
        "            results_map[mid][\"status\"] == \"PENDING\"\n",
        "            and mid not in topo_order\n",
        "        ):\n",
        "            results_map[mid][\"status\"] = \"FAILED\"\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 6: Define the actual processor functions. These must not modify\n",
        "    #         the original message payload directly. Instead, they return\n",
        "    #         an updated copy or partial result that can be merged.\n",
        "    #\n",
        "    #         All processors must do a simple validation check before\n",
        "    #         proceeding, and if that fails, we raise an exception to\n",
        "    #         indicate a failure that should stop the chain.\n",
        "    ########################################################################\n",
        "    \n",
        "    def validate_data(msg: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        For DATA type messages:\n",
        "        - Ensures required fields are present.\n",
        "        - Adds 'validated': True if successful.\n",
        "        - Does not keep 'checksum' in final result per example.\n",
        "        \"\"\"\n",
        "        payload = msg[\"payload\"]\n",
        "        # Double-check required fields\n",
        "        for field in REQUIRED_FIELDS[\"DATA\"]:\n",
        "            if field not in payload:\n",
        "                raise ValueError(\"Missing required DATA field.\")\n",
        "        # Return new partial result\n",
        "        return {\n",
        "            \"content\": payload[\"content\"],\n",
        "            \"validated\": True\n",
        "        }\n",
        "\n",
        "    def transform_data(msg: Dict, current_result: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Transforms content to uppercase.\n",
        "        \"\"\"\n",
        "        # Basic validation\n",
        "        if \"content\" not in current_result:\n",
        "            raise ValueError(\"Missing content in partial result (DATA).\")\n",
        "        transformed = current_result[\"content\"].upper()\n",
        "        updated_result = dict(current_result)\n",
        "        updated_result[\"content\"] = transformed\n",
        "        return updated_result\n",
        "\n",
        "    def route_data(msg: Dict, current_result: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Example of routing step; does nothing significant in this example.\n",
        "        \"\"\"\n",
        "        # Basic validation\n",
        "        if \"content\" not in current_result:\n",
        "            raise ValueError(\"Cannot route DATA without content.\")\n",
        "        return dict(current_result)\n",
        "\n",
        "    def validate_control(msg: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        For CONTROL type messages:\n",
        "        - Ensures required fields are present.\n",
        "        - We'll discard them in final output, but let's pass them along.\n",
        "        \"\"\"\n",
        "        # <Issue>: Model doesn't check for payload depth validation (max 3\n",
        "        # levels)\n",
        "        payload = msg[\"payload\"]\n",
        "        \n",
        "        for field in REQUIRED_FIELDS[\"CONTROL\"]:\n",
        "            if field not in payload:\n",
        "                raise ValueError(\"Missing required CONTROL field.\")\n",
        "        # <Issue>: Model's CONTROL processor doesn't return correct result\n",
        "        # format\n",
        "        # Return an empty partial since example discards them\n",
        "        return {}\n",
        "\n",
        "    def apply_control(msg: Dict, current_result: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Applies some control logic.\n",
        "        In the example, we ended up with {\"command_status\": \"completed\"}.\n",
        "        We'll do that here.\n",
        "        \"\"\"\n",
        "        updated_result = dict(current_result)\n",
        "        updated_result[\"command_status\"] = \"completed\"\n",
        "        return updated_result\n",
        "\n",
        "    def route_control(msg: Dict, current_result: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Routing for CONTROL, does nothing special in the example.\n",
        "        \"\"\"\n",
        "        return dict(current_result)\n",
        "\n",
        "    def validate_status(msg: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        For STATUS type messages:\n",
        "        - Ensures required fields are present.\n",
        "        \"\"\"\n",
        "        payload = msg[\"payload\"]\n",
        "        for field in REQUIRED_FIELDS[\"STATUS\"]:\n",
        "            if field not in payload:\n",
        "                raise ValueError(\"Missing required STATUS field.\")\n",
        "        return {\"info\": payload[\"info\"]}\n",
        "\n",
        "    def route_status(msg: Dict, current_result: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Example final step for STATUS messages.\n",
        "        \"\"\"\n",
        "        return dict(current_result)\n",
        "\n",
        "    # Create a mapping from processor name to actual callable\n",
        "    PROCESSOR_FUNCTIONS = {\n",
        "        \"validate_p1\": lambda msg, res=None: validate_data(msg),\n",
        "        \"transform_p1\": lambda msg, res: transform_data(msg, res),\n",
        "        \"route_p1\": lambda msg, res: route_data(msg, res),\n",
        "\n",
        "        \"control_p1\": lambda msg, res=None: validate_control(msg),\n",
        "        \"route_p2\": lambda msg, res: route_control(msg, res),\n",
        "\n",
        "        \"status_p1\": lambda msg, res=None: validate_status(msg),\n",
        "        \"route_p3\": lambda msg, res: route_status(msg, res),\n",
        "    }\n",
        "\n",
        "    ########################################################################\n",
        "    # Step 7: Process each message in topological order if status==PENDING.\n",
        "    #         - If unknown type, mark SKIPPED\n",
        "    #         - If any processor fails, mark FAILED\n",
        "    #         - Otherwise, STATUS=SUCCESS\n",
        "    #\n",
        "    #         NOTE: \"Processor must not modify original input payload\", so\n",
        "    #         each step works on a copy.\n",
        "    ########################################################################\n",
        "    for mid in topo_order:\n",
        "        if results_map[mid][\"status\"] != \"PENDING\":\n",
        "            continue\n",
        "\n",
        "        message = messages_by_id[mid]\n",
        "        mtype = message.get(\"type\", \"\")\n",
        "        # If it's an unknown type, skip\n",
        "        if mtype not in PROCESSOR_CHAINS:\n",
        "            results_map[mid][\"status\"] = \"SKIPPED\"\n",
        "            continue\n",
        "\n",
        "        # <Issue>: Model doesn't check for processor chain length constraint\n",
        "        # Build the chain\n",
        "        chain = PROCESSOR_CHAINS[mtype]\n",
        "\n",
        "        current_result = {}\n",
        "        processors_list = []\n",
        "        try:\n",
        "            for processor_name in chain:\n",
        "                processor_func = PROCESSOR_FUNCTIONS[processor_name]\n",
        "                # Some processors expect res=None for their first step,\n",
        "                # some expect res. We'll handle it carefully:\n",
        "                if \"validate\" in processor_name or processor_name.endswith(\"p1\"):\n",
        "                    # If it's the first in chain, pass res=None if we have none\n",
        "                    if current_result:\n",
        "                        # we might pass it anyway if that is simpler\n",
        "                        new_result = processor_func(message, current_result)\n",
        "                    else:\n",
        "                        new_result = processor_func(message)\n",
        "                else:\n",
        "                    # subsequent steps expect current_result\n",
        "                    new_result = processor_func(message, current_result)\n",
        "                current_result = new_result\n",
        "                processors_list.append(processor_name)\n",
        "\n",
        "            # Mark success\n",
        "            results_map[mid][\"status\"] = \"SUCCESS\"\n",
        "            results_map[mid][\"processors\"] = processors_list\n",
        "            results_map[mid][\"result\"] = current_result\n",
        "\n",
        "        except Exception:\n",
        "            # On any failure in the chain, mark FAILED\n",
        "            results_map[mid][\"status\"] = \"FAILED\"\n",
        "            results_map[mid][\"processors\"] = processors_list\n",
        "            results_map[mid][\"result\"] = {}\n",
        "            # Stop processing further\n",
        "\n",
        "    ########################################################################\n",
        "    # Finally, build the output list in the original (valid) message order.\n",
        "    ########################################################################\n",
        "    output = []\n",
        "    for m in valid_messages:\n",
        "        mid = m[\"id\"]\n",
        "        output.append({\n",
        "            \"id\": results_map[mid][\"id\"],\n",
        "            \"status\": results_map[mid][\"status\"],\n",
        "            \"processors\": results_map[mid][\"processors\"],\n",
        "            \"result\": results_map[mid][\"result\"],\n",
        "        })\n",
        "\n",
        "    return output\n",
        "\n",
        "########################################################################\n",
        "# Driver code / Example test\n",
        "########################################################################\n",
        "if __name__ == \"__main__\":\n",
        "    # Example input\n",
        "    messages_input = [\n",
        "        {\n",
        "            \"id\": \"msg1\",\n",
        "            \"type\": \"DATA\",\n",
        "            \"payload\": {\"content\": \"hello\", \"checksum\": \"abc123\"},\n",
        "            \"dependencies\": []\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"msg2\",\n",
        "            \"type\": \"CONTROL\",\n",
        "            \"payload\": {\"command\": \"validate\", \"target\": \"msg1\"},\n",
        "            \"dependencies\": [\"msg1\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    results = process_message_pipeline(messages_input)\n",
        "    print(\"RESULTS:\")\n",
        "    for r in results:\n",
        "        print(r)\n",
        "\n",
        "    # Expected output (similar to the problem statement example):\n",
        "    #\n",
        "    # [\n",
        "    #   {\n",
        "    #       \"id\": \"msg1\",\n",
        "    #       \"status\": \"SUCCESS\",\n",
        "    #       \"processors\": [\"validate_p1\", \"transform_p1\", \"route_p1\"],\n",
        "    #       \"result\": {\"content\": \"HELLO\", \"validated\": True}\n",
        "    #   },\n",
        "    #   {\n",
        "    #       \"id\": \"msg2\",\n",
        "    #       \"status\": \"SUCCESS\",\n",
        "    #       \"processors\": [\"control_p1\", \"route_p2\"],\n",
        "    #       \"result\": {\"command_status\": \"completed\"}\n",
        "    #   }\n",
        "    # ]\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}