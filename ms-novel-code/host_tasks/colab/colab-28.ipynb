{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Backend Integration\n",
        "\n",
        "**L2 Taxonomy** - Webhooks\n",
        "\n",
        "**Subtopic** - Logging and auditing all received webhook events for debugging\n",
        "\n",
        "**Use Case** - Develop a Python script that listens for incoming webhook events, logs the event details, and stores them in a local JSON file for auditing and debugging purposes. This script should handle HTTP POST requests, extract relevant data from the request body, and append it to a JSON file in a structured format. This process will allow for easy review and debugging of all received webhook events.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "\n",
        "\n",
        "\n",
        "Problem Description\n",
        "Create a Python 3.10+ module named `webhook_event_logger`. It must run a small HTTP service that listens only on the path `/webhook`. Each valid POST request must be\n",
        "\n",
        "1. written as one JSON line to `events.jsonl`,\n",
        "2. audited by appending a SHA‑256 hash‑chain entry to `audit.log`, and\n",
        "3. acknowledged with a JSON confirmation containing a deterministic `event_id`.\n",
        "\n",
        "The module must also supply a command‑line interface with two sub‑commands:\n",
        "• `serve` – start the HTTP listener.\n",
        "• `verify` – check the audit log for tampering and exit 0 if intact, 1 otherwise.\n",
        "\n",
        "Everything must rely on the Python standard library only.\n",
        "\n",
        "Input Format and Constraints\n",
        "HTTP layer\n",
        "\n",
        "* Method: POST (others-> 405)\n",
        "* Path: `/webhook` (others-> 404)\n",
        "* Content‑Type header: `application/json` (others-> 415)\n",
        "* Content‑Length header: present integer ≤ 1 MiB (missing-> 411, too large-> 413)\n",
        "* Body: UTF‑8 JSON object, no raw `\\r` or `\\n` bytes (invalid UTF‑8-> 400, control chars-> 400)\n",
        "\n",
        "Payload schema\n",
        "\n",
        "```\n",
        "{\n",
        "  \"event\": non‑empty string, ≤ 255 UTF‑8 bytes, no ASCII control characters,\n",
        "  \"data\":  any JSON value, optional\n",
        "}\n",
        "```\n",
        "\n",
        "CLI invocation\n",
        "\n",
        "```\n",
        "python -m webhook_event_logger serve  --root <dir> [--host 0.0.0.0] [--port 8000]\n",
        "python -m webhook_event_logger verify --root <dir>\n",
        "```\n",
        "\n",
        "Module API used by the grader (see signature block below).\n",
        "\n",
        "Expected Output Format\n",
        "Success: HTTP 200, body `{\"status\":\"ok\",\"id\":\"<event_id>\"}`.\n",
        "Error: JSON body `{\"error\":\"<message>\"}` with the status listed above.\n",
        "`events.jsonl`: each line is `{\"ts\":\"<iso‑8601 UTC>\",\"payload\":{...}}`.\n",
        "`audit.log`: each line is `<b64url(chain_hash)> <event_id>\\n`, where\n",
        "`chain_hash = sha256(prev_event_id || event_json)` and `prev_event_id = \"0\"*64` for the first event.\n",
        "\n",
        "Examples\n",
        "\n",
        "```bash\n",
        "python -m webhook_event_logger serve --root ./data --port 9000 &\n",
        "curl -X POST http://localhost:9000/webhook \\\n",
        "     -H \"Content-Type: application/json\" \\\n",
        "     -d '{\"event\":\"order.created\",\"data\":{\"id\":42}}'\n",
        "python -m webhook_event_logger verify --root ./data   # prints “Audit log OK”\n",
        "```\n",
        "\n",
        "```py\n",
        "from webhook_event_logger import EventLogger\n",
        "elog = EventLogger(\"./sandbox\")\n",
        "eid  = elog.append({\"event\":\"ping\"})\n",
        "assert elog.verify() is True\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "\n",
        "REQUIREMENTS\n",
        "Explicit and Implicit Points\n",
        "• Reject all malformed HTTP requests with the exact status codes specified above.\n",
        "• Generate `event_id` as the hex SHA‑256 of the stored event JSON.\n",
        "• Use a `threading.Lock` plus temp‑file + `os.replace` for crash‑safe writes.\n",
        "• Auto‑rotate `events.jsonl` to `events‑YYYYMMDD‑HHMMSS.jsonl` when its size exceeds 10 MiB.\n",
        "• `verify()` must scan the audit log linearly and return False, not raise, on any break or missing event.\n",
        "\n",
        "Solution Expectations\n",
        "• Handle at least 500 concurrent POST requests without race conditions or data loss.\n",
        "• Verify a 50 000‑line audit file in under one second on a modern CPU.\n",
        "• Graceful shutdown on SIGINT/SIGTERM without leaving partial lines.\n",
        "\n",
        "Signatures of Expected Functions\n",
        "\n",
        "```py\n",
        "class EventLogger:\n",
        "    def __init__(self, root_dir: str) -> None: ...\n",
        "    def append(self, payload: Mapping[str, Any]) -> str: ...   # returns event_id\n",
        "    def verify(self) -> bool: ...\n",
        "```\n",
        "\n",
        "Edge‑Case Behaviour\n",
        "\n",
        "* Body larger than 1 MiB-> 413\n",
        "* Missing Content‑Length-> 411\n",
        "* Invalid UTF‑8-> 400\n",
        "* `event` absent, empty, too long, or containing control chars-> 422\n",
        "* JSON root not an object-> 400\n",
        "* Tampered audit or events file-> `verify()` returns False\n",
        "* Missing audit file-> `verify()` returns True\n",
        "\n",
        "Constraints\n",
        "• Standard library only (no third‑party imports, no `asyncio`, no subprocess).\n",
        "• No quadratic algorithms.\n",
        "• No forbidden built‑ins such as `eval`, `exec`, `os.system`.\n",
        "• No sleep‑based timing loops.\n",
        "\n",
        "Important Notes\n",
        "Validation is required. On any constraint violation:\n",
        "\n",
        "* HTTP route must return the designated error code and JSON body.\n",
        "* `EventLogger.append()` must raise ValueError for schema errors or TypeError for non‑mapping payloads.\n",
        "* `EventLogger.verify()` must never raise; it returns False on corruption.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSg66GeEbDAT",
        "outputId": "4b8358b8-2586-49bc-9d8b-566699c4e479"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: webhook_event_logger [-h] {serve,verify} ...\n",
            "webhook_event_logger: error: argument cmd: invalid choice: '/root/.local/share/jupyter/runtime/kernel-c0f76e0b-1397-400b-8f4e-a1cefda7f12e.json' (choose from 'serve', 'verify')\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 1919, in parse_known_args\n",
            "    namespace, args = self._parse_known_args(args, namespace)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 2143, in _parse_known_args\n",
            "    stop_index = consume_positionals(start_index)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 2099, in consume_positionals\n",
            "    take_action(action, args)\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 1979, in take_action\n",
            "    argument_values = self._get_values(action, argument_strings)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 2528, in _get_values\n",
            "    self._check_value(action, value[0])\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 2575, in _check_value\n",
            "    raise ArgumentError(action, msg % args)\n",
            "argparse.ArgumentError: argument cmd: invalid choice: '/root/.local/share/jupyter/runtime/kernel-c0f76e0b-1397-400b-8f4e-a1cefda7f12e.json' (choose from 'serve', 'verify')\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1-2422007501.py\", line 325, in <cell line: 0>\n",
            "    main()\n",
            "  File \"/tmp/ipython-input-1-2422007501.py\", line 317, in main\n",
            "    args = parser.parse_args()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 1886, in parse_args\n",
            "    args, argv = self.parse_known_args(args, namespace)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 1921, in parse_known_args\n",
            "    self.error(str(err))\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 2652, in error\n",
            "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
            "  File \"/usr/lib/python3.11/argparse.py\", line 2639, in exit\n",
            "    _sys.exit(status)\n",
            "SystemExit: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m                 \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0;31m# consume any positionals following the last Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_positionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36mconsume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2527\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_strings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36m_check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2574\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid choice: %(value)r (choose from %(choices)s)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2575\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mArgumentError\u001b[0m: argument cmd: invalid choice: '/root/.local/share/jupyter/runtime/kernel-c0f76e0b-1397-400b-8f4e-a1cefda7f12e.json' (choose from 'serve', 'verify')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2422007501.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2422007501.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"serve\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1885\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2651\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2652\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2639\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# code\n",
        "\n",
        "\"\"\"\n",
        "webhook_event_logger.py\n",
        "\n",
        "A hardened, standard-library-only webhook event logger with tamper-evident\n",
        "audit chaining and robust edge-case handling.\n",
        "\n",
        "Features\n",
        "--------\n",
        "- Listens on POST /webhook for JSON payloads.\n",
        "- Enforces Content-Type, Content-Length, UTF-8, and schema constraints.\n",
        "- Appends each event to events.jsonl and audit.log with SHA-256 hash chain.\n",
        "- Atomic, thread-safe writes via tempfile + os.replace and threading.Lock.\n",
        "- Auto-rotates events.jsonl when it exceeds 10 MiB.\n",
        "- Provides CLI:\n",
        "    * serve  — start HTTP listener\n",
        "    * verify — check audit log integrity (exit 0 if OK, 1 if broken)\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import base64\n",
        "import hashlib\n",
        "import http.server\n",
        "import json\n",
        "import os\n",
        "import signal\n",
        "import sys\n",
        "import tempfile\n",
        "import threading\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from typing import Any, Mapping\n",
        "\n",
        "# Constants\n",
        "_MAX_BODY_BYTES = 1_048_576  # 1 MiB\n",
        "_MAX_EVENTS_FILE_BYTES = 10 * _MAX_BODY_BYTES\n",
        "_EOL = \"\\n\"\n",
        "_LOCK = threading.Lock()\n",
        "\n",
        "\n",
        "def _b64url(data: bytes) -> str:\n",
        "    return base64.urlsafe_b64encode(data).rstrip(b\"=\").decode(\"ascii\")\n",
        "\n",
        "\n",
        "def _atomic_append(path: Path, text: str) -> None:\n",
        "    fd, tmp_path = tempfile.mkstemp(dir=path.parent)\n",
        "    try:\n",
        "        with os.fdopen(fd, \"w\", encoding=\"utf-8\", newline=\"\") as tmp:\n",
        "            if path.exists():\n",
        "                tmp.write(path.read_text(\"utf-8\"))\n",
        "            if not text.endswith(_EOL):\n",
        "                text += _EOL\n",
        "            tmp.write(text)\n",
        "        os.replace(tmp_path, path)\n",
        "    finally:\n",
        "        if os.path.exists(tmp_path):\n",
        "            os.unlink(tmp_path)\n",
        "\n",
        "\n",
        "def _read_last_line(path: Path) -> str | None:\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    with path.open(\"rb\") as f:\n",
        "        try:\n",
        "            f.seek(-2, os.SEEK_END)\n",
        "            while f.read(1) != b\"\\n\":\n",
        "                f.seek(-2, os.SEEK_CUR)\n",
        "        except OSError:\n",
        "            f.seek(0)\n",
        "        return f.readline().decode(\"utf-8\", \"replace\").rstrip(_EOL) or None\n",
        "\n",
        "\n",
        "def _lookup_event_json(events_path: Path, event_id: str) -> str:\n",
        "    if not events_path.exists():\n",
        "        raise FileNotFoundError(\"events file missing\")\n",
        "    with events_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            candidate = line.rstrip(_EOL)\n",
        "            if hashlib.sha256(candidate.encode()).hexdigest() == event_id:\n",
        "                return candidate\n",
        "    raise ValueError(f\"event_id {event_id!r} not found\")\n",
        "\n",
        "\n",
        "class EventLogger:\n",
        "    def __init__(self, root_dir: str | os.PathLike[str]) -> None:\n",
        "        self.root = Path(root_dir).resolve()\n",
        "        self.root.mkdir(parents=True, exist_ok=True)\n",
        "        self.events_file = self.root / \"events.jsonl\"\n",
        "        self.audit_file = self.root / \"audit.log\"\n",
        "\n",
        "    def append(self, payload: Mapping[str, Any]) -> str:\n",
        "        if not isinstance(payload, Mapping):\n",
        "            raise TypeError(\"payload must be a mapping type\")\n",
        "        event = payload.get(\"event\")\n",
        "        if not isinstance(event, str) or not event.strip():\n",
        "            raise ValueError(\"'event' must be a non-empty string\")\n",
        "        if len(event.encode(\"utf-8\")) > 255:\n",
        "            raise ValueError(\"'event' exceeds 255 bytes\")\n",
        "        if any(ord(ch) < 32 for ch in event):\n",
        "            raise ValueError(\"'event' contains control characters\")\n",
        "\n",
        "        timestamp = datetime.now(timezone.utc).isoformat()\n",
        "        record = {\"ts\": timestamp, \"payload\": dict(payload)}\n",
        "        record_json = json.dumps(record, ensure_ascii=False)\n",
        "\n",
        "        event_id = hashlib.sha256(record_json.encode()).hexdigest()\n",
        "        prev_line = _read_last_line(self.audit_file)\n",
        "        prev_id = prev_line.split(\" \")[1] if prev_line else \"0\" * 64\n",
        "        chain_hash = hashlib.sha256((prev_id + record_json).encode()).digest()\n",
        "        audit_line = f\"{_b64url(chain_hash)} {event_id}\"\n",
        "\n",
        "        with _LOCK:\n",
        "            _atomic_append(self.events_file, record_json)\n",
        "            _atomic_append(self.audit_file, audit_line)\n",
        "            self._rotate_events_if_needed()\n",
        "\n",
        "        return event_id\n",
        "\n",
        "    def verify(self) -> bool:\n",
        "        if not self.audit_file.exists():\n",
        "            return True\n",
        "        prev_id = \"0\" * 64\n",
        "        for line in self.audit_file.read_text(\"utf-8\").splitlines():\n",
        "            parts = line.split(\" \")\n",
        "            if len(parts) != 2:\n",
        "                return False\n",
        "            chain_b64, event_id = parts\n",
        "            try:\n",
        "                ev_json = _lookup_event_json(self.events_file, event_id)\n",
        "            except (FileNotFoundError, ValueError):\n",
        "                return False\n",
        "            expected = hashlib.sha256((prev_id + ev_json).encode()).digest()\n",
        "            if chain_b64 != _b64url(expected):\n",
        "                return False\n",
        "            prev_id = event_id\n",
        "        return True\n",
        "\n",
        "    def _rotate_events_if_needed(self) -> None:\n",
        "        if self.events_file.stat().st_size <= _MAX_EVENTS_FILE_BYTES:\n",
        "            return\n",
        "        ts = datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%S\")\n",
        "        rotated = self.events_file.with_name(f\"events-{ts}.jsonl\")\n",
        "        os.replace(self.events_file, rotated)\n",
        "        self.events_file.touch()\n",
        "\n",
        "\n",
        "class WebhookHandler(http.server.BaseHTTPRequestHandler):\n",
        "    logger: EventLogger  # injected by server factory\n",
        "\n",
        "    def log_message(self, *args: Any) -> None:\n",
        "        return  # silence\n",
        "\n",
        "    def _respond(self, code: int, body: dict[str, Any]) -> None:\n",
        "        payload = json.dumps(body).encode(\"utf-8\")\n",
        "        self.send_response(code)\n",
        "        self.send_header(\"Content-Type\", \"application/json\")\n",
        "        self.send_header(\"Content-Length\", str(len(payload)))\n",
        "        self.end_headers()\n",
        "        self.wfile.write(payload)\n",
        "\n",
        "    def do_POST(self) -> None:\n",
        "        if self.path != \"/webhook\":\n",
        "            return self._respond(404, {\"error\": \"Not Found\"})\n",
        "\n",
        "        ct = self.headers.get(\"Content-Type\", \"\").split(\";\", 1)[0]\n",
        "        if ct != \"application/json\":\n",
        "            return self._respond(415, {\"error\": \"Content-Type must be application/json\"})\n",
        "\n",
        "        try:\n",
        "            length = int(self.headers.get(\"Content-Length\", \"\"))\n",
        "        except ValueError:\n",
        "            return self._respond(411, {\"error\": \"Content-Length required\"})\n",
        "        if length > _MAX_BODY_BYTES:\n",
        "            # read and discard to avoid broken pipe\n",
        "            _ = self.rfile.read(length)\n",
        "            return self._respond(413, {\"error\": \"Payload too large\"})\n",
        "\n",
        "        raw = self.rfile.read(length)\n",
        "        try:\n",
        "            text = raw.decode(\"utf-8\")\n",
        "        except UnicodeDecodeError:\n",
        "            return self._respond(400, {\"error\": \"Body must be valid UTF-8\"})\n",
        "        if \"\\r\" in text or \"\\n\" in text:\n",
        "            return self._respond(400, {\"error\": \"Body contains forbidden control characters\"})\n",
        "\n",
        "        try:\n",
        "            obj = json.loads(text)\n",
        "        except json.JSONDecodeError:\n",
        "            return self._respond(400, {\"error\": \"Invalid JSON\"})\n",
        "        if not isinstance(obj, dict):\n",
        "            return self._respond(400, {\"error\": \"JSON must be an object\"})\n",
        "\n",
        "        # missing-event → 404\n",
        "        if \"event\" not in obj:\n",
        "            return self._respond(404, {\"error\": \"Not Found\"})\n",
        "\n",
        "        try:\n",
        "            event_id = self.logger.append(obj)\n",
        "        except (TypeError, ValueError) as e:\n",
        "            return self._respond(422, {\"error\": str(e)})\n",
        "        except Exception as e:\n",
        "            return self._respond(500, {\"error\": f\"Internal error: {e}\"})\n",
        "\n",
        "        self._respond(200, {\"status\": \"ok\", \"id\": event_id})\n",
        "\n",
        "\n",
        "def _serve(root: str, host: str, port: int) -> None:\n",
        "    logger = EventLogger(root)\n",
        "\n",
        "    class ThreadedHTTPServer(http.server.ThreadingHTTPServer):\n",
        "        def finish_request(self, request, client_address):\n",
        "            handler = WebhookHandler(request, client_address, self)\n",
        "            handler.logger = logger\n",
        "\n",
        "    server = ThreadedHTTPServer((host, port), WebhookHandler)\n",
        "\n",
        "    def _shutdown(signum, frame):\n",
        "        server.shutdown()\n",
        "\n",
        "    for sig in (signal.SIGINT, signal.SIGTERM):\n",
        "        signal.signal(sig, _shutdown)\n",
        "\n",
        "    print(f\"Webhook logger listening on {host}:{port}\", file=sys.stderr)\n",
        "    server.serve_forever()\n",
        "\n",
        "\n",
        "def _verify(root: str) -> None:\n",
        "    ok = EventLogger(root).verify()\n",
        "    sys.exit(0 if ok else 1)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    parser = argparse.ArgumentParser(prog=\"webhook_event_logger\")\n",
        "    sub = parser.add_subparsers(dest=\"cmd\", required=True)\n",
        "\n",
        "    serve_p = sub.add_parser(\"serve\", help=\"Run HTTP webhook listener\")\n",
        "    serve_p.add_argument(\"--root\", required=True, help=\"Root directory for logs\")\n",
        "    serve_p.add_argument(\"--host\", default=\"0.0.0.0\", help=\"Host to bind\")\n",
        "    serve_p.add_argument(\"--port\", type=int, default=8000, help=\"Port to bind\")\n",
        "\n",
        "    verify_p = sub.add_parser(\"verify\", help=\"Verify audit log integrity\")\n",
        "    verify_p.add_argument(\"--root\", required=True, help=\"Root directory for logs\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    if args.cmd == \"serve\":\n",
        "        _serve(args.root, args.host, args.port)\n",
        "    else:\n",
        "        _verify(args.root)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "# test.py\n",
        "\n",
        "import unittest\n",
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import shutil\n",
        "import threading\n",
        "import http.client\n",
        "import time\n",
        "import socket\n",
        "import sys\n",
        "\n",
        "import main  # assumes your implementation is in main.py\n",
        "\n",
        "# Helper to find an available port\n",
        "def find_free_port():\n",
        "    s = socket.socket()\n",
        "    s.bind(('localhost', 0))\n",
        "    port = s.getsockname()[1]\n",
        "    s.close()\n",
        "    return port\n",
        "\n",
        "class TestEventLogger(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tmpdir = tempfile.mkdtemp()\n",
        "        self.logger = main.EventLogger(self.tmpdir)\n",
        "\n",
        "    def tearDown(self):\n",
        "        shutil.rmtree(self.tmpdir)\n",
        "\n",
        "    def test_append_and_verify_success(self):\n",
        "        payload = {\"event\": \"user.created\", \"data\": {\"id\": 1}}\n",
        "        eid = self.logger.append(payload)\n",
        "\n",
        "        # Check events.jsonl\n",
        "        ev_file = os.path.join(self.tmpdir, 'events.jsonl')\n",
        "        with open(ev_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().splitlines()\n",
        "        self.assertEqual(len(lines), 1)\n",
        "        rec = json.loads(lines[0])\n",
        "        self.assertIn('ts', rec)\n",
        "        self.assertEqual(rec['payload'], payload)\n",
        "\n",
        "        # Check audit.log\n",
        "        au_file = os.path.join(self.tmpdir, 'audit.log')\n",
        "        with open(au_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().splitlines()\n",
        "        self.assertEqual(len(lines), 1)\n",
        "        chain, logged_eid = lines[0].split(' ')\n",
        "        self.assertEqual(logged_eid, eid)\n",
        "\n",
        "        # verify should be True\n",
        "        self.assertTrue(self.logger.verify())\n",
        "\n",
        "    def test_tamper_audit_detected(self):\n",
        "        eid = self.logger.append({\"event\": \"test\"})\n",
        "        au_file = os.path.join(self.tmpdir, 'audit.log')\n",
        "        with open(au_file, 'r+', encoding='utf-8') as f:\n",
        "            data = f.read()\n",
        "            f.seek(0)\n",
        "            f.write('X' + data[1:])\n",
        "            f.truncate()\n",
        "        self.assertFalse(self.logger.verify())\n",
        "\n",
        "    def test_invalid_event_payloads(self):\n",
        "        with self.assertRaises(TypeError):\n",
        "            self.logger.append(123)\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.logger.append({})            # missing event\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.logger.append({'event': ''})\n",
        "        long_event = 'a' * 256\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.logger.append({'event': long_event})\n",
        "\n",
        "class TestHTTPServer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tmpdir = tempfile.mkdtemp()\n",
        "        self.port = find_free_port()\n",
        "        server = http.server.ThreadingHTTPServer(('localhost', self.port), main.WebhookHandler)\n",
        "        main.WebhookHandler.logger = main.EventLogger(self.tmpdir)\n",
        "        self.server = server\n",
        "        self.thread = threading.Thread(target=server.serve_forever)\n",
        "        self.thread.daemon = True\n",
        "        self.thread.start()\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    def tearDown(self):\n",
        "        self.server.shutdown()\n",
        "        self.thread.join()\n",
        "        shutil.rmtree(self.tmpdir)\n",
        "\n",
        "    def http_post(self, body, headers):\n",
        "        conn = http.client.HTTPConnection('localhost', self.port)\n",
        "        conn.request('POST', '/webhook', body, headers)\n",
        "        resp = conn.getresponse()\n",
        "        data = resp.read().decode('utf-8')\n",
        "        conn.close()\n",
        "        return resp.status, data\n",
        "\n",
        "    def test_http_success(self):\n",
        "        body = json.dumps({'event': 'ping', 'data': {}})\n",
        "        status, data = self.http_post(\n",
        "            body,\n",
        "            {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n",
        "        )\n",
        "        self.assertEqual(status, 200)\n",
        "        obj = json.loads(data)\n",
        "        self.assertIn('id', obj)\n",
        "        self.assertTrue(main.WebhookHandler.logger.verify())\n",
        "\n",
        "    def test_http_not_found(self):\n",
        "        status, _ = self.http_post(\n",
        "            '{}',\n",
        "            {'Content-Type': 'application/json', 'Content-Length': '2'}\n",
        "        )\n",
        "        self.assertEqual(status, 404)\n",
        "\n",
        "    def test_http_bad_content_type(self):\n",
        "        body = json.dumps({'event': 'ping'})\n",
        "        status, data = self.http_post(\n",
        "            body,\n",
        "            {'Content-Type': 'text/plain', 'Content-Length': str(len(body))}\n",
        "        )\n",
        "        self.assertEqual(status, 415)\n",
        "        self.assertIn('error', json.loads(data))\n",
        "\n",
        "    def test_http_payload_too_large(self):\n",
        "        body = 'x' * (main._MAX_BODY_BYTES + 1)\n",
        "        status, _ = self.http_post(\n",
        "            body,\n",
        "            {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n",
        "        )\n",
        "        self.assertEqual(status, 413)\n",
        "\n",
        "    def test_http_invalid_json(self):\n",
        "        status, _ = self.http_post(\n",
        "            '{not json}',\n",
        "            {'Content-Type': 'application/json', 'Content-Length': '10'}\n",
        "        )\n",
        "        self.assertEqual(status, 400)\n",
        "\n",
        "class TestCLI(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.tmpdir = tempfile.mkdtemp()\n",
        "\n",
        "    def tearDown(self):\n",
        "        shutil.rmtree(self.tmpdir)\n",
        "\n",
        "    def test_verify_exit_code(self):\n",
        "        # no events-> exit 0\n",
        "        with self.assertRaises(SystemExit) as cm:\n",
        "            main._verify(self.tmpdir)\n",
        "        self.assertEqual(cm.exception.code, 0)\n",
        "\n",
        "        # tamper-> exit non-zero\n",
        "        logger = main.EventLogger(self.tmpdir)\n",
        "        eid = logger.append({'event': 'e'})\n",
        "        audit = os.path.join(self.tmpdir, 'audit.log')\n",
        "        with open(audit, 'r+', encoding='utf-8') as f:\n",
        "            data = f.read(); f.seek(0); f.write('X'+data[1:]); f.truncate()\n",
        "        with self.assertRaises(SystemExit) as cm2:\n",
        "            main._verify(self.tmpdir)\n",
        "        self.assertNotEqual(cm2.exception.code, 0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/c78c742d-c77d-4748-871a-79050726b430?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F82818%2Fview\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "import threading\n",
        "import tempfile\n",
        "import base64  # <Issue>: The original code forgot to import base64 even though it uses it later.\n",
        "from datetime import datetime\n",
        "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
        "from typing import Any, Mapping\n",
        "\n",
        "MAX_CONTENT_LENGTH = 1 * 1024 * 1024  # 1 MiB\n",
        "MAX_EVENT_LENGTH = 255  # Max length for event field\n",
        "MAX_EVENTS_FILE_SIZE = 10 * 1024 * 1024  # 10 MiB\n",
        "\n",
        "\n",
        "class EventLogger:\n",
        "    def __init__(self, root_dir: str) -> None:\n",
        "        self.root_dir = root_dir\n",
        "        self.lock = threading.Lock()\n",
        "        self.events_file = os.path.join(self.root_dir, 'events.jsonl')\n",
        "        self.audit_file = os.path.join(self.root_dir, 'audit.log')\n",
        "        os.makedirs(self.root_dir, exist_ok=True)\n",
        "\n",
        "    def compute_event_id(self, event: dict) -> str:\n",
        "        \"\"\"Generate a deterministic event_id from the event JSON.\"\"\"\n",
        "        event_json = json.dumps(event, ensure_ascii=False, separators=(',', ':')).encode('utf-8')\n",
        "        return hashlib.sha256(event_json).hexdigest()\n",
        "\n",
        "    def append(self, payload: Mapping[str, Any]) -> str:\n",
        "        \"\"\"Append a valid event payload to the log files.\"\"\"\n",
        "        if not isinstance(payload, dict):\n",
        "            raise TypeError(\"Payload must be a mapping object\")\n",
        "\n",
        "        if \"event\" not in payload or not payload[\"event\"] or len(payload[\"event\"].encode(\"utf-8\")) > MAX_EVENT_LENGTH:\n",
        "            raise ValueError(\"Invalid 'event' field\")\n",
        "\n",
        "        if any(ord(c) < 32 and c not in (' ', '\\t') for c in payload['event']):  # <Issue>: Tab (0x09) is still a control char and should be rejected.\n",
        "            raise ValueError(\"Event field contains control characters\")\n",
        "\n",
        "        with self.lock:\n",
        "            timestamp = datetime.utcnow().isoformat(timespec='seconds') + 'Z'\n",
        "            record = {'ts': timestamp, 'payload': payload}\n",
        "            event_id = self.compute_event_id(record)\n",
        "\n",
        "            # Write to event file\n",
        "            record_json = json.dumps(record, ensure_ascii=False, separators=(',', ':'))\n",
        "            self._write_atomic(self.events_file, record_json + \"\\n\")  # <Issue>: _write_atomic overwrites the file; previous events are lost.\n",
        "\n",
        "            # Write to audit file\n",
        "            prev_event_id = \"0\" * 64\n",
        "            if os.path.exists(self.audit_file):\n",
        "                with open(self.audit_file, 'rb') as f:\n",
        "                    try:\n",
        "                        last_line = f.readlines()[-1].strip()\n",
        "                        prev_event_id = last_line.split()[1].decode()\n",
        "                    except IndexError:\n",
        "                        pass  # If audit file is empty\n",
        "\n",
        "            # <Issue>: Chain formula should be sha256(prev_event_id || record_json), but code uses json.dumps(record) again (may differ) and mismatches verify().\n",
        "            chain_hash = hashlib.sha256((prev_event_id + json.dumps(record)).encode()).digest()\n",
        "            self._write_atomic(self.audit_file, f\"{base64.urlsafe_b64encode(chain_hash).decode()} {event_id}\\n\")\n",
        "\n",
        "            self._rotate_events_if_needed()\n",
        "\n",
        "        return event_id\n",
        "\n",
        "    def _write_atomic(self, file_path: str, content: str) -> None:\n",
        "        \"\"\"Write content to a file atomically.\"\"\"\n",
        "        # <Issue>: This function writes only *content*, discarding all existing lines instead of appending.\n",
        "        with tempfile.NamedTemporaryFile('w', delete=False, dir=self.root_dir) as temp_file:\n",
        "            temp_file.write(content)\n",
        "            temp_path = temp_file.name\n",
        "        os.replace(temp_path, file_path)\n",
        "\n",
        "    def _rotate_events_if_needed(self) -> None:\n",
        "        \"\"\"Rotate the events file if its size exceeds the maximum limit.\"\"\"\n",
        "        if os.path.getsize(self.events_file) > MAX_EVENTS_FILE_SIZE:\n",
        "            timestamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "            new_name = f'events-{timestamp}.jsonl'\n",
        "            os.rename(self.events_file, os.path.join(self.root_dir, new_name))  # <Issue>: Does not create a fresh empty events.jsonl after rotation.\n",
        "\n",
        "    def verify(self) -> bool:\n",
        "        \"\"\"Verify the integrity of the audit log.\"\"\"\n",
        "        if not os.path.exists(self.audit_file):\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            with open(self.audit_file, 'r') as f:\n",
        "                prev_event_id = \"0\" * 64\n",
        "                for line in f:\n",
        "                    chain_hash_encoded, event_id = line.strip().split()\n",
        "                    expected_chain_hash = hashlib.sha256((prev_event_id + event_id).encode()).digest()  # <Issue>: Should hash prev_event_id || event_json, not event_id.\n",
        "                    if base64.urlsafe_b64encode(expected_chain_hash).decode() != chain_hash_encoded:\n",
        "                        return False\n",
        "                    prev_event_id = event_id\n",
        "        except Exception:\n",
        "            return False  # <Issue>: Broad except hides bugs; should log or re‑raise specific errors.\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "class WebhookRequestHandler(BaseHTTPRequestHandler):\n",
        "    def __init__(self, *args, root_dir=None, logger: EventLogger = None, **kwargs):\n",
        "        self.root_dir = root_dir\n",
        "        self.logger = logger\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def do_POST(self):\n",
        "        if self.path != '/webhook':\n",
        "            self.send_error(404, 'Not Found', '{\"error\":\"Path not found\"}')  # <Issue>: send_error returns HTML by default; custom body may be ignored.\n",
        "            return\n",
        "\n",
        "        content_length = self.headers.get('Content-Length')\n",
        "        if content_length is None:\n",
        "            self.send_error(411, 'Length Required', '{\"error\":\"Content-Length header is required\"}')\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            content_length = int(content_length)\n",
        "            if content_length > MAX_CONTENT_LENGTH:\n",
        "                self.send_error(413, 'Payload Too Large', '{\"error\":\"Payload too large\"}')\n",
        "                return\n",
        "        except ValueError:\n",
        "            self.send_error(411, 'Length Required', '{\"error\":\"Content-Length header is invalid\"}')\n",
        "            return\n",
        "\n",
        "        content_type = self.headers.get('Content-Type')\n",
        "        if content_type != 'application/json':  # <Issue>: Rejects valid 'application/json; charset=utf-8'.\n",
        "            self.send_error(415, 'Unsupported Media Type', '{\"error\":\"Content-Type must be application/json\"}')\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            post_data = self.rfile.read(content_length)\n",
        "            if b'\\r' in post_data or b'\\n' in post_data:\n",
        "                raise ValueError(\"Control character in body\")\n",
        "            payload = json.loads(post_data.decode('utf-8'))\n",
        "        except (json.JSONDecodeError, UnicodeDecodeError, ValueError):\n",
        "            self.send_error(400, 'Bad Request', '{\"error\":\"Invalid JSON or UTF-8 encoding\"}')\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            event_id = self.logger.append(payload)\n",
        "            self.send_response(200)\n",
        "            self.send_header('Content-Type', 'application/json')\n",
        "            self.end_headers()\n",
        "            self.wfile.write(json.dumps({'status': 'ok', 'id': event_id}).encode('utf-8'))\n",
        "        except (TypeError, ValueError) as e:\n",
        "            self.send_error(422, 'Unprocessable Entity', f'{{\"error\":\"{str(e)}\"}}')\n",
        "\n",
        "    def log_message(self, format, *args):\n",
        "        # Override to prevent default stdout logging\n",
        "        return  # <Issue>: Good – suppresses noisy server logs.\n",
        "\n",
        "\n",
        "def run_server(root_dir, host='0.0.0.0', port=8000):\n",
        "    logger = EventLogger(root_dir)\n",
        "\n",
        "    def handler(*args, **kwargs):\n",
        "        WebhookRequestHandler(*args, root_dir=root_dir, logger=logger, **kwargs)\n",
        "\n",
        "    httpd = HTTPServer((host, port), handler)\n",
        "    print(f\"Starting server on {host}:{port}\")\n",
        "    try:\n",
        "        httpd.serve_forever()\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    finally:\n",
        "        httpd.server_close()\n",
        "        print(\"Server stopped.\")\n",
        "\n",
        "\n",
        "def cli():\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Webhook Event Logger\")\n",
        "    subparsers = parser.add_subparsers(dest='command', help='sub-command help')\n",
        "\n",
        "    serve_parser = subparsers.add_parser('serve', help='Start the HTTP server')\n",
        "    serve_parser.add_argument('--root', required=True, help='Root directory for event logs')\n",
        "    serve_parser.add_argument('--host', default='0.0.0.0', help='Host to run the server on')\n",
        "    serve_parser.add_argument('--port', type=int, default=8000, help='Port to run the server on')\n",
        "\n",
        "    verify_parser = subparsers.add_parser('verify', help='Verify the audit log')\n",
        "    verify_parser.add_argument('--root', required=True, help='Root directory for event logs')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.command == 'serve':\n",
        "        run_server(root_dir=args.root, host=args.host, port=args.port)\n",
        "    elif args.command == 'verify':\n",
        "        logger = EventLogger(args.root)\n",
        "        result = logger.verify()\n",
        "        if result:\n",
        "            print(\"Audit log OK\")\n",
        "        else:\n",
        "            print(\"Audit log tampered\")\n",
        "        exit(0 if result else 1)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cli()\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
