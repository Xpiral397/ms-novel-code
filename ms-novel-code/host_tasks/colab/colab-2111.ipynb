{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - Security\n",
        "\n",
        "**L2 Taxonomy** - Authorization\n",
        "\n",
        "**Subtopic** - Implementing resource ownership checks (user can only modify their own resources) at the service layer\n",
        "\n",
        "**Use Case** - Develop a Python module that simulates a service layer for a simple file-based resource system. The module should include functions for creating, reading, updating, and deleting resources, represented as files within a local directory. Each resource should be owned by a user, and the module should enforce that a user can only modify their own resources. The system should be able to handle multiple users, each with their own set of resources.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - o1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "\n",
        "\n",
        "### Prompt\n",
        "\n",
        "**Problem Description**\n",
        "Implement a module named `ResourceService` that keeps every user’s text resources inside a single JSON file: `<root>/<user_id>.json`.\n",
        "Each resource holds a list of immutable revisions, and every write appends a new revision.\n",
        "The module must\n",
        "\n",
        "* guarantee that only the owner can change or delete a resource,\n",
        "* maintain a tamper‑evident audit log (`audit.log`) with a SHA‑256 hash chain,\n",
        "* stay correct when ten‑thousand concurrent threads perform mixed operations,\n",
        "* reject path‑traversal attacks or symlink tricks that attempt to escape `<root>`.\n",
        "\n",
        "**Input Format and Constraints**\n",
        "\n",
        "* `user_id` – non‑empty string, no path separators, case‑sensitive.\n",
        "* `resource_name` – non‑empty UTF‑8, ends with “.txt”, no path separators, normalised with NFC, ≤ 255 bytes after normalisation, unique for a user when compared case‑insensitively after normalisation.\n",
        "* `revision_id` – a hex string returned by this service; callers must not invent one.\n",
        "* `content` – arbitrary UTF‑8 text.\n",
        "  Validation is required; wrong inputs raise the exceptions listed under Edge‑case Behaviour.\n",
        "\n",
        "**Expected Output Format**\n",
        "All public methods return Python primitives (str, list, dict, or None) or raise a documented exception.\n",
        "They must not print or log to stdout/stderr.\n",
        "\n",
        "**Illustrative Example**\n",
        "\n",
        "```\n",
        "svc = ResourceService(\"./data\")\n",
        "\n",
        "rev1 = svc.create_resource(\"alice\", \"note.txt\", \"first\")\n",
        "rev2 = svc.update_resource(\"alice\", \"note.txt\", \"second\")\n",
        "\n",
        "latest = svc.read_resource(\"alice\", \"note.txt\")          # \"second\"\n",
        "older  = svc.read_resource(\"alice\", \"note.txt\", rev1)    # \"first\"\n",
        "\n",
        "history = svc.list_revisions(\"alice\", \"note.txt\")        # [rev1, rev2]\n",
        "ok = svc.verify_audit_log()                              # True\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "\n",
        "\n",
        "### Requirements\n",
        "\n",
        "**Explicit and Implicit Points**\n",
        "\n",
        "* Each user file is a JSON object mapping normalised slugs to a list of revision records: `{\"slug\": [{\"id\": \"...\", \"content\": \"...\"} , ...]}`.\n",
        "* `create_resource` fails if any revision exists for that slug.\n",
        "* Each update appends a new revision and returns its `revision_id`.\n",
        "* All writes go through a temp file followed by `os.replace` for crash‑safety.\n",
        "* Use a per‑user lock file (e.g. `<user_id>.lock`) to give writers exclusive access; readers spin until the lock disappears (timeout 200 ms).\n",
        "* Append every successful public operation to `audit.log` as one JSON line containing a SHA‑256 hash of the previous line plus the current event.\n",
        "* The service must detect any break in the hash chain: `verify_audit_log()` returns `False` if tampering is found.\n",
        "* Resolve real paths after each file action; abort if the resolved path leaves `<root>`.\n",
        "\n",
        "**Solution Expectations**\n",
        "\n",
        "* Standard library only, Python 3.10+.\n",
        "* Pass a stress test: 500 threads × 20 adversarial operations within two seconds wall time on a 32‑core machine.\n",
        "* Deterministic behaviour; no reliance on `time.sleep`–based randomness.\n",
        "\n",
        "**Signatures of Expected Functions**\n",
        "\n",
        "```python\n",
        "class ResourceService:\n",
        "    def __init__(self, root_dir: str) -> None: ...\n",
        "    def create_resource(self, user_id: str, resource_name: str, content: str) -> str: ...\n",
        "    def read_resource(\n",
        "        self,\n",
        "        user_id: str,\n",
        "        resource_name: str,\n",
        "        revision_id: str | None = None\n",
        "    ) -> str: ...\n",
        "    def update_resource(\n",
        "        self,\n",
        "        user_id: str,\n",
        "        resource_name: str,\n",
        "        new_content: str\n",
        "    ) -> str: ...\n",
        "    def delete_resource(self, user_id: str, resource_name: str) -> None: ...\n",
        "    def list_resources(self, user_id: str) -> list[str]: ...\n",
        "    def list_revisions(self, user_id: str, resource_name: str) -> list[str]: ...\n",
        "    def verify_audit_log(self) -> bool: ...\n",
        "```\n",
        "\n",
        "**Edge‑case Behaviour**\n",
        "• Bad `user_id` or `resource_name` – raise `ValueError`.\n",
        "• Duplicate resource creation – raise `FileExistsError`.\n",
        "• Missing resource on read, update, delete, or list\\_revisions – raise `FileNotFoundError`.\n",
        "• Attempt to access a path outside `<root>` or via symlink – raise `PermissionError`.\n",
        "• Lock acquisition exceeds 200 ms – raise `TimeoutError`.\n",
        "• `verify_audit_log()` returns `False` (no exception) if the hash chain is broken.\n",
        "\n",
        "**Constraints**\n",
        "\n",
        "* No third‑party libraries.\n",
        "* Never call `subprocess`, `os.system`, or similar.\n",
        "* Aim for roughly constant‑time filesystem work per public call (ignoring unavoidable JSON parsing).\n",
        "* All cryptographic hashes must use `hashlib.sha256`.\n",
        "\n",
        "**Important Notes**\n",
        "All constraints are enforced during testing. The harness feeds invalid inputs, Unicode collision attempts, concurrent symlink races, and deliberate audit‑log edits. Your code must raise exactly the exceptions listed above or return the specified values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import secrets\n",
        "import hashlib\n",
        "import unicodedata\n",
        "from contextlib import contextmanager\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "\n",
        "class ResourceService:\n",
        "    def __init__(self, root_dir: str) -> None:\n",
        "        self.root = os.path.abspath(root_dir)\n",
        "        os.makedirs(self.root, exist_ok=True)\n",
        "        self.audit_path = os.path.join(self.root, \"audit.log\")\n",
        "        self.audit_lock = os.path.join(self.root, \"audit.lock\")\n",
        "\n",
        "    # ------------------------------------------------------------------ public\n",
        "\n",
        "    def create_resource(\n",
        "        self, user_id: str, resource_name: str, content: str\n",
        "    ) -> str:\n",
        "        uid = self._check_user_id(user_id)\n",
        "        name = self._check_resource_name(resource_name)\n",
        "        slug = name.casefold()\n",
        "\n",
        "        with self._user_lock(uid):\n",
        "            data = self._read_user_json(uid)\n",
        "            if slug in data:\n",
        "                raise FileExistsError(\n",
        "                    f\"{resource_name!r} exists for user {uid!r}\"\n",
        "                )\n",
        "            rev = secrets.token_hex(16)\n",
        "            data[slug] = {\"name\": name, \"revs\": [{\"id\": rev, \"text\": content}]}\n",
        "            self._write_user_json(uid, data)\n",
        "        # ── critical section ended ──\n",
        "        self._log_event(\n",
        "            {\"action\": \"create\", \"user\": uid, \"resource\": name, \"rev\": rev}\n",
        "        )\n",
        "        return rev\n",
        "\n",
        "    def read_resource(\n",
        "        self,\n",
        "        user_id: str,\n",
        "        resource_name: str,\n",
        "        revision_id: Optional[str] = None\n",
        "    ) -> str:\n",
        "        uid = self._check_user_id(user_id)\n",
        "        name = self._check_resource_name(resource_name)\n",
        "        slug = name.casefold()\n",
        "\n",
        "        self._wait_unlock(uid)\n",
        "        data = self._read_user_json(uid)\n",
        "        if slug not in data:\n",
        "            raise FileNotFoundError(\n",
        "                f\"{resource_name!r} not found for user {uid!r}\"\n",
        "            )\n",
        "        revs = data[slug][\"revs\"]\n",
        "        if revision_id is None:\n",
        "            return revs[-1][\"text\"]\n",
        "        for r in revs:\n",
        "            if r[\"id\"] == revision_id:\n",
        "                return r[\"text\"]\n",
        "        raise FileNotFoundError(\n",
        "            f\"Revision {revision_id!r} not found for {resource_name!r}\"\n",
        "        )\n",
        "\n",
        "    def update_resource(\n",
        "        self, user_id: str, resource_name: str, new_content: str\n",
        "    ) -> str:\n",
        "        uid = self._check_user_id(user_id)\n",
        "        name = self._check_resource_name(resource_name)\n",
        "        slug = name.casefold()\n",
        "\n",
        "        with self._user_lock(uid):\n",
        "            data = self._read_user_json(uid)\n",
        "            if slug not in data:\n",
        "                raise FileNotFoundError(\n",
        "                    f\"{resource_name!r} not found for user {uid!r}\"\n",
        "                )\n",
        "            rev = secrets.token_hex(16)\n",
        "            data[slug][\"revs\"].append({\"id\": rev, \"text\": new_content})\n",
        "            self._write_user_json(uid, data)\n",
        "        # ── critical section ended ──\n",
        "        self._log_event(\n",
        "            {\"action\": \"update\", \"user\": uid, \"resource\": name, \"rev\": rev}\n",
        "        )\n",
        "        return rev\n",
        "\n",
        "    def delete_resource(self, user_id: str, resource_name: str) -> None:\n",
        "        uid = self._check_user_id(user_id)\n",
        "        name = self._check_resource_name(resource_name)\n",
        "        slug = name.casefold()\n",
        "\n",
        "        with self._user_lock(uid):\n",
        "            data = self._read_user_json(uid)\n",
        "            if slug not in data:\n",
        "                raise FileNotFoundError(\n",
        "                    f\"{resource_name!r} not found for user {uid!r}\"\n",
        "                )\n",
        "            del data[slug]\n",
        "            self._write_user_json(uid, data)\n",
        "        # ── critical section ended ──\n",
        "        self._log_event(\n",
        "            {\"action\": \"delete\", \"user\": uid, \"resource\": name}\n",
        "        )\n",
        "\n",
        "    def list_resources(self, user_id: str) -> List[str]:\n",
        "        uid = self._check_user_id(user_id)\n",
        "        self._wait_unlock(uid)\n",
        "        data = self._read_user_json(uid)\n",
        "        return [info[\"name\"] for info in data.values()]\n",
        "\n",
        "    def list_revisions(\n",
        "        self, user_id: str, resource_name: str\n",
        "    ) -> List[str]:\n",
        "        uid = self._check_user_id(user_id)\n",
        "        name = self._check_resource_name(resource_name)\n",
        "        slug = name.casefold()\n",
        "\n",
        "        self._wait_unlock(uid)\n",
        "        data = self._read_user_json(uid)\n",
        "        if slug not in data:\n",
        "            raise FileNotFoundError(\n",
        "                f\"{resource_name!r} not found for user {uid!r}\"\n",
        "            )\n",
        "        return [r[\"id\"] for r in data[slug][\"revs\"]]\n",
        "\n",
        "    def verify_audit_log(self) -> bool:\n",
        "        if not os.path.exists(self.audit_path):\n",
        "            return True\n",
        "        prev = \"\"\n",
        "        try:\n",
        "            with open(self.audit_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                for raw in f:\n",
        "                    entry = json.loads(raw)\n",
        "                    expected = hashlib.sha256(\n",
        "                        (prev + json.dumps(entry[\"event\"],\n",
        "                                           sort_keys=True)).encode()\n",
        "                    ).hexdigest()\n",
        "                    if entry.get(\"hash\") != expected:\n",
        "                        return False\n",
        "                    prev = raw.rstrip(\"\\n\")\n",
        "        except Exception:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    # ----------------------------------------------------------------- helpers\n",
        "\n",
        "    def _check_user_id(self, uid: str) -> str:\n",
        "        if not uid or os.sep in uid:\n",
        "            raise ValueError(\"Invalid user_id\")\n",
        "        path = os.path.realpath(os.path.join(self.root, f\"{uid}.json\"))\n",
        "        if not path.startswith(self.root + os.sep):\n",
        "            raise PermissionError(\"Path escape\")\n",
        "        return uid\n",
        "\n",
        "    def _check_resource_name(self, name: str) -> str:\n",
        "        # accept any case “.txt”, forbid path separators\n",
        "        if (\n",
        "            not name\n",
        "            or \"/\" in name\n",
        "            or \"\\\\\" in name\n",
        "            or not name.lower().endswith(\".txt\")\n",
        "        ):\n",
        "            raise ValueError(\"Invalid resource_name\")\n",
        "        norm = unicodedata.normalize(\"NFC\", name)\n",
        "        if len(norm.encode(\"utf-8\")) > 255:\n",
        "            raise ValueError(\"Name too long\")\n",
        "        return norm\n",
        "\n",
        "    def _read_user_json(self, uid: str) -> Dict[str, Any]:\n",
        "        path = os.path.join(self.root, f\"{uid}.json\")\n",
        "        if not os.path.exists(path):\n",
        "            return {}\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def _write_user_json(self, uid: str, data: Dict[str, Any]) -> None:\n",
        "        path = os.path.join(self.root, f\"{uid}.json\")\n",
        "        tmp = path + \".tmp\"\n",
        "        with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(data, f, ensure_ascii=False)\n",
        "        os.replace(tmp, path)\n",
        "\n",
        "    def _wait_unlock(self, uid: str, timeout: float = 0.2) -> None:\n",
        "        lock = os.path.join(self.root, f\"{uid}.lock\")\n",
        "        start = time.monotonic()\n",
        "        while os.path.exists(lock):\n",
        "            if time.monotonic() - start > timeout:\n",
        "                raise TimeoutError(\"Lock wait timed out\")\n",
        "            time.sleep(0.001)\n",
        "\n",
        "    @contextmanager\n",
        "    def _user_lock(self, uid: str, timeout: float = 0.2):\n",
        "        lock = os.path.join(self.root, f\"{uid}.lock\")\n",
        "        start = time.monotonic()\n",
        "        while True:\n",
        "            try:\n",
        "                fd = os.open(lock, os.O_CREAT | os.O_EXCL | os.O_WRONLY)\n",
        "                os.close(fd)\n",
        "                break\n",
        "            except FileExistsError:\n",
        "                if time.monotonic() - start > timeout:\n",
        "                    raise TimeoutError(\"Could not acquire user lock\")\n",
        "                time.sleep(0.001)\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            try:\n",
        "                os.remove(lock)\n",
        "            except OSError:\n",
        "                pass\n",
        "\n",
        "    def _log_event(self, event: dict) -> None:\n",
        "        start = time.monotonic()\n",
        "        while True:\n",
        "            try:\n",
        "                fd = os.open(\n",
        "                    self.audit_lock, os.O_CREAT | os.O_EXCL | os.O_WRONLY\n",
        "                )\n",
        "                os.close(fd)\n",
        "                break\n",
        "            except FileExistsError:\n",
        "                if time.monotonic() - start > 0.2:\n",
        "                    raise TimeoutError(\"Audit lock timeout\")\n",
        "                time.sleep(0.001)\n",
        "\n",
        "        prev_line = \"\"\n",
        "        if os.path.exists(self.audit_path):\n",
        "            with open(self.audit_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                lines = f.read().splitlines()\n",
        "                if lines:\n",
        "                    prev_line = lines[-1]\n",
        "\n",
        "        payload = json.dumps(event, sort_keys=True)\n",
        "        h = hashlib.sha256((prev_line + payload).encode()).hexdigest()\n",
        "        record = {\"hash\": h, \"event\": event}\n",
        "        line = json.dumps(record, ensure_ascii=False)\n",
        "\n",
        "        with open(self.audit_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "        try:\n",
        "            os.remove(self.audit_lock)\n",
        "        except OSError:\n",
        "            pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import threading\n",
        "import tempfile\n",
        "import unittest\n",
        "from pathlib import Path\n",
        "\n",
        "# The implementation to be tested must live in main.py\n",
        "from main import ResourceService\n",
        "\n",
        "\n",
        "# ---------- helpers ---------- #\n",
        "\n",
        "def new_service():\n",
        "    \"\"\"Return a fresh ResourceService rooted in a brand‑new temp dir\n",
        "    and the pathlib.Path object for that directory.\"\"\"\n",
        "    tmpdir = tempfile.TemporaryDirectory()\n",
        "    root = Path(tmpdir.name)\n",
        "    return ResourceService(str(root)), root, tmpdir\n",
        "\n",
        "\n",
        "def read_audit(root: Path) -> list[dict]:\n",
        "    \"\"\"Return audit.log lines already parsed as JSON.\"\"\"\n",
        "    log_file = root / \"audit.log\"\n",
        "    if not log_file.exists():\n",
        "        return []\n",
        "    return [json.loads(l) for l in log_file.read_text().splitlines()]\n",
        "\n",
        "\n",
        "# ---------- test‑cases ---------- #\n",
        "\n",
        "class ResourceServiceBasics(unittest.TestCase):\n",
        "    def setUp(self) -> None:\n",
        "        self.svc, self.root, self._tmp = new_service()\n",
        "\n",
        "    def tearDown(self) -> None:\n",
        "        # Ensure tempdir is cleaned even if the test fails.\n",
        "        self._tmp.cleanup()\n",
        "\n",
        "    # ----- normal workflow ----- #\n",
        "    def test_create_read_update_delete_cycle(self):\n",
        "        rid1 = self.svc.create_resource(\"alice\", \"note.txt\", \"first\")\n",
        "        self.assertIsInstance(rid1, str)\n",
        "        self.assertEqual(self.svc.read_resource(\"alice\", \"note.txt\"), \"first\")\n",
        "\n",
        "        rid2 = self.svc.update_resource(\"alice\", \"note.txt\", \"second\")\n",
        "        self.assertNotEqual(rid1, rid2)\n",
        "        self.assertEqual(self.svc.read_resource(\"alice\", \"note.txt\"), \"second\")\n",
        "        self.assertEqual(self.svc.read_resource(\"alice\", \"note.txt\", rid1), \"first\")\n",
        "\n",
        "        revs = self.svc.list_revisions(\"alice\", \"note.txt\")\n",
        "        self.assertEqual(revs, [rid1, rid2])\n",
        "\n",
        "        resources = self.svc.list_resources(\"alice\")\n",
        "        self.assertEqual(resources, [\"note.txt\"])\n",
        "\n",
        "        # audit log must verify\n",
        "        self.assertTrue(self.svc.verify_audit_log())\n",
        "\n",
        "        # delete and ensure it is gone\n",
        "        self.svc.delete_resource(\"alice\", \"note.txt\")\n",
        "        with self.assertRaises(FileNotFoundError):\n",
        "            self.svc.read_resource(\"alice\", \"note.txt\")\n",
        "\n",
        "    # ----- duplicate and case‑insensitive slug clash ----- #\n",
        "    def test_duplicate_resource_raises(self):\n",
        "        self.svc.create_resource(\"alice\", \"Hello.txt\", \"a\")\n",
        "        with self.assertRaises(FileExistsError):\n",
        "            self.svc.create_resource(\"alice\", \"hELLo.TXT\", \"b\")\n",
        "\n",
        "    # ----- edge‑case: bad inputs ----- #\n",
        "    def test_invalid_user_and_resource_names(self):\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.svc.create_resource(\"al/ice\", \"note.txt\", \"x\")          # slash inside user\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.svc.create_resource(\"bob\", \"note\", \"x\")                 # missing .txt\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.svc.create_resource(\"bob\", \"../note.txt\", \"x\")          # traversal chars\n",
        "        long_name = \"a\" * 260 + \".txt\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.svc.create_resource(\"bob\", long_name, \"x\")\n",
        "\n",
        "    # ----- missing resource operations ----- #\n",
        "    def test_missing_resource_errors(self):\n",
        "        with self.assertRaises(FileNotFoundError):\n",
        "            self.svc.read_resource(\"nobody\", \"ghost.txt\")\n",
        "        with self.assertRaises(FileNotFoundError):\n",
        "            self.svc.update_resource(\"nobody\", \"ghost.txt\", \"boo\")\n",
        "        with self.assertRaises(FileNotFoundError):\n",
        "            self.svc.delete_resource(\"nobody\", \"ghost.txt\")\n",
        "        with self.assertRaises(FileNotFoundError):\n",
        "            self.svc.list_revisions(\"nobody\", \"ghost.txt\")\n",
        "\n",
        "    # ----- path‑traversal / symlink attack ----- #\n",
        "    def test_symlink_escape_prevention(self):\n",
        "        # Forge a symlink inside <root> that points outside\n",
        "        outside = Path(tempfile.gettempdir()) / \"evil.json\"\n",
        "        outside.write_text(\"{}\")\n",
        "        (self.root / \"bob.json\").symlink_to(outside)\n",
        "        with self.assertRaises(PermissionError):\n",
        "            self.svc.create_resource(\"bob\", \"note.txt\", \"should fail\")\n",
        "\n",
        "    # ----- audit‑log tamper detection ----- #\n",
        "    def test_audit_log_tampering_detected(self):\n",
        "        self.svc.create_resource(\"alice\", \"note.txt\", \"hi\")\n",
        "        self.assertTrue(self.svc.verify_audit_log())      # baseline OK\n",
        "\n",
        "        # Break the hash chain: flip one bit in the 2nd char of 2nd line\n",
        "        log_file = self.root / \"audit.log\"\n",
        "        lines = log_file.read_bytes().splitlines()\n",
        "        if len(lines) < 2:   # paranoia guard\n",
        "            self.skipTest(\"need at least two lines to tamper\")\n",
        "        tampered = bytearray(lines[1])\n",
        "        tampered[2] ^= 0x01\n",
        "        lines[1] = bytes(tampered)\n",
        "        log_file.write_bytes(b\"\\n\".join(lines))\n",
        "\n",
        "        self.assertFalse(self.svc.verify_audit_log())\n",
        "\n",
        "    # ----- concurrent access with per‑user locking ----- #\n",
        "    def test_concurrent_updates_consistent(self):\n",
        "        rid0 = self.svc.create_resource(\"alice\", \"note.txt\", \"v0\")\n",
        "\n",
        "        # 20 threads each append one revision\n",
        "        def worker(i):\n",
        "            self.svc.update_resource(\"alice\", \"note.txt\", f\"v{i}\")\n",
        "\n",
        "        threads = [threading.Thread(target=worker, args=(i,)) for i in range(20)]\n",
        "        for t in threads:\n",
        "            t.start()\n",
        "        for t in threads:\n",
        "            t.join()\n",
        "\n",
        "        revs = self.svc.list_revisions(\"alice\", \"note.txt\")\n",
        "        # initial + 20 updates\n",
        "        self.assertEqual(len(revs), 1 + 20)\n",
        "        self.assertEqual(self.svc.read_resource(\"alice\", \"note.txt\"), \"v19\")\n",
        "        self.assertTrue(self.svc.verify_audit_log())\n",
        "\n",
        "\n",
        "# Run the tests when executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(verbosity=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/97dbf10b-6433-4ec6-a524-1e9f0c692a26?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F80889%2Fview\n",
        "\n",
        "```python\n",
        "def create_resource(self, user_id: str, resource_name: str, content: str) -> str:\n",
        "    user_id = self._validate_user_id(user_id)\n",
        "    normalized_name = self._validate_resource_name(resource_name)\n",
        "    slug = self._slugify(normalized_name)\n",
        "\n",
        "    # Acquire writer lock\n",
        "    with self._acquire_user_lock(user_id):\n",
        "        user_data = self._load_user_data(user_id)\n",
        "\n",
        "        if slug in user_data:\n",
        "            # Resource already exists\n",
        "            raise FileExistsError(f\"Resource {resource_name!r} already exists for user {user_id!r}.\")\n",
        "\n",
        "        # Create the new resource’s revision list\n",
        "        rev_id = self._generate_revision_id()\n",
        "        user_data[slug] = {\n",
        "            \"name\": normalized_name,  # store the canonical name\n",
        "            \"revisions\": [\n",
        "                {\n",
        "                    \"id\": rev_id,\n",
        "                    \"content\": content\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self._write_user_data(user_id, user_data)\n",
        "        # Append operation to audit log\n",
        "        self._append_audit_log({\n",
        "            \"op\": \"create_resource\",\n",
        "            \"user_id\": user_id,\n",
        "            \"resource_name\": resource_name,\n",
        "            \"revision_id\": rev_id\n",
        "        })\n",
        "        return rev_id\n",
        "\n",
        "def read_resource(\n",
        "    self,\n",
        "    user_id: str,\n",
        "    resource_name: str,\n",
        "    revision_id: Optional[str] = None\n",
        ") -> str:\n",
        "    user_id = self._validate_user_id(user_id)\n",
        "    normalized_name = self._validate_resource_name(resource_name)\n",
        "    slug = self._slugify(normalized_name)\n",
        "\n",
        "    # Readers spin until lock disappears (or 200ms passes)\n",
        "    self._wait_for_lock_to_disappear(user_id)\n",
        "\n",
        "    user_data = self._load_user_data(user_id)\n",
        "    if slug not in user_data:\n",
        "        raise FileNotFoundError(f\"Resource {resource_name!r} not found for user {user_id!r}.\")\n",
        "\n",
        "    rev_list = user_data[slug][\"revisions\"]\n",
        "    if revision_id is None:\n",
        "        # Return last revision’s content\n",
        "        content = rev_list[-1][\"content\"]\n",
        "    else:\n",
        "        for rev in rev_list:\n",
        "            if rev[\"id\"] == revision_id:\n",
        "                content = rev[\"content\"]\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Revision {revision_id!r} not found for resource {resource_name!r}.\")\n",
        "    # <Issue>: Missing audit log entry for successful read (spec: log every successful public operation)\n",
        "    return content\n",
        "\n",
        "def update_resource(\n",
        "    self,\n",
        "    user_id: str,\n",
        "    resource_name: str,\n",
        "    new_content: str\n",
        ") -> str:\n",
        "    user_id = self._validate_user_id(user_id)\n",
        "    normalized_name = self._validate_resource_name(resource_name)\n",
        "    slug = self._slugify(normalized_name)\n",
        "\n",
        "    # Acquire writer lock\n",
        "    with self._acquire_user_lock(user_id):\n",
        "        user_data = self._load_user_data(user_id)\n",
        "        if slug not in user_data:\n",
        "            raise FileNotFoundError(f\"Resource {resource_name!r} not found for user {user_id!r}.\")\n",
        "\n",
        "        rev_id = self._generate_revision_id()\n",
        "        user_data[slug][\"revisions\"].append({\n",
        "            \"id\": rev_id,\n",
        "            \"content\": new_content\n",
        "        })\n",
        "\n",
        "        self._write_user_data(user_id, user_data)\n",
        "        self._append_audit_log({\n",
        "            \"op\": \"update_resource\",\n",
        "            \"user_id\": user_id,\n",
        "            \"resource_name\": resource_name,\n",
        "            \"revision_id\": rev_id\n",
        "        })\n",
        "        return rev_id\n",
        "\n",
        "def delete_resource(self, user_id: str, resource_name: str) -> None:\n",
        "    user_id = self._validate_user_id(user_id)\n",
        "    normalized_name = self._validate_resource_name(resource_name)\n",
        "    slug = self._slugify(normalized_name)\n",
        "\n",
        "    # Acquire writer lock\n",
        "    with self._acquire_user_lock(user_id):\n",
        "        user_data = self._load_user_data(user_id)\n",
        "        if slug not in user_data:\n",
        "            raise FileNotFoundError(f\"Resource {resource_name!r} not found for user {user_id!r}.\")\n",
        "        del user_data[slug]\n",
        "\n",
        "        self._write_user_data(user_id, user_data)\n",
        "        self._append_audit_log({\n",
        "            \"op\": \"delete_resource\",\n",
        "            \"user_id\": user_id,\n",
        "            \"resource_name\": resource_name\n",
        "        })\n",
        "\n",
        "def list_resources(self, user_id: str) -> list[str]:\n",
        "    user_id = self._validate_user_id(user_id)\n",
        "    self._wait_for_lock_to_disappear(user_id)\n",
        "\n",
        "    user_data = self._load_user_data(user_id)\n",
        "    names = [info[\"name\"] for info in user_data.values()]\n",
        "    # <Issue>: Missing audit log entry for successful list_resources (spec: log every successful public operation)\n",
        "    return names\n",
        "\n",
        "def list_revisions(self, user_id: str, resource_name: str) -> list[str]:\n",
        "    user_id = self._validate_user_id(user_id)\n",
        "    normalized_name = self._validate_resource_name(resource_name)\n",
        "    slug = self._slugify(normalized_name)\n",
        "\n",
        "    self._wait_for_lock_to_disappear(user_id)\n",
        "\n",
        "    user_data = self._load_user_data(user_id)\n",
        "    if slug not in user_data:\n",
        "        raise FileNotFoundError(f\"Resource {resource_name!r} not found for user {user_id!r}.\")\n",
        "\n",
        "    rev_list = user_data[slug][\"revisions\"]\n",
        "    ids = [r[\"id\"] for r in rev_list]\n",
        "    # <Issue>: Missing audit log entry for successful list_revisions (spec: log every successful public operation)\n",
        "    return ids\n",
        "\n",
        "def verify_audit_log(self) -> bool:\n",
        "    \"\"\"\n",
        "    Returns False if the hash chain is broken anywhere, True otherwise.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(self.audit_log_path):\n",
        "        return True  # No audit log => trivially valid\n",
        "\n",
        "    try:\n",
        "        with open(self.audit_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = f.read().splitlines()\n",
        "    except OSError:\n",
        "        # If we can’t read the log for some reason, treat as broken chain\n",
        "        return False\n",
        "\n",
        "    prev_line_raw = \"\"\n",
        "    for line in lines:\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            stored_hash = record[\"sha256\"]\n",
        "            event_obj = record[\"event\"]\n",
        "        except (KeyError, json.JSONDecodeError, TypeError):\n",
        "            return False\n",
        "\n",
        "        recomputed = hashlib.sha256(\n",
        "            (prev_line_raw + json.dumps(event_obj, sort_keys=True)).encode(\"utf-8\")\n",
        "        ).hexdigest()\n",
        "\n",
        "        if recomputed != stored_hash:\n",
        "            return False\n",
        "        prev_line_raw = line  # Next line’s \"previous\" is the entire raw line\n",
        "\n",
        "   #  <Issue>: verify_audit_log (a public operation) not appended to audit log (spec: log every successful public operation)\n",
        "    return True\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# Internal Helpers\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "def _slugify(self, resource_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Return a lowercased version for uniqueness checks:\n",
        "    Normalized name is guaranteed by _validate_resource_name.\n",
        "    \"\"\"\n",
        "    return resource_name.casefold()\n",
        "\n",
        "def _validate_user_id(self, user_id: str) -> str:\n",
        "    # Basic check for emptiness or path separators\n",
        "    if not user_id or \"/\" in user_id or \"\\\\\" in user_id:\n",
        "        raise ValueError(\"Invalid user_id.\")\n",
        "    # Real-path check\n",
        "    real = self._resolve_in_root(user_id + \".json\")\n",
        "    return user_id\n",
        "\n",
        "def _validate_resource_name(self, resource_name: str) -> str:\n",
        "    if not resource_name or \"/\" in resource_name or \"\\\\\" in resource_name:\n",
        "        raise ValueError(\"Invalid resource_name: path separators not allowed.\")\n",
        "    if not resource_name.endswith(\".txt\"):\n",
        "        raise ValueError(\"Invalid resource_name: must end with .txt.\")\n",
        "    nfc_name = unicodedata.normalize(\"NFC\", resource_name)\n",
        "    if len(nfc_name.encode(\"utf-8\")) > 255:\n",
        "        raise ValueError(\"Resource name too long after normalization.\")\n",
        "    return nfc_name\n",
        "\n",
        "def _generate_revision_id(self) -> str:\n",
        "    \"\"\"Generate a 32-hex-digit revision ID.\"\"\"\n",
        "    return secrets.token_hex(16)\n",
        "\n",
        "def _user_json_path(self, user_id: str) -> str:\n",
        "    return f\"{user_id}.json\"\n",
        "\n",
        "def _user_lock_path(self, user_id: str) -> str:\n",
        "    return f\"{user_id}.lock\"\n",
        "\n",
        "def _resolve_in_root(self, relative_path: str) -> str:\n",
        "    full = os.path.realpath(os.path.join(self.root_dir, relative_path))\n",
        "    if not full.startswith(self.root_dir + os.sep) and full != self.root_dir:\n",
        "        raise PermissionError(\"Attempted path escape or symlink trick.\")\n",
        "    return full\n",
        "\n",
        "def _load_user_data(self, user_id: str) -> dict:\n",
        "    path = self._resolve_in_root(self._user_json_path(user_id))\n",
        "    if not os.path.exists(path):\n",
        "        return {}\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        try:\n",
        "            return json.load(f)\n",
        "        except json.JSONDecodeError:\n",
        "            # <Issue>: Silently treating corrupt JSON as empty loses data & hides tampering (should raise to surface integrity issue)\n",
        "            return {}\n",
        "\n",
        "def _write_user_data(self, user_id: str, data: dict) -> None:\n",
        "    path = self._resolve_in_root(self._user_json_path(user_id))\n",
        "    tmp_path = path + \".tmp\"\n",
        "    with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False)\n",
        "    os.replace(tmp_path, path)\n",
        "\n",
        "def _append_audit_log(self, event: dict) -> None:\n",
        "    \"\"\"\n",
        "    Append a line to audit.log with a hash that chains from the previous record\n",
        "    and includes the current event.\n",
        "    \"\"\"\n",
        "    prev_line_raw = \"\"\n",
        "    if os.path.exists(self.audit_log_path):\n",
        "        try:\n",
        "            with open(self.audit_log_path, \"rb\") as f:\n",
        "                f.seek(0, os.SEEK_END)\n",
        "                fsize = f.tell()\n",
        "                pos = max(0, fsize - 1024)\n",
        "                f.seek(pos)\n",
        "                tail = f.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "                lines = tail.splitlines()\n",
        "                if lines:\n",
        "                    last_line = lines[-1]\n",
        "                    prev_line_raw = last_line\n",
        "        except OSError:\n",
        "            pass\n",
        "    # <Issue>: No audit wide lock — concurrent append can race causing hash chain divergence or interleaving\n",
        "    # <Issue>: Partial tail read (fixed 1024 bytes) risks missing the true last line for large log => hash chain invalid\n",
        "    event_json = json.dumps(event, sort_keys=True)\n",
        "    new_hash = hashlib.sha256((prev_line_raw + event_json).encode(\"utf-8\")).hexdigest()\n",
        "    record = {\n",
        "        \"sha256\": new_hash,\n",
        "        \"event\": event\n",
        "    }\n",
        "    line = json.dumps(record, ensure_ascii=False)\n",
        "    with open(self.audit_log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "def _wait_for_lock_to_disappear(self, user_id: str, timeout: float = 0.2) -> None:\n",
        "    lock_path = self._resolve_in_root(self._user_lock_path(user_id))\n",
        "    start = time.monotonic()\n",
        "    while os.path.exists(lock_path):\n",
        "        if time.monotonic() - start > timeout:\n",
        "            raise TimeoutError(\"Timeout waiting for lock to disappear.\")\n",
        "        time.sleep(0.001)\n",
        "\n",
        "from contextlib import contextmanager\n",
        "\n",
        "@contextmanager\n",
        "def _acquire_user_lock(self, user_id: str, timeout: float = 0.2):\n",
        "    lock_path = self._resolve_in_root(self._user_lock_path(user_id))\n",
        "    start = time.monotonic()\n",
        "    lock_acquired = False\n",
        "    while True:\n",
        "        try:\n",
        "            fd = os.open(lock_path, os.O_CREAT | os.O_EXCL | os.O_WRONLY, 0o644)\n",
        "            os.close(fd)\n",
        "            lock_acquired = True\n",
        "            break\n",
        "        except FileExistsError:\n",
        "            if time.monotonic() - start > timeout:\n",
        "                raise TimeoutError(\"Timeout acquiring user lock.\")\n",
        "            time.sleep(0.001)\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        if lock_acquired and os.path.exists(lock_path):\n",
        "            os.remove(lock_path)\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
