{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKe-t1pIOo2f"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**L1 Taxonomy** - SQL in Python\n",
        "\n",
        "**L2 Taxonomy** - Database Normalization\n",
        "\n",
        "**Subtopic** - Integrating Python Libraries for SQL Database Normalization\n",
        "\n",
        "**Use Case** - Implement a Python script using Pandas to normalize a denormalized CSV dataset into third normal form and export the results to SQL tables.\n",
        "\n",
        "**Programming Language** - Python\n",
        "\n",
        "**Target Model** - GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0xHSaZoEJO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "```requirements.txt\n",
        "pandas\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YToTLlRqOqmj"
      },
      "source": [
        "# Prompt\n",
        "\n",
        "## **Problem Overview**\n",
        "\n",
        "You are given a denormalized CSV file representing customer orders. However, instead of each product being on a separate row, each row may contain **multiple products encoded in a single field** using a custom format.\n",
        "\n",
        "Your task is to implement a Python program that **normalizes** this dataset into **Third Normal Form (3NF)** and exports it into a SQLite database. You must correctly:\n",
        "\n",
        "* Parse and normalize multiple products per order row,\n",
        "* Assign stable, deduplicated primary keys for customers and products,\n",
        "* Maintain foreign key integrity in the resulting normalized schema.\n",
        "\n",
        "This problem simulates real-world input from a semi-structured system where embedded lists must be flattened and normalized.\n",
        "\n",
        "\n",
        "## **Input Format**\n",
        "\n",
        "* A CSV file named `denormalized_data.csv` with the following headers:\n",
        "\n",
        "```\n",
        "order_id,customer_name,customer_email,products,order_date\n",
        "```\n",
        "\n",
        "* The `products` field contains one or more product entries **delimited by semicolons (`;`)**. Each product is encoded as:\n",
        "\n",
        "```\n",
        "product_name:quantity@price\n",
        "```\n",
        "\n",
        "## **Example `products` field**:\n",
        "\n",
        "```\n",
        "\"Laptop:1@1000;Mouse:2@20\"\n",
        "```\n",
        "\n",
        "\n",
        "## **Output Format**\n",
        "\n",
        "Your function must generate a SQLite database named `normalized_data.db`, containing the following **four tables** in 3NF:\n",
        "\n",
        "1. **customers**\n",
        "   Columns: `customer_id`, `customer_name`, `customer_email`\n",
        "\n",
        "2. **products**\n",
        "   Columns: `product_id`, `product_name`\n",
        "\n",
        "3. **orders**\n",
        "   Columns: `order_id`, `customer_id`, `order_date`\n",
        "\n",
        "4. **order_items**\n",
        "   Columns: `order_id`, `product_id`, `quantity`, `price`\n",
        "\n",
        "\n",
        "## **Examples**\n",
        "\n",
        "### Input CSV Row:\n",
        "\n",
        "```\n",
        "1001,John Doe,john@example.com,\"Laptop:1@1000;Mouse:2@20\",2023-01-15\n",
        "```\n",
        "\n",
        "### Normalized Tables:\n",
        "\n",
        "**customers**\n",
        "\n",
        "```\n",
        "1,John Doe,john@example.com\n",
        "```\n",
        "\n",
        "**products**\n",
        "\n",
        "```\n",
        "1,Laptop\n",
        "2,Mouse\n",
        "```\n",
        "\n",
        "**orders**\n",
        "\n",
        "```\n",
        "1001,1,2023-01-15\n",
        "```\n",
        "\n",
        "**order_items**\n",
        "\n",
        "```\n",
        "1001,1,1,1000\n",
        "1001,2,2,20\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79gFg5DOtlN"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "\n",
        "## **Explicit Requirements**\n",
        "\n",
        "* Parse the `products` field correctly and normalize it.\n",
        "* Use `pandas` for CSV processing and `sqlite3` or `SQLAlchemy` for SQL export.\n",
        "* Assign consistent, stable IDs to `customer_id` and `product_id`.\n",
        "* Populate and link all four normalized tables using foreign keys.\n",
        "* Treat customers as unique by (`customer_name`, `customer_email`).\n",
        "* Treat products as unique by `product_name`.\n",
        "\n",
        "\n",
        "## **Implicit Requirements**\n",
        "\n",
        "* Maintain **referential integrity** using foreign key constraints.\n",
        "* Ensure the solution is **deterministic** (same input gives same IDs).\n",
        "* Sanitize and trim any whitespace in parsed fields.\n",
        "* Raise descriptive errors for malformed product strings.\n",
        "* Allow for empty product lists (skip row or handle gracefully).\n",
        "* Use snake_case for all table and column names.\n",
        "* Price and quantity must be cast to numeric types and defaulted to zero if missing.\n",
        "\n",
        "\n",
        "## **Edge Cases**\n",
        "\n",
        "* `products` field is empty or null: skip or handle gracefully without crashing.\n",
        "* Product entry is malformed, e.g., `\"Mouse:2\"` or `\"Laptop@1000\"`: raise validation error or log and skip.\n",
        "* Multiple orders with the same customer.\n",
        "* Multiple products with the same name across different orders.\n",
        "* CSV file with only headers and no data.\n",
        "\n",
        "\n",
        "## **Function Signature**\n",
        "\n",
        "```python\n",
        "def normalize_csv_to_3nf(csv_path: str, db_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Reads a denormalized CSV file, parses composite product entries,\n",
        "    normalizes the data into 3NF, and exports it to a SQLite database.\n",
        "\n",
        "    Parameters:\n",
        "    csv_path (str): Path to the input CSV file.\n",
        "    db_path (str): Path to the output SQLite database file.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "\n",
        "## **Constraints**\n",
        "\n",
        "* Input CSV file size: up to 500 MB.\n",
        "* Maximum number of unique customers: 100,000.\n",
        "* Maximum number of unique products: 500,000.\n",
        "* Maximum orders: 1 million.\n",
        "* Python version: 3.8+\n",
        "* Allowed libraries: `pandas`, `sqlite3`, or `sqlalchemy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSg66GeEbDAT"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from typing import Tuple, List, Set\n",
        "import os\n",
        "\n",
        "\n",
        "def generate_customer_id_map(customers_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Assigns deterministic integer IDs to customers sorted by name and email.\"\"\"\n",
        "    customers_df = customers_df.drop_duplicates()\n",
        "    customers_df = customers_df.sort_values(by=['customer_name', 'customer_email']).reset_index(drop=True)\n",
        "    customers_df['customer_id'] = customers_df.index + 1\n",
        "    return customers_df\n",
        "\n",
        "\n",
        "def generate_product_id_map(products_set: Set[Tuple[str]]) -> pd.DataFrame:\n",
        "    \"\"\"Creates a DataFrame of unique products with deterministic product IDs.\"\"\"\n",
        "    products_list = sorted(list(products_set), key=lambda x: x[0].lower())\n",
        "    products_df = pd.DataFrame(products_list, columns=['product_name'])\n",
        "    products_df['product_id'] = products_df.index + 1\n",
        "    return products_df\n",
        "\n",
        "\n",
        "def parse_products_column(df: pd.DataFrame) -> Tuple[List[Tuple[int, str, int, float]], Set[Tuple[str]]]:\n",
        "    \"\"\"\n",
        "    Parses the 'products' column to extract order_items and unique products.\n",
        "\n",
        "    Returns:\n",
        "        - A list of (order_id, product_name, quantity, price) tuples\n",
        "        - A set of unique (product_name,) tuples\n",
        "    \"\"\"\n",
        "    order_items = []\n",
        "    products_set = set()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        order_id = row['order_id']\n",
        "        products_str = row.get('products', '')\n",
        "        if pd.isna(products_str) or not isinstance(products_str, str):\n",
        "            continue\n",
        "\n",
        "        for item in products_str.split(';'):\n",
        "            item = item.strip()\n",
        "            if not item:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                name_qty, price = item.split('@')\n",
        "                product_name, quantity = name_qty.split(':')\n",
        "                product_name = product_name.strip()\n",
        "                quantity = int(quantity.strip())\n",
        "                price = float(price.strip())\n",
        "\n",
        "                if not product_name:\n",
        "                    continue\n",
        "\n",
        "                products_set.add((product_name,))\n",
        "                order_items.append((order_id, product_name, quantity, price))\n",
        "\n",
        "            except (ValueError, AttributeError):\n",
        "                # Skip malformed entries but could log these if needed\n",
        "                continue\n",
        "\n",
        "    return order_items, products_set\n",
        "\n",
        "\n",
        "def normalize_csv_to_3nf(csv_path: str, db_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Reads a denormalized CSV file, parses composite product entries,\n",
        "    normalizes the data into 3NF, and exports it to a SQLite database.\n",
        "\n",
        "    Parameters:\n",
        "        csv_path (str): Path to the input CSV file.\n",
        "        db_path (str): Path to the output SQLite database file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    required_columns = {'order_id', 'customer_name', 'customer_email', 'order_date', 'products'}\n",
        "    missing = required_columns - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in CSV: {', '.join(missing)}\")\n",
        "\n",
        "    if df.empty:\n",
        "        # Create empty tables with schema only\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
        "        cursor.executescript(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS customers (\n",
        "            customer_id INTEGER PRIMARY KEY,\n",
        "            customer_name TEXT NOT NULL,\n",
        "            customer_email TEXT NOT NULL\n",
        "        );\n",
        "        CREATE TABLE IF NOT EXISTS products (\n",
        "            product_id INTEGER PRIMARY KEY,\n",
        "            product_name TEXT NOT NULL\n",
        "        );\n",
        "        CREATE TABLE IF NOT EXISTS orders (\n",
        "            order_id INTEGER PRIMARY KEY,\n",
        "            customer_id INTEGER NOT NULL,\n",
        "            order_date TEXT NOT NULL,\n",
        "            FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "        );\n",
        "        CREATE TABLE IF NOT EXISTS order_items (\n",
        "            order_id INTEGER NOT NULL,\n",
        "            product_id INTEGER NOT NULL,\n",
        "            quantity INTEGER NOT NULL,\n",
        "            price REAL NOT NULL,\n",
        "            PRIMARY KEY (order_id, product_id),\n",
        "            FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
        "            FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        "        );\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        return\n",
        "\n",
        "    # Normalize customers\n",
        "    customers_df = df[['customer_name', 'customer_email']].copy()\n",
        "    customers_df = generate_customer_id_map(customers_df)\n",
        "\n",
        "    # Normalize orders\n",
        "    orders_df = df[['order_id', 'customer_name', 'customer_email', 'order_date']].drop_duplicates()\n",
        "    orders_df = orders_df.merge(customers_df, on=['customer_name', 'customer_email'], how='left')\n",
        "    orders_df = orders_df[['order_id', 'customer_id', 'order_date']]\n",
        "\n",
        "    # Parse products and order_items\n",
        "    order_items_raw, products_set = parse_products_column(df)\n",
        "    products_df = generate_product_id_map(products_set)\n",
        "\n",
        "    # Create order_items DataFrame by joining product IDs\n",
        "    order_items_df = pd.DataFrame(order_items_raw, columns=['order_id', 'product_name', 'quantity', 'price'])\n",
        "    order_items_df = order_items_df.merge(products_df, on='product_name', how='left')\n",
        "    order_items_df = order_items_df[['order_id', 'product_id', 'quantity', 'price']]\n",
        "\n",
        "    # Fill missing numeric values safely\n",
        "    order_items_df['quantity'] = order_items_df['quantity'].fillna(0).astype(int)\n",
        "    order_items_df['price'] = order_items_df['price'].fillna(0.0).astype(float)\n",
        "\n",
        "    # Connect to SQLite and create tables\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
        "\n",
        "    cursor.executescript(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS customers (\n",
        "        customer_id INTEGER PRIMARY KEY,\n",
        "        customer_name TEXT NOT NULL,\n",
        "        customer_email TEXT NOT NULL\n",
        "    );\n",
        "\n",
        "    CREATE TABLE IF NOT EXISTS products (\n",
        "        product_id INTEGER PRIMARY KEY,\n",
        "        product_name TEXT NOT NULL\n",
        "    );\n",
        "\n",
        "    CREATE TABLE IF NOT EXISTS orders (\n",
        "        order_id INTEGER PRIMARY KEY,\n",
        "        customer_id INTEGER NOT NULL,\n",
        "        order_date TEXT NOT NULL,\n",
        "        FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "    );\n",
        "\n",
        "    CREATE TABLE IF NOT EXISTS order_items (\n",
        "        order_id INTEGER NOT NULL,\n",
        "        product_id INTEGER NOT NULL,\n",
        "        quantity INTEGER NOT NULL,\n",
        "        price REAL NOT NULL,\n",
        "        PRIMARY KEY (order_id, product_id),\n",
        "        FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
        "        FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        "    );\n",
        "    \"\"\")\n",
        "\n",
        "    # Export data to database\n",
        "    customers_df.to_sql('customers', conn, if_exists='replace', index=False)\n",
        "    products_df.to_sql('products', conn, if_exists='replace', index=False)\n",
        "    orders_df.to_sql('orders', conn, if_exists='replace', index=False)\n",
        "    order_items_df.to_sql('order_items', conn, if_exists='replace', index=False)\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlcq7ycbHYw"
      },
      "outputs": [],
      "source": [
        "# tests\n",
        "\n",
        "\"\"\"Unit tests for the normalize_csv_to_3nf function.\n",
        "\n",
        "This module contains test cases to verify CSV to 3NF database normalization,\n",
        "including edge cases and data validation scenarios.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sqlite3\n",
        "import unittest\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from main import normalize_csv_to_3nf\n",
        "\n",
        "\n",
        "class TestNormalizeCSVTo3NF(unittest.TestCase):\n",
        "    \"\"\"Test suite for normalize_csv_to_3nf function.\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Initialize test files and paths before each test.\"\"\"\n",
        "        self.csv_path = \"test_denormalized_data.csv\"\n",
        "        self.db_path = \"test_normalized_data.db\"\n",
        "        self.cleanup_files()\n",
        "\n",
        "    def tearDown(self):\n",
        "        \"\"\"Clean up test files after each test.\"\"\"\n",
        "        self.cleanup_files()\n",
        "\n",
        "    def cleanup_files(self):\n",
        "        \"\"\"Remove test files if they exist.\"\"\"\n",
        "        for path in [self.csv_path, self.db_path]:\n",
        "            try:\n",
        "                if os.path.exists(path):\n",
        "                    os.remove(path)\n",
        "            except PermissionError:\n",
        "                pass\n",
        "\n",
        "    def read_table(self, table_name):\n",
        "        \"\"\"Read table from database.\"\"\"\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            query = f\"SELECT * FROM {table_name}\"\n",
        "            return pd.read_sql_query(query, conn)\n",
        "\n",
        "    def test_single_valid_order(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write(\"1001, John Doe, john@example.com, Laptop:1@1000,\"\n",
        "                    \" 2023-01-15\\n\")\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"orders\")\n",
        "        self.assertEqual(len(df), 1)\n",
        "        self.assertEqual(df.iloc[0][\"order_id\"], 1001)\n",
        "\n",
        "    def test_empty_products_field_skips_order(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write(\"1002,Alice,a@example.com,,2023-01-16\\n\")\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertEqual(len(df), 0)\n",
        "\n",
        "    def test_multiple_products_parsed_correctly(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1003,Bob,b@example.com,\"Laptop:1@1000;Mouse:2@20\",'\n",
        "                    \"2023-01-17\\n\")\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertEqual(len(df), 2)\n",
        "\n",
        "    def test_product_missing_quantity_skipped_or_zero(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1004,Carl,c@example.com,\"Keyboard:@100\",2023-01-18\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertTrue(df.empty)\n",
        "\n",
        "    def test_product_missing_price_skipped_or_zero(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1005,Diana,d@example.com,\"Monitor:2@\",2023-01-19\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertTrue(df.empty)\n",
        "\n",
        "    def test_no_crash_on_missing_columns(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,products,order_date\\n\")\n",
        "            f.write('1006,Eve,\"Tablet:1@200\",2023-01-20\\n')\n",
        "\n",
        "        with self.assertRaises(Exception):\n",
        "            normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "\n",
        "    def test_trailing_semicolon_is_ignored(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1007,Fred,f@example.com,\"Mouse:2@20;\",2023-01-21\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertEqual(len(df), 1)\n",
        "\n",
        "    def test_malformed_product_skipped(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1008,Gary,g@example.com,\"BadProduct\",2023-01-22\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertEqual(len(df), 0)\n",
        "\n",
        "    def test_customers_have_unique_ids(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1009,Hank,h@example.com,\"Pen:1@5\",2023-01-23\\n')\n",
        "            f.write('1010,Hank,h@example.com,\"Book:2@15\",2023-01-24\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"customers\")\n",
        "        self.assertEqual(len(df), 1)\n",
        "\n",
        "    def test_products_have_unique_ids(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1011,Ivy,i@example.com,\"Pen:1@5;Pen:2@6\",2023-01-25\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"products\")\n",
        "        self.assertEqual(len(df), 1)\n",
        "\n",
        "    def test_multi_order_same_customer_and_product(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1012,John Doe,john@example.com,\"Pen:1@5\",2023-01-26\\n')\n",
        "            f.write('1013,John Doe,john@example.com,\"Pen:3@15\",2023-01-27\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        self.assertEqual(len(self.read_table(\"customers\")), 1)\n",
        "        self.assertEqual(len(self.read_table(\"products\")), 1)\n",
        "\n",
        "    def test_order_id_is_preserved(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('9999,Zack,z@example.com,\"Phone:1@999\",2023-01-28\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"orders\")\n",
        "        self.assertEqual(df.iloc[0][\"order_id\"], 9999)\n",
        "\n",
        "    def test_whitespace_trimmed_in_fields(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1014,  Jill ,  jill@example.com  ,\" Lamp :1@50 \",'\n",
        "                    \"2023-01-29\\n\")\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"customers\")\n",
        "        self.assertIn(\"Jill\", df.iloc[0][\"customer_name\"])\n",
        "\n",
        "    def test_case_sensitive_customers(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1015,Kate,kate@example.com,\"Cup:1@10\",2023-01-30\\n')\n",
        "            f.write('1016,kate,kate@example.com,\"Cup:1@10\",2023-01-31\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"customers\")\n",
        "        self.assertEqual(len(df), 2)\n",
        "\n",
        "    def test_product_name_case_insensitive_uniqueness(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('1017,Liam,liam@example.com,\"Chair:1@30\",2023-02-01\\n')\n",
        "            f.write('1018,Liam,liam@example.com,\"chair:1@35\",2023-02-02\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"products\")\n",
        "        self.assertEqual(len(df), 2)\n",
        "\n",
        "    def test_large_order_list_limit(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            for i in range(1000, 1020):\n",
        "                date = f\"2023-02-0{i % 28 + 1}\"\n",
        "                f.write(f'{i},Bulk,b@example.com,\"Item{i}:1@10\",{date}\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"orders\")\n",
        "        self.assertEqual(len(df), 20)\n",
        "\n",
        "    def test_valid_product_with_zero_quantity(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('2001,Mira,m@example.com,\"Box:0@10\",2023-02-10\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertEqual(df.iloc[0][\"quantity\"], 0)\n",
        "\n",
        "    def test_valid_product_with_zero_price(self):\n",
        "        with open(self.csv_path, \"w\") as f:\n",
        "            f.write(\"order_id,customer_name,customer_email,products,\"\n",
        "                    \"order_date\\n\")\n",
        "            f.write('2002,Nico,n@example.com,\"Board:2@0\",2023-02-11\\n')\n",
        "\n",
        "        normalize_csv_to_3nf(self.csv_path, self.db_path)\n",
        "        df = self.read_table(\"order_items\")\n",
        "        self.assertEqual(df.iloc[0][\"price\"], 0)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZs2ehLYWkm"
      },
      "source": [
        "# Model Breaking Proof\n",
        "\n",
        "#### Model Breaking Task URL: https://rlhf-v3.turing.com/prompt/0eceb2dc-a0c1-4bdf-a312-408b9453caa7?origin=https%3A%2F%2Flabeling-ms.turing.com&redirect_url=https%3A%2F%2Flabeling-ms.turing.com%2Fconversations%2F67752%2Fview\n",
        "\n",
        "#### Model code:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import hashlib\n",
        "\n",
        "def normalize_csv_to_3nf(csv_path: str, db_path: str) -> None:\n",
        "    # Load the CSV file into a DataFrame\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Extract unique customers\n",
        "    customers = df[['customer_name', 'customer_email']].drop_duplicates().reset_index(drop=True)\n",
        "    # Hash customer_name and customer_email for unique and consistent IDs\n",
        "    customers['customer_id'] = customers.apply(lambda row: hashlib.md5((row['customer_name'] + row['customer_email']).encode()).hexdigest(), axis=1) # <Issue>: It is using md5 hashes as primary keys which violates the explicit requirement for consistent and stable ids\n",
        "\n",
        "    # Separate orders\n",
        "    orders = df[['order_id', 'order_date']]\n",
        "    # Ensure order_id field is unique (dropping duplicates if any)\n",
        "    orders = orders.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # Get customer_id for each order by merging\n",
        "    orders = orders.merge(df[['order_id', 'customer_name', 'customer_email']], on='order_id')\n",
        "    orders = orders.merge(customers, on=['customer_name', 'customer_email'], how='left')\n",
        "    orders = orders[['order_id', 'customer_id', 'order_date']]\n",
        "    \n",
        "    # Extract and normalize products and order_items\n",
        "    products_set = set()\n",
        "    order_items = []\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        order_id = row['order_id']\n",
        "        if pd.isna(row['products']):\n",
        "            continue\n",
        "        products = row['products'].split(';')\n",
        "        for prod in products:\n",
        "            details = prod.split('@')\n",
        "            if len(details) != 2:\n",
        "                continue  # Skip malformed entries\n",
        "            name_qty = details[0].split(':')\n",
        "            if len(name_qty) != 2:\n",
        "                continue  # Skip malformed entries\n",
        "            product_name, quantity = name_qty[0].strip(), name_qty[1].strip()\n",
        "            price = details[1].strip()\n",
        "            try:\n",
        "                quantity = int(quantity)\n",
        "                price = float(price)\n",
        "            except ValueError:\n",
        "                continue  # Skip entries with invalid quantity or price\n",
        "            \n",
        "            product_id = hashlib.md5(product_name.encode()).hexdigest()\n",
        "            products_set.add((product_id, product_name))\n",
        "            order_items.append((order_id, product_id, quantity, price))\n",
        "    \n",
        "    # Create a DataFrame from products set\n",
        "    products = pd.DataFrame(list(products_set), columns=['product_id', 'product_name'])\n",
        "    \n",
        "    # Create a DataFrame for order_items\n",
        "    order_items_df = pd.DataFrame(order_items, columns=['order_id', 'product_id', 'quantity', 'price'])\n",
        "    \n",
        "    # Create the SQLite database and tables\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Creating the tables\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS customers (\n",
        "            customer_id TEXT PRIMARY KEY,\n",
        "            customer_name TEXT,\n",
        "            customer_email TEXT\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS products (\n",
        "            product_id TEXT PRIMARY KEY,\n",
        "            product_name TEXT\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS orders (\n",
        "            order_id INTEGER PRIMARY KEY,\n",
        "            customer_id TEXT,\n",
        "            order_date TEXT,\n",
        "            FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS order_items (\n",
        "            order_id INTEGER,\n",
        "            product_id TEXT,\n",
        "            quantity INTEGER,\n",
        "            price REAL,\n",
        "            FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
        "            FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        "        )\n",
        "    ''') # <Issue>: does not include a primary key. At a minimum, (order_id, product_id) should be defined as a composite primary key.\n",
        "\n",
        "    # Insert data into database\n",
        "    customers.to_sql('customers', conn, if_exists='replace', index=False)\n",
        "    products.to_sql('products', conn, if_exists='replace', index=False)\n",
        "    orders.to_sql('orders', conn, if_exists='replace', index=False)\n",
        "    order_items_df.to_sql('order_items', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Close the database connection\n",
        "    conn.commit()\n",
        "    conn # <Issue>: Generated incomplete response. conn.close() was not called.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}